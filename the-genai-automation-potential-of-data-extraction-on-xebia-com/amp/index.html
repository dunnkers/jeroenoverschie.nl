<!DOCTYPE html>
<html ‚ö° lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <title>The GenAI automation potential of data extraction (on Xebia.com ‚ßâ)</title>

    <meta name="description" content="GenAI has been around for a little while and its capabilities are expanding quickly. But still, many companies fail to generate actual value with GenAI. Why is that? In this blogpost, we explore the GenAI automation potential that exists today for data extraction.">
    <link rel="icon" href="https://jeroenoverschie.nl/content/images/size/w256h256/format/png/2022/10/cartoon-head-jeroen-1-2.svg" type="image/png">
    <link rel="canonical" href="https://jeroenoverschie.nl/the-genai-automation-potential-of-data-extraction-on-xebia-com/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="Jeroen Overschie">
    <meta property="og:type" content="article">
    <meta property="og:title" content="The GenAI automation potential of data extraction (on Xebia.com ‚ßâ)">
    <meta property="og:description" content="GenAI has been around for a little while and its capabilities are expanding quickly. But still, many companies fail to generate actual value with GenAI. Why is that? In this blogpost, we explore the GenAI automation potential that exists today for data extraction.">
    <meta property="og:url" content="https://jeroenoverschie.nl/the-genai-automation-potential-of-data-extraction-on-xebia-com/">
    <meta property="og:image" content="https://jeroenoverschie.nl/content/images/2025/04/banner.jpg">
    <meta property="article:published_time" content="2025-04-09T13:45:49.000Z">
    <meta property="article:modified_time" content="2025-04-09T13:53:56.000Z">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="The GenAI automation potential of data extraction (on Xebia.com ‚ßâ)">
    <meta name="twitter:description" content="GenAI has been around for a little while and its capabilities are expanding quickly. But still, many companies fail to generate actual value with GenAI. Why is that? In this blogpost, we explore the GenAI automation potential that exists today for data extraction.">
    <meta name="twitter:url" content="https://jeroenoverschie.nl/the-genai-automation-potential-of-data-extraction-on-xebia-com/">
    <meta name="twitter:image" content="https://jeroenoverschie.nl/content/images/2025/04/banner.jpg">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Jeroen Overschie">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="800">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Jeroen Overschie",
        "url": "https://jeroenoverschie.nl/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://jeroenoverschie.nl/content/images/size/w256h256/format/png/2022/10/cartoon-head-jeroen-1-2.svg",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "Jeroen Overschie",
        "image": {
            "@type": "ImageObject",
            "url": "https://www.gravatar.com/avatar/b37b136916ade32aada1f345482aafa4?s=250&r=x&d=mp",
            "width": 250,
            "height": 250
        },
        "url": "https://jeroenoverschie.nl/author/jeroen/",
        "sameAs": []
    },
    "headline": "The GenAI automation potential of data extraction (on Xebia.com ‚ßâ)",
    "url": "https://jeroenoverschie.nl/the-genai-automation-potential-of-data-extraction-on-xebia-com/",
    "datePublished": "2025-04-09T13:45:49.000Z",
    "dateModified": "2025-04-09T13:53:56.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://jeroenoverschie.nl/content/images/2025/04/banner.jpg",
        "width": 1200,
        "height": 800
    },
    "description": "GenAI has been around for a little while and its capabilities are expanding quickly. But still, many companies fail to generate actual value with GenAI. Why is that? In this blogpost, we explore the GenAI automation potential that exists today for data extraction.",
    "mainEntityOfPage": "https://jeroenoverschie.nl/the-genai-automation-potential-of-data-extraction-on-xebia-com/"
}
    </script>

    <meta name="generator" content="Ghost 5.130">
    <link rel="alternate" type="application/rss+xml" title="Jeroen Overschie" href="https://jeroenoverschie.nl/rss/">

    <style amp-custom>
    *,
    *::before,
    *::after {
        box-sizing: border-box;
    }

    html {
        overflow-x: hidden;
        overflow-y: scroll;
        font-size: 62.5%;
        -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
    }

    body {
        min-height: 100vh;
        margin: 0;
        padding: 0;
        color: #3a4145;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        font-size: 1.7rem;
        line-height: 1.55em;
        font-weight: 400;
        font-style: normal;
        background: #fff;
        scroll-behavior: smooth;
        overflow-x: hidden;
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
    }

    p,
    ul,
    ol,
    li,
    dl,
    dd,
    hr,
    pre,
    form,
    table,
    video,
    figure,
    figcaption,
    blockquote {
        margin: 0;
        padding: 0;
    }

    ul[class],
    ol[class] {
        padding: 0;
        list-style: none;
    }

    img {
        display: block;
        max-width: 100%;
    }

    input,
    button,
    select,
    textarea {
        font: inherit;
        -webkit-appearance: none;
    }

    fieldset {
        margin: 0;
        padding: 0;
        border: 0;
    }

    label {
        display: block;
        font-size: 0.9em;
        font-weight: 700;
    }

    hr {
        position: relative;
        display: block;
        width: 100%;
        height: 1px;
        border: 0;
        border-top: 1px solid currentcolor;
        opacity: 0.1;
    }

    ::selection {
        text-shadow: none;
        background: #cbeafb;
    }

    mark {
        background-color: #fdffb6;
    }

    small {
        font-size: 80%;
    }

    sub,
    sup {
        position: relative;
        font-size: 75%;
        line-height: 0;
        vertical-align: baseline;
    }
    sup {
        top: -0.5em;
    }
    sub {
        bottom: -0.25em;
    }

    ul li + li {
        margin-top: 0.6em;
    }

    a {
        color: var(--ghost-accent-color, #1292EE);
        text-decoration-skip-ink: auto;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 0;
        font-weight: 700;
        color: #121212;
        line-height: 1.4em;
    }

    h1 {
        font-size: 3.4rem;
        line-height: 1.1em;
    }

    h2 {
        font-size: 2.4rem;
        line-height: 1.2em;
    }

    h3 {
        font-size: 1.8rem;
    }

    h4 {
        font-size: 1.7rem;
    }

    h5 {
        font-size: 1.6rem;
    }

    h6 {
        font-size: 1.6rem;
    }

    amp-img {
        height: 100%;
        width: 100%;
        max-width: 100%;
        max-height: 100%;
    }

    amp-img img {
        object-fit: cover;
    }
    
    amp-youtube {
        height: calc(100vw / 1.78);
        width: 100vw;
        position: relative;
    }

    amp-youtube img {
        position: absolute;
    }

    .page-header {
        padding: 50px 5vmin 30px;
        text-align: center;
        font-size: 2rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }

    .page-header a {
        color: #121212;
        font-weight: 700;
        text-decoration: none;
        font-size: 1.6rem;
        letter-spacing: -0.1px;
    }

    .post {
        max-width: 680px;
        margin: 0 auto;
    }

    .post-header {
        margin: 0 5vmin 5vmin;
        text-align: center;
    }

    .post-meta {
        margin: 1rem 0 0 0;
        text-transform: uppercase;
        color: #738a94;
        font-weight: 500;
        font-size: 1.3rem;
    }

    .post-image {
        margin: 0 0 5vmin;
    }

    .post-image img {
        display: block;
        width: 100%;
        height: auto;
    }

    .post-content {
        padding: 0 5vmin;
    }

    .post-content > * + * {
        margin-top: 1.5em;
    }

    .post-content [id]:not(:first-child) {
        margin: 2em 0 0;
    }

    .post-content > [id] + * {
        margin-top: 1rem;
    }

    .post-content [id] + .kg-card,
    .post-content blockquote + .kg-card {
        margin-top: 40px;
    }

    .post-content > ul,
    .post-content > ol,
    .post-content > dl {
        padding-left: 1.9em;
    }

    .post-content hr {
        margin-top: 40px;
    }

    .post .post-content hr + * {
        margin-top: 40px;
    }

    .post-content amp-img {
        background-color: #f8f8f8;
    }

    .post-content blockquote {
        position: relative;
        font-style: italic;
    }

    .post-content blockquote::before {
        content: "";
        position: absolute;
        left: -1.5em;
        top: 0;
        bottom: 0;
        width: 0.3rem;
        background: var(--ghost-accent-color, #1292EE);
    }

    .post-content blockquote.kg-blockquote-alt {
        font-size: 1.2em;
        font-style: italic;
        line-height: 1.6em;
        text-align: center;
        color: #738a94;
        padding: 0.75em 3em 1.25em;
    }

    .post-content blockquote.kg-blockquote-alt::before {
        display: none;
    }

    .post-content :not(.kg-card):not([id]) + .kg-card {
        margin-top: 40px;
    }

    .post-content .kg-card + :not(.kg-card) {
        margin-top: 40px;
    }

    .kg-card figcaption {
        padding: 1.5rem 1.5rem 0;
        text-align: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.4em;
        opacity: 0.6;
    }

    .kg-card figcaption strong {
        color: rgba(0,0,0,0.8);
    }

    .post-content :not(pre) code {
        vertical-align: middle;
        padding: 0.15em 0.4em 0.15em;
        border: #e1eaef 1px solid;
        font-weight: 400;
        font-size: 0.9em;
        line-height: 1em;
        color: #15171a;
        background: #f0f6f9;
        border-radius: 0.25em;
    }

    .post-content > pre {
        overflow: scroll;
        padding: 16px 20px;
        color: #fff;
        background: #1F2428;
        border-radius: 5px;
        box-shadow: 0 2px 6px -2px rgba(0,0,0,.1), 0 0 1px rgba(0,0,0,.4);
    }

    .kg-embed-card {
        display: flex;
        flex-direction: column;
        align-items: center;
        width: 100%;
    }

    .kg-image-card img {
        margin: auto;
    }

    .kg-gallery-card + .kg-gallery-card {
        margin-top: 0.75em;
    }

    .kg-gallery-container {
        position: relative;
    }

    .kg-gallery-row {
        display: flex;
        flex-direction: row;
        justify-content: center;
    }

    .kg-gallery-image {
        width: 100%;
        height: 100%;
    }

    .kg-gallery-row:not(:first-of-type) {
        margin: 0.75em 0 0 0;
    }

    .kg-gallery-image:not(:first-of-type) {
        margin: 0 0 0 0.75em;
    }

    .kg-bookmark-card,
    .kg-bookmark-publisher {
        position: relative;
    }

    .kg-bookmark-container,
    .kg-bookmark-container:hover {
        display: flex;
        flex-wrap: wrap;
        flex-direction: row-reverse;
        color: currentColor;
        background: rgba(255,255,255,0.6);
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        text-decoration: none;
        border-radius: 3px;
        box-shadow: 0 2px 6px -2px rgba(0, 0, 0, 0.1), 0 0 1px rgba(0, 0, 0, 0.4);
        overflow: hidden;
    }

    .kg-bookmark-content {
        flex-basis: 0;
        flex-grow: 999;
        padding: 20px;
        order: 1;
    }

    .kg-bookmark-title {
        font-weight: 600;
        font-size: 1.5rem;
        line-height: 1.3em;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        max-height: 45px;
        margin: 0.5em 0 0 0;
        font-size: 1.4rem;
        line-height: 1.55em;
        overflow: hidden;
        opacity: 0.8;
        -webkit-line-clamp: 2;
        -webkit-box-orient: vertical;
    }

    .kg-bookmark-metadata {
        margin-top: 20px;
    }

    .kg-bookmark-metadata {
        display: flex;
        align-items: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.3em;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        -webkit-box-orient: vertical;
        -webkit-line-clamp: 2;
        overflow: hidden;
    }

    .kg-bookmark-metadata amp-img {
        width: 18px;
        height: 18px;
        max-width: 18px;
        max-height: 18px;
        margin-right: 10px;
    }

    .kg-bookmark-thumbnail {
        display: flex;
        flex-basis: 20rem;
        flex-grow: 1;
        justify-content: flex-end;
    }

    .kg-bookmark-thumbnail amp-img {
        max-height: 200px;
    }

    .kg-bookmark-author {
        white-space: nowrap;
        text-overflow: ellipsis;
        overflow: hidden;
    }

    .kg-bookmark-publisher::before {
        content: "‚Ä¢";
        margin: 0 .5em;
    }

    .kg-toggle-card-icon {
        display: none;
    }

    .kg-toggle-content {
        margin-top: 0.8rem;
    }

    .kg-product-card-container {
        background: transparent;
        padding: 20px;
        width: 100%;
        border-radius: 5px;
        box-shadow: inset 0 0 0 1px rgb(124 139 154 / 25%);
    }

    .kg-product-card-description p {
        margin-top: 1.5em;
    }

    .kg-product-card-description ul {
        margin-left: 24px;
    }

    .kg-product-card-title {
        font-size: 1.9rem;
        font-weight: 700;
    }

    .kg-product-card-rating-star {
        height: 28px;
        width: 20px;
        margin-right: 2px;
    }

    .kg-product-card-rating-star svg {
    width: 16px;
    height: 16px;
    fill: currentColor;
    opacity: 0.15;
    }

    .kg-product-card-rating-active.kg-product-card-rating-star svg {
    opacity: 1;
    }

    .kg-nft-card-container {
        position: relative;
        display: flex;
        flex: auto;
        flex-direction: column;
        text-decoration: none;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        font-size: 1.4rem;
        font-weight: 400;
        box-shadow: 0 2px 6px -2px rgb(0 0 0 / 10%), 0 0 1px rgb(0 0 0 / 40%);
        width: 100%;
        max-width: 512px;
        color: #15212A;
        background: #fff;
        border-radius: 5px;
        transition: none;
        margin: 0 auto;
    }

    .kg-nft-metadata {
        padding: 2.0rem;
    }

    .kg-nft-image-container {
        position: relative;
    }

    .kg-nft-image {
        display: flex;
        border-radius: 5px 5px 0 0;
    }

    .kg-nft-header {
        display: flex;
        justify-content: space-between;
        align-items: flex-start;
        gap: 20px;
    }

    .kg-nft-header h4.kg-nft-title {
        font-size: 1.9rem;
        font-weight: 700;
        margin: 0;
        color: #15212A;
    }

    .kg-nft-header amp-img {
        max-width: 114px;
        max-height: 26px;
    }

    .kg-nft-opensea-logo {
        margin-top: 2px;
        width: 100px;
    }

    .kg-nft-creator {
        font-family: inherit;
        color: #95A1AD;
    }

    .kg-nft-creator span {
        font-weight: 500;
        color: #15212A;
    }

    .kg-nft-card p.kg-nft-description {
        font-size: 1.4rem;
        line-height: 1.4em;
        margin: 2.0rem 0 0;
        color: #222;
    }

    .kg-button-card {
        display: flex;
        position: static;
        align-items: center;
        width: 100%;
        justify-content: center;
    }

    .kg-btn {
        display: flex;
        position: static;
        align-items: center;
        padding: 0 2.0rem;
        height: 4.0rem;
        line-height: 4.0rem;
        font-size: 1.65rem;
        font-weight: 600;
        text-decoration: none;
        border-radius: 5px;
        transition: opacity 0.2s ease-in-out;
    }

    .kg-btn:hover {
        opacity: 0.85;
    }

    .kg-btn-accent {
        background-color: var(--ghost-accent-color, #1292EE);
        color: #fff;
    }

    .kg-callout-card {
        display: flex;
        padding: 20px 28px;
        border-radius: 3px;
    }

    .kg-callout-card-grey {
        background: rgba(124, 139, 154, 0.13);
    }

    .kg-callout-card-white {
        background: transparent;
        box-shadow: inset 0 0 0 1px rgba(124, 139, 154, 0.25);
    }

    .kg-callout-card-blue {
        background: rgba(33, 172, 232, 0.12);
    }

    .kg-callout-card-green {
        background: rgba(52, 183, 67, 0.12);
    }

    .kg-callout-card-yellow {
        background: rgba(240, 165, 15, 0.13);
    }

    .kg-callout-card-red {
        background: rgba(209, 46, 46, 0.11);
    }

    .kg-callout-card-pink {
        background: rgba(225, 71, 174, 0.11);
    }

    .kg-callout-card-purple {
        background: rgba(135, 85, 236, 0.12);
    }

    .kg-callout-card-accent {
        background: var(--ghost-accent-color);
        color: #fff;
    }

    .kg-callout-card-accent a {
        color: #fff;
    }

    .kg-callout-emoji {
        padding-right: 16px;
        line-height: 1.3;
        font-size: 1.25em;
    }

    .kg-header-card {
        padding: 6em 3em;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        text-align: center;
    }

    .kg-header-card.kg-size-small {
        padding-top: 4em;
        padding-bottom: 4em;
    }

    .kg-header-card.kg-size-large {
        padding-top: 12em;
        padding-bottom: 12em;
    }

    .kg-header-card.kg-width-full {
        padding-left: 4em;
        padding-right: 4em;
    }

    .kg-header-card.kg-align-left {
        text-align: left;
        align-items: flex-start;
    }

    .kg-header-card.kg-style-dark {
        background: #15171a;
        color: #ffffff;
    }

    .kg-header-card.kg-style-light {
        color: #15171a;
        border: 1px solid rgba(124, 139, 154, 0.25);
        border-width: 1px 0;
    }

    .kg-header-card.kg-style-accent {
        background-color: var(--ghost-accent-color);
    }

    .kg-header-card.kg-style-image {
        background-color: #e7e7eb;
        background-size: cover;
        background-position: center center;
    }

    .kg-header-card h2 {
        font-size: 4em;
        font-weight: 700;
        line-height: 1.1em;
        margin: 0;
    }

    .kg-header-card h2 strong {
        font-weight: 800;
    }

    .kg-header-card.kg-size-small h2 {
        font-size: 3em;
    }

    .kg-header-card.kg-size-large h2 {
        font-size: 5em;
    }

    .kg-header-card h3 {
        font-size: 1.25em;
        font-weight: 500;
        line-height: 1.3em;
        margin: 0;
    }

    .kg-header-card h3 strong {
        font-weight: 600;
    }

    .kg-header-card.kg-size-small h3 {
        font-size: 1em;
    }

    .kg-header-card.kg-size-large h3 {
        font-size: 1.5em;
    }

    .kg-header-card:not(.kg-style-light) h2,
    .kg-header-card:not(.kg-style-light) h3 {
        color: #ffffff;
    }

    .kg-header-card a.kg-header-card-button {
        display: flex;
        position: static;
        align-items: center;
        padding: 0 1.2em;
        height: 2.4em;
        line-height: 1em;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif;
        font-size: 0.95em;
        font-weight: 600;
        text-decoration: none;
        border-radius: 5px;
        transition: opacity 0.2s ease-in-out;
        background-color: var(--ghost-accent-color);
        color: #ffffff;
        margin: 1.75em 0 0;
    }

    .kg-header-card a.kg-header-card-button:hover {
        opacity: 0.85;
    }

    .kg-header-card.kg-size-large a.kg-header-card-button {
        margin-top: 2em;
    }

    .kg-header-card.kg-size-small a.kg-header-card-button {
        margin-top: 1.5em;
    }

    .kg-header-card.kg-style-image a.kg-header-card-button,
    .kg-header-card.kg-style-dark a.kg-header-card-button {
        background: #ffffff;
        color: #15171a;
    }

    .kg-header-card.kg-style-accent a.kg-header-card-button {
        background: #ffffff;
        color: var(--ghost-accent-color);
    }

    .kg-audio-card {
        display: flex;
        width: 100%;
        box-shadow: inset 0 0 0 1px rgba(124, 139, 154, 0.25);
    }

    .kg-audio-thumbnail {
        display: flex;
        justify-content: center;
        align-items: center;
        width: 80px;
        min-width: 80px;
        height: 80px;
        background: transparent;
        object-fit: cover;
        aspect-ratio: 1/1;
        border-radius: 3px 0 0 3px;
    }

    .kg-audio-thumbnail.placeholder {
        background: var(--ghost-accent-color);
    }

    .kg-audio-thumbnail.placeholder svg {
        width: 24px;
        height: 24px;
        fill: white;
    }

    .kg-audio-player-container {
        position: relative;
        display: flex;
        flex-direction: column;
        justify-content: space-between;
        width: 100%;
        --seek-before-width: 0%;
        --volume-before-width: 100%;
        --buffered-width: 0%;
    }

    .kg-audio-title {
        width: 100%;
        padding: 8px 12px 0;
        border: none;
        font-family: inherit;
        font-size: 1.1em;
        font-weight: 700;
        background: transparent;
    }

    .kg-audio-player {
        display: none;
    }

    .kg-width-full.kg-card-hascaption {
        display: grid;
        grid-template-columns: inherit;
    }

    .post-content table {
        border-collapse: collapse;
        width: 100%;
    }

    .post-content th {
        padding: 0.5em 0.8em;
        text-align: left;
        font-size: .75em;
        text-transform: uppercase;
    }

    .post-content td {
        padding: 0.4em 0.7em;
    }

    .post-content tbody tr:nth-child(2n + 1) {
        background-color: rgba(0,0,0,0.1);
        padding: 1px;
    }

    .post-content tbody tr:nth-child(2n + 2) td:last-child {
        box-shadow:
            inset 1px 0 rgba(0,0,0,0.1),
            inset -1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:nth-child(2n + 2) td {
        box-shadow: inset 1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:last-child {
        border-bottom: 1px solid rgba(0,0,0,.1);
    }

    .page-footer {
        padding: 60px 5vmin;
        margin: 60px auto 0;
        text-align: center;
        background-color: #f8f8f8;
    }

    .page-footer h3 {
        margin: 0.5rem 0 0 0;
    }

    .page-footer p {
        max-width: 500px;
        margin: 1rem auto 1.5rem;
        font-size: 1.7rem;
        line-height: 1.5em;
        color: rgba(0,0,0,0.6)
    }

    .powered {
        display: inline-flex;
        align-items: center;
        margin: 30px 0 0;
        padding: 6px 9px 6px 6px;
        border: rgba(0,0,0,0.1) 1px solid;
        font-size: 12px;
        line-height: 12px;
        letter-spacing: -0.2px;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif;
        font-weight: 500;
        color: #222;
        text-decoration: none;
        background: #fff;
        border-radius: 6px;
    }

    .powered svg {
        height: 16px;
        width: 16px;
        margin: 0 6px 0 0;
    }

    @media (max-width: 600px) {
        body {
            font-size: 1.6rem;
        }
        h1 {
            font-size: 3rem;
        }

        h2 {
            font-size: 2.2rem;
        }
    }

    @media (max-width: 400px) {
        h1 {
            font-size: 2.6rem;
            line-height: 1.15em;
        }
        h2 {
            font-size: 2rem;
            line-height: 1.2em;
        }
        h3 {
            font-size: 1.7rem;
        }
    }

    :root {--ghost-accent-color: #FF1A75;}
    </style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    

</head>

<body class="amp-template">
    <header class="page-header">
        <a href="https://jeroenoverschie.nl">
                <amp-img class="site-icon" src="https://jeroenoverschie.nl/content/images/2022/10/cartoon-head-jeroen-1-2.svg" width="50" height="50" layout="fixed" alt="Jeroen Overschie"></amp-img>
        </a>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">The GenAI automation potential of data extraction (on Xebia.com ‚ßâ)</h1>
                <section class="post-meta">
                    Jeroen Overschie -
                    <time class="post-date" datetime="2025-04-09">09 Apr 2025</time>
                </section>
            </header>
            <figure class="post-image">
                <amp-img src="https://jeroenoverschie.nl/content/images/2025/04/banner.jpg" width="600" height="340" layout="responsive" 
                alt="The GenAI automation potential of data extraction (on Xebia.com ‚ßâ)"
                ></amp-img>
            </figure>
            <section class="post-content">

                <h2 id="introduction">Introduction</h2><p>GenAI has been around for a little while and its capabilities are expanding quickly. We are experiencing peak-hype levels for AI and expectations are sky-high. But still, many companies fail to generate actual value with GenAI. Why is that? Why are we promised so much yet manage to get so little? What is still fantasy and what concrete potential exists? What should be automated and what should not? In this blogpost, we explore the GenAI automation potential that exists today for¬†<em>data extraction</em>.</p><p>Together, we will learn about:</p><ol><li>Why GenAI data extraction</li><li>The automation levels</li><li>The automation potential</li></ol><p>Let‚Äôs start!</p><h2 id="1-why-genai-data-extraction">1. Why GenAI data extraction</h2><p>Why exactly should we care about GenAI data extraction? Let us motivate this by looking at 4 example usecases in different domains and with various data types like text-, images-, documents- or audio.</p><ul><li>Insurance claims (text)</li><li>Menu cards (images)</li><li>Annual reports (PDF documents)</li><li>Customer service calls (audio)</li></ul><h3 id="insurance-claims-text">Insurance claims (text)</h3><p>Imagine you are running an insurance company and your employees are tasked with processing insurance claims. Claims are often provided in a free-form format: email, phone call, chat, in short: unstructured data. Your employees will then need to process this information to handle the claim: update the internal databases, find similar claim cases, etc. Let‚Äôs take the case where we receive this information in free-form¬†<strong>text</strong>¬†like emails.</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption><span>LLMs can extract structured data from free-form text like an insurance claim, saving employees time doing it manually.¬†See¬†</span><a href="https://github.com/xebia/genai-data-extraction/blob/main/notebooks/insurance_claims_reports.ipynb" rel="noopener"><span>Code</span></a><span>.</span></figcaption></figure><p>We instruct the LLM to give its answers in¬†<em>structured</em>¬†format¬†<a href="https://ai.google.dev/gemini-api/docs/structured-output?lang=python" rel="noopener"><sup>[ref]</sup></a>, so we can easily work with- and transform its output. To clear this entire email box with some 25 emails Gemini 2.0 Flash took some 15 seconds. That is if ran¬†<em>sequentially</em>: if ran in parallel this amount of data process can be processed in a matter of seconds. If this were scaled to process a mailbox of 100k emails we would spend about $1.52. Not an awful lot given we can save some serious time here. We can also half this cost if we use Gemini‚Äôs¬†<a href="https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini" rel="noopener">Batch API</a>¬†instead. How long would it take a human to process 100k emails? What is their time worth?</p><p>Extracting client information from this email message took Gemini 2.0 Flash about 0.5 seconds and cost $0.000015.</p><h3 id="menu-cards-images">Menu cards (images)</h3><p>Different usecase. Imagine now you are running an online platform for food delivery. You want to digitise menu cards so the offering can be ingested in your own platform in standardised manner. You are staffing a number of employees to help you do this task. The menu cards arrive in¬†<strong>image</strong>¬†format. Can we speed up the menu conversion process?</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption><span>LLMs can read menu cards and convert them directly into a desired structured format, cutting development cost for custom- OCR and extraction solutions and potentially providing superior extraction performance.¬†See¬†</span><a href="https://github.com/xebia/genai-data-extraction/blob/main/notebooks/menu_card.ipynb" rel="noopener"><span>Code</span></a><span>.</span></figcaption></figure><p>Yes: we can speed this up. LLMs consider the image as a whole and are also able to accurately process text details in the image. Because we are using a generic model images in many contexts can be processed by the same model without having to fine-tune over specific situations.</p><p>Converting this menu card took Gemini 2.0 Flash about 10 seconds and cost $0.0005. How long would a human take?</p><h3 id="annual-reports-pdf-documents">Annual reports (PDF documents)</h3><p>Imagine you are tasked with answering questions based on financial documents. You are to go through each question and reason on the answer based on information provided in the documents. Take annual statements, for example. Companies worldwide are obliged to publish these statements and company finances are to be audited. Going through such documents is time-consuming. Take an annual statement in¬†<strong>PDF document</strong>¬†format. Can we help employees formulate answers based on this document faster?</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption><span>An entire annual report document of 382 pages fits in the model context at once, allowing the model to answer questions considering the¬†</span><i><em class="italic">whole</em></i><span>¬†document. Reasoning-type of questions like audit questionnaires can now be answered by LLMs, citing where the answer is located. The human gets a head start and then only has to check and extend the answers, saving time.¬†See¬†</span><a href="https://github.com/xebia/genai-data-extraction/blob/main/notebooks/annual_report_audit.ipynb" rel="noopener"><span>Code</span></a><span>.</span></figcaption></figure><p>Yes. The document fits in the model context¬†<em>all at once</em>, allowing the model to take a comprehensive view of the document and formulate sensible answers. In fact, LLMs like Google‚Äôs Gemini models take up to 2 million tokens in context at once¬†<a href="https://ai.google.dev/gemini-api/docs/long-context" rel="noopener"><sup>[ref]</sup></a>. This allows for up to 3,000 PDF pages to be inserted into the prompt. PDF pages are processed as images by Gemini¬†<a href="https://ai.google.dev/gemini-api/docs/vision?lang=python" rel="noopener"><sup>[ref]</sup></a>.</p><p>Answering these questions took Gemini 2.0 Flash just under 1 minute and cost $0.015 . How long would a human take?</p><h3 id="customer-service-calls-audio">Customer service calls (audio)</h3><p>Imagine you have a customer service department and are processing many calls on the daily. The customer service agents do their best to document and record useful information during the call but cannot possibly document all valuable information. Calls are temporarily recorded for analytical purposes. Calls could be listened back to figure out the customer problem, the root cause, the solution and the customer sentiment. This information is valuable to have because this is necessary feedback information to improve customer service in a targeted way. What issues were we most often unable to resolve? In what situations are our customers left unhappy?</p><p>The insights are valuable, but hard to get to. The data is hidden in an¬†<strong>audio format</strong>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption><span>LLMs can listen to audio quicker than any human. Customer service calls can be analysed and previously-inaccessible but valuable information can be extracted and taken advantage of. Insights can be gathered in automated fashion, effectively improving business processes in targeted fashion.¬†See¬†</span><a href="https://github.com/xebia/genai-data-extraction/blob/main/notebooks/annual_report_audit.ipynb" rel="noopener"><span>Code</span></a><span>.</span></figcaption></figure><p>Gemini 2.0 Flash processed this 5-minute customer service call in 3 seconds and spent $0.0083. That is faster than any human takes to listen- and process the call. LLMs can also accurately process audio, without the need for a transcription step first. Because the model is exposed to the raw audio file, more than just the words that are spoken can be taken into account. In what¬†<em>way</em>¬†is this customer talking? Is this customer happy or unhappy? Off-the-shelf LLMs can be used without modification and just by prompting to extract structured data from audio¬†<a href="https://ai.google.dev/gemini-api/docs/audio?lang=python" rel="noopener"><sup>[ref]</sup></a>.</p><p>Concluding on the 4 usecase examples, we learned the following.</p><ul><li><strong>LLMs for data extraction</strong>: LLMs can be used to extract structured data from free-form formats like text, images, PDFs, and audio.</li><li><strong>Larger contexts</strong>: Growing LLM context windows allow processing of larger documents at once. This strengthens the applicability for data extraction using LLMs without the need for extra retrieval steps.</li><li><strong>Competitive pricing</strong>: Lower inference costs make more data extraction use cases feasible.</li><li><strong>GenAI data extraction ROI</strong>: LLMs can complete data extraction tasks faster than humans and at a lower cost. Albeit not at perfection, the goal is to create a system that is good enough to assist humans in their work and provide business value.</li></ul><p>That is really cool. LLMs are becoming more capable and cheaper, making possible more usecases than before. So now what exactly is this data extraction? How can we use this to our advantage to automate business processes? What are¬†<strong>the automation levels</strong>¬†for data extraction?</p><h2 id="2-the-automation-levels">2. The automation levels</h2><p>To discover what is possible with GenAI data extraction, we will divide into 4 levels of increasing automation.</p><ul><li><strong>Level 0: Manual</strong></li><li><strong>Level 1: Assisted</strong></li><li><strong>Level 2: Autopilot</strong></li><li><strong>Level 3: Autonomous</strong></li></ul><h3 id="level-0-manual-work">Level 0: Manual work</h3><p>No automation is applied. Human labor is required to extract data in the desired format. The extracted data is then consumed by a human user. All of the data extraction-, evaluation of the data quality and any actions to be done with the data are manual human processes.</p><figure class="kg-card kg-image-card"></figure><p>Without automation, manual work is required to extract data in structured format. After extraction humans decide on what to do with the data.</p><p>We can do better. LLMs can be used to automate part of this process, helping the human in the¬†<strong>Assisted</strong>automation level.</p><h3 id="level-1-assisted">Level 1: Assisted</h3><p>In the assisted workflow, a LLM is used to extract useful data. This process we like to call¬†<strong>Structured Data Extraction</strong>.</p><figure class="kg-card kg-image-card"></figure><p>LLMs can be used for structured data extraction: extracting useful data from free-form documents in structured format.</p><p>That can already save a lot of time. Previously we needed to manually perform the tedious process of processing the document to formulate answers in the target format. In this level of automation, though, we are still targeting a human user as output. The human user is responsible for all of evaluating the LLM output and deciding what to do with the data. This gives the human control but also costs extra time. We can do better in¬†<strong>Autopilot</strong>.</p><h3 id="level-2-autopilot">Level 2: Autopilot</h3><p>In the autopilot workflow we go a step further. The extracted data is directly ingested in a¬†<strong>Data Warehouse</strong>, opening up new automation possibilities. With the data in the data warehouse the data can be more efficiently taken advantage of. We can now use the data for dashboards and insights as well as use the data for Machine Learning usecases.</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption><span>When extracted data is ingested into a Data Warehouse the data can be more efficiently taken advantage of. Dashboards can reveal new insights and ML usecases can benefit from richer available data.</span></figcaption></figure><p>Ingesting this data directly into a Data Warehouse can be beneficial indeed. But with the introduction of this automated ingestion we also need to be careful. Data Warehouse consumers are farther away from the extraction process and are not aware of the data quality. We need to always ask ourselves: Is this data reliable?</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption><span>Data Warehouse consumers need to always be aware of data- quality and reliability.</span></figcaption></figure><p>Bad data quality can lead to misleading insights and bad decisions later down. This is not what we want! Quantified metrics informing us on the data reliability are required. Those with expertise in the dataset and those involved in the extraction process will need to help out. These are typically an AI Engineer and a Subject Matter Expert. We need to introduce an¬†<strong>evaluation</strong>¬†step.</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption><span>A Subject Matter Expert is required to label samples of data, informing Data Warehouse consumers and engineers on the data reliability. The Subject Matter Expert is to be enabled to also experiment with the data extraction process, lowering iteration times.</span></figcaption></figure><p>More steps are introduced, keeping the human-in-the-loop. The steps are necessary, though. The Subject Matter Expert plays a key role in ensuring the quality- and reliability of the data. This gives Data Warehouse consumers the trust they are looking for and at the same time enables the AI Engineer to more systematically improve the Structured Data Extraction system. Additionally, enabling the Subject Matter Expert themselves to be part of the prompting process lowers iteration times and reduces context being lost in translation between AI Engineer and Subject Matter Expert. Win-win.</p><p>We can go more automated, even. Let‚Äôs continue to the last level:¬†<strong>Autonomous</strong>.</p><h3 id="level-3-autonomous">Level 3: Autonomous</h3><p>In this level, the last human interactions are ought to be automated. Evaluation previously manually done by the Subject Matter Expert is now done by¬†<strong>Quality Assurance- and evaluation</strong>¬†tooling.</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption><span>Introducing Quality Assurance- and evaluation tooling allows the Structured Data Extraction system to run fully autonomous.</span></figcaption></figure><p>So what do we mean with such tooling? We want tooling to help us guarantee the outcome and quality of our data without minimal human intervention. This can be¬†<a href="https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge" rel="noopener">LLM-as-a-judge systems</a>, for example. The required effort, however, to successfully implement such systems and run them safely is high. One gets value in return, from extra automation, but whether this is worth the effort- and cost is the question. Let‚Äôs compare the automation levels and summarise its potential.</p><h2 id="3-the-automation-potential">3. The automation potential</h2><p>We have learned about each of the four different levels of automation for data extraction using GenAI. Also, for each level, we have explored how architecturally a Structured Data Extraction system would look like. That is great, but now where is most potential? Let‚Äôs first summarise the automation levels as follows:</p>

<table><caption class="text-center text-grey-500 text-sm">The Automation Levels for GenAI data extraction.</caption><thead><tr><th>Level</th><th>Automation</th><th>Description</th><th>Human-in-the-loop</th></tr></thead><tbody><tr><td>0</td><td><b>Manual</b></td><td>Human performs all work.<br /><small>Human responsible for data extraction, quality assurance and consumption of data.</small></td><td>Yes</td></tr><tr><td>1</td><td><b>Assisted</b></td><td>Human is assisted with tasks but still in control and responsible.<br /><small>Data is extracted using a LLM. Extracted data is used to assist human users.</small></td><td>Yes</td></tr><tr><td>2</td><td><b>Autopilot</b></td><td>Tasks largely automated ‚Äì human supervises.<br /><small>Extracted data is upserted directly into a Data Warehouse. Systematic evaluation is necessary and Subject Matter Expert involvement is key.</small></td><td>Yes</td></tr><tr><td>3</td><td><b>Autonomous</b></td><td>Tasks fully automated.<br /><small>Evaluation step is to be automated using Quality Assurance- and evaluation tooling. Fully automated pipelines: no human intervention or supervision.</small></td><td>No</td></tr></tbody></table>

<p>So say you are thinking about implementing a data extraction usecase. What is the ultimate goal? The ultimate goal need not always be to automate as much as possible: it should be to create value. Because perhaps, you can benefit largely enough from your usecase if Assisted- or Autopilot automation is applied and the extra investment to full automation is not worth it. If we were to take the menu card example from earlier, how would potential time savings look like?</p><p><strong>Time savings for automating data extraction</strong>¬†(example):¬†<br />30 minutes (manual) ‚Üí 5 minutes (assisted) ‚Üí 1 minute (autopilot) ‚Üí 0 minutes (autonomous).</p><p>We can see that the time savings are not linear. The more automation we apply, the less time we save. Even though, the last step is the hardest and most expensive to implement. It is not always worth the effort and cost to implement this last step. These are the¬†<strong>Diminishing Returns</strong>¬†of automation, which can be plotted as follows:</p><figure class="kg-card kg-image-card"></figure><p>Automation is nice but value is the goal. Take automation step-by-step. Partial automation is also valuable.</p><p></p><p>Let‚Äôs sum things up. To conclude, GenAI for data extraction is:</p><ul><li>Useful for a wide variety of usecases with various data types including text, images, PDFs and audio.</li><li>More likely to provide ROI due to 1) cheaper models, 2) larger context windows and 3) more capable models able to process multi-modal data.</li><li>Very well suited for¬†<em>partial automation</em>: which can bring business value without needing extra investment for full automation.</li></ul><p>Good luck with your own GenAI data extraction usecases üçÄ‚ô°.</p>

            </section>

        </article>
    </main>
    <footer class="page-footer">
            <amp-img class="site-icon" src="https://jeroenoverschie.nl/content/images/2022/10/cartoon-head-jeroen-1-2.svg" width="50" height="50" layout="fixed" alt="Jeroen Overschie"></amp-img>
        <h3>Jeroen Overschie</h3>
            <p>I&#x27;m Jeroen üëãüèª</p>
        <p><a href="https://jeroenoverschie.nl">Read more posts ‚Üí</a></p>
        <a class="powered" href="https://ghost.org" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 156 156"><g fill="none" fill-rule="evenodd"><rect fill="#15212B" width="156" height="156" rx="27"/><g transform="translate(36 36)" fill="#F6F8FA"><path d="M0 71.007A4.004 4.004 0 014 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0130 84H4a4 4 0 01-4-4.007v-8.986zM50 71.007A4.004 4.004 0 0154 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0180 84H54a4 4 0 01-4-4.007v-8.986z"/><rect y="34" width="84" height="17" rx="4"/><path d="M0 4.007A4.007 4.007 0 014.007 0h41.986A4.003 4.003 0 0150 4.007v8.986A4.007 4.007 0 0145.993 17H4.007A4.003 4.003 0 010 12.993V4.007z"/><rect x="67" width="17" height="17" rx="4"/></g></g></svg> Published with Ghost</a>
    </footer>
    
</body>
</html>
