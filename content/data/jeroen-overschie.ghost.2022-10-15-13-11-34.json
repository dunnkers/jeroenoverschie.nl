{"meta":{"exported_on":1665839494852,"version":"5.19.0"},"data":{"newsletters":[{"id":"62a48eba9cd77522dc21c094","uuid":"5a037ed9-61d7-4dfe-ba69-a37c1aaf5d6d","name":"Jeroen Overschie","description":null,"slug":"default-newsletter","sender_name":null,"sender_email":null,"sender_reply_to":"newsletter","status":"active","visibility":"members","subscribe_on_signup":1,"sort_order":0,"header_image":null,"show_header_icon":1,"show_header_title":1,"title_font_category":"sans_serif","title_alignment":"center","show_feature_image":1,"body_font_category":"sans_serif","footer_content":null,"show_badge":1,"show_header_name":0,"created_at":"2022-06-11 12:46:50","updated_at":"2022-06-11 12:47:41"}],"posts":[{"id":"62a48eba9cd77522dc21c0f8","uuid":"1f68f58e-8edb-40bd-aa81-ee5597b06f17","title":"About this site","slug":"about","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"hr\",{}]],\"markups\":[[\"a\",[\"href\",\"https://ghost.org\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Jeroen Overschie is an independent publication launched in June 2022 by Jeroen Overschie. If you subscribe today, you'll get full access to the website as well as email newsletters about new content when it's available. Your subscription makes this site possible, and allows Jeroen Overschie to continue to exist. Thank you!\"]]],[1,\"h3\",[[0,[],0,\"Access all areas\"]]],[1,\"p\",[[0,[],0,\"By signing up, you'll get access to the full archive of everything that's been published before and everything that's still to come. Your very own private library.\"]]],[1,\"h3\",[[0,[],0,\"Fresh content, delivered\"]]],[1,\"p\",[[0,[],0,\"Stay up to date with new content sent straight to your inbox! No more worrying about whether you missed something because of a pesky algorithm or news feed.\"]]],[1,\"h3\",[[0,[],0,\"Meet people like you\"]]],[1,\"p\",[[0,[],0,\"Join a community of other subscribers who share the same interests.\"]]],[10,0],[1,\"h3\",[[0,[],0,\"Start your own thing\"]]],[1,\"p\",[[0,[],0,\"Enjoying the experience? Get started for free and set up your very own subscription business using \"],[0,[0],1,\"Ghost\"],[0,[],0,\", the same platform that powers this website.\"]]]],\"ghostVersion\":\"4.0\"}","html":"<p>Jeroen Overschie is an independent publication launched in June 2022 by Jeroen Overschie. If you subscribe today, you'll get full access to the website as well as email newsletters about new content when it's available. Your subscription makes this site possible, and allows Jeroen Overschie to continue to exist. Thank you!</p><h3 id=\"access-all-areas\">Access all areas</h3><p>By signing up, you'll get access to the full archive of everything that's been published before and everything that's still to come. Your very own private library.</p><h3 id=\"fresh-content-delivered\">Fresh content, delivered</h3><p>Stay up to date with new content sent straight to your inbox! No more worrying about whether you missed something because of a pesky algorithm or news feed.</p><h3 id=\"meet-people-like-you\">Meet people like you</h3><p>Join a community of other subscribers who share the same interests.</p><hr><h3 id=\"start-your-own-thing\">Start your own thing</h3><p>Enjoying the experience? Get started for free and set up your very own subscription business using <a href=\"https://ghost.org\">Ghost</a>, the same platform that powers this website.</p>","comment_id":"62a48eba9cd77522dc21c0f8","plaintext":"Jeroen Overschie is an independent publication launched in June 2022 by Jeroen Overschie. If you subscribe today, you'll get full access to the website as well as email newsletters about new content when it's available. Your subscription makes this site possible, and allows Jeroen Overschie to continue to exist. Thank you!\n\n\nAccess all areas\n\nBy signing up, you'll get access to the full archive of everything that's been published before and everything that's still to come. Your very own private library.\n\n\nFresh content, delivered\n\nStay up to date with new content sent straight to your inbox! No more worrying about whether you missed something because of a pesky algorithm or news feed.\n\n\nMeet people like you\n\nJoin a community of other subscribers who share the same interests.\n\n\nStart your own thing\n\nEnjoying the experience? Get started for free and set up your very own subscription business using Ghost, the same platform that powers this website.","feature_image":null,"featured":0,"type":"page","status":"published","locale":null,"visibility":"public","email_recipient_filter":"all","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:47:41","updated_by":"62a48eba9cd77522dc21c0f8","published_at":"2022-06-11 12:46:51","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c274","uuid":"e3fff64d-66ca-4132-978e-894f2b2b7a1e","title":"Contact","slug":"contact","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/github32-2.png\",\"width\":32,\"height\":32,\"caption\":\"<a href=\\\"https://github.com/dunnkers\\\">github.com/dunnkers</a>\",\"href\":\"https://github.com/dunnkers\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/SU001-Sticker-LinkedIn-logo-uitgesneden.png\",\"width\":32,\"height\":32,\"caption\":\"<a href=\\\"https://linkedin.com/in/jeroenoverschie\\\">linkedin.com/in/jeroenoverschie</a>\",\"href\":\"https://linkedin.com/in/jeroenoverschie\"}]],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"‚Äã‚ÄãHi! I am Jeroen. I hold a Masters in Data Science and Systems Complexity, obtained at the University of Groningen. I have experience in Web Development and Data Science. Feel free to shoot me a message if you would like to learn more.\"]]],[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>‚Äã‚ÄãHi! I am Jeroen. I hold a Masters in Data Science and Systems Complexity, obtained at the University of Groningen. I have experience in Web Development and Data Science. Feel free to shoot me a message if you would like to learn more.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><a href=\"https://github.com/dunnkers\"><img src=\"__GHOST_URL__/content/images/2021/11/github32-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"32\" height=\"32\"></a><figcaption><a href=\"https://github.com/dunnkers\">github.com/dunnkers</a></figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><a href=\"https://linkedin.com/in/jeroenoverschie\"><img src=\"__GHOST_URL__/content/images/2021/11/SU001-Sticker-LinkedIn-logo-uitgesneden.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"32\" height=\"32\"></a><figcaption><a href=\"https://linkedin.com/in/jeroenoverschie\">linkedin.com/in/jeroenoverschie</a></figcaption></figure>","comment_id":"61a0cd6372c7ac1e20461f77","plaintext":"Hi! I am Jeroen. I hold a Masters in Data Science and Systems Complexity, obtained at the University of Groningen. I have experience in Web Development and Data Science. Feel free to shoot me a message if you would like to learn more.","feature_image":null,"featured":0,"type":"page","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","created_at":"2021-11-26 12:04:51","created_by":"1","updated_at":"2021-12-18 19:54:00","updated_by":null,"published_at":"2021-11-26 12:05:17","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c275","uuid":"50ddcc96-fd94-4a6e-9823-66a18b626b81","title":"Automated curtains project","slug":"automated-curtains","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/SOMFY-TELIS-1-RTS-old.jpeg\",\"width\":300,\"height\":300,\"caption\":\"My curtain remote. The goal is to emulate whatever signal it is sending to the curtains using a Raspberry Pi.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/Photo-from-Jeroen-Overschie-3.png\",\"width\":1000,\"height\":600,\"caption\":\"The RF emitter on the left and a replacement part for changing its oscillator frequency on the right.\",\"cardWidth\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/Screen-Shot-2021-11-26-at-14.49.31.png\",\"width\":1008,\"height\":942,\"cardWidth\":\"\",\"caption\":\"The fully assembled Raspberry Pi, with its RF emitter attached via a cable.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/image00003.jpeg\",\"width\":540,\"height\":720,\"cardWidth\":\"\",\"caption\":\"Assembled Raspberry Pi RF transmitter, with enclosure.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/p3.png\",\"width\":982,\"height\":545,\"caption\":\"The Pi-Somfy interface. One can easily connect to a web server running on the Pi if on the same network, allowing me to configure the alarms even on my phone.\"}],[\"image\",{\"caption\":\"Opening my curtains using the Raspberry Pi and its RF sensor.\",\"src\":\"__GHOST_URL__/content/images/2021/11/ezgif-2-a5aab328d979.gif\",\"width\":320,\"height\":569}]],\"markups\":[[\"em\"],[\"a\",[\"href\",\"https://github.com/Nickduino/Pi-Somfy\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"An idea sprung up in my mind some while ago. In my student dorm, I have electric curtains. They can be operated using a little remote, allowing one to open or close the curtains. This is pretty useful, because I don't even have to get out of bed to open my curtains ‚Äì I can just use the remote. But the remote uses radio waves to operate the curtains - and I have a Raspberry Pi laying around, doing nothing. What if I could operate the curtains using my Raspberry Pi? Such, that the curtains open at a certain time in the morning. In this way, my curtains would function as an alarm clock! In this project, I did exactly that üòâ.\"]]],[1,\"h3\",[[0,[],0,\"How\"]]],[1,\"p\",[[0,[],0,\"First, I have to figure out at all how to do this. Taking a look at the curtain remote, I found the brand to be '\"],[0,[0],1,\"Somfy'\"],[0,[],0,\". After some Google image searches I found the name of my remote model, the Somfy Telis 1-RTS:\"]]],[10,0],[1,\"p\",[[0,[],0,\"I want to emulate the RF (Radio Frequency) signal the remote is emitting. Such that, instead of pressing a button on the remote, I can control the curtains programmatically using code. Then, because the Raspberry Pi will always be on, I can configure certain times to open/close the curtains.\"]]],[1,\"p\",[[0,[],0,\"But surely, other people have wanted to do this too. Somfy is a popular brand for electric curtains after all. So, I searched, and found \"],[0,[1],1,\"Github project\"],[0,[],0,\" containing code to control the curtains using a Raspberry Pi, if correctly assembled. Let's start!\"]]],[1,\"h3\",[[0,[],0,\"Preparation\"]]],[1,\"p\",[[0,[],0,\"I need a couple things to make this work.\"]]],[3,\"ol\",[[[0,[],0,\"Raspberry Pi (I am using a Raspberry Pi 2011 edition - Model B)\"]],[[0,[],0,\"RF (Radio Frequency) transmitter (with an oscillator at 433.42 Mhz)\"]],[[0,[],0,\"Cables to connect the RF emitter to the Raspberry Pi\"]]]],[1,\"p\",[[0,[],0,\"Most parts could easily be ordered through Ebay. However, Somfy did something smart in their product. They intentionally set their oscillator frequency to an odd number, 433.42 Mhz. Most other RF emitters run at 433.93 Mhz. There are, luckily, some places you can order a 433.42 oscillator. But only the oscillator. This means we are going to have to do some soldering to replace the oscillator. After a couple weeks, my parts arrived.\"]]],[10,1],[1,\"h3\",[[0,[],0,\"Building the Pi emitter\"]]],[1,\"p\",[[0,[],0,\"My friend happened to possess a soldering set, so after a quick visit I managed to solder the correct oscillator onto the RF emitter board.  Using a set of cables, I could attach the RF transmitter to the Raspberry Pi üôåüèª.\"]]],[10,2],[1,\"p\",[[0,[],0,\"I also bought an extra enclosure to keep the thing a bit more safe:\"]]],[10,3],[1,\"p\",[[0,[],0,\"Now all there's left is configure the correct software on the Raspberry Pi. Using the Github project I found, I was able to install the software and make the software automatically start on a reboot. It has a pretty neat interface, allowing one to set CRON jobs to open/close the curtains. In non-nerd speech we would just call this 'an alarm' üòÖ.\"]]],[10,4],[1,\"p\",[[0,[],0,\"I now just had to execute a certain pattern of button presses to emulate pairing a new remote. And then ... it worked! üéâ\"]]],[10,5],[1,\"p\",[[0,[],0,\"Now, I can go to sleep in darkness, and wake up with sunlight hitting my face üåû. Awesome! The project has succeeded and the cool thing is I have been using this every day ever since. The cool thing about doing a Computer Science degree is when you can apply your knowledge to solve real-world problems. When I leave this student dormitory, I will leave the Raspberry Pi right where it is, so others can also benefit from automated curtains üòä. Cheers!\"]]]],\"ghostVersion\":\"4.0\"}","html":"<p>An idea sprung up in my mind some while ago. In my student dorm, I have electric curtains. They can be operated using a little remote, allowing one to open or close the curtains. This is pretty useful, because I don't even have to get out of bed to open my curtains ‚Äì I can just use the remote. But the remote uses radio waves to operate the curtains - and I have a Raspberry Pi laying around, doing nothing. What if I could operate the curtains using my Raspberry Pi? Such, that the curtains open at a certain time in the morning. In this way, my curtains would function as an alarm clock! In this project, I did exactly that üòâ.</p><h3 id=\"how\">How</h3><p>First, I have to figure out at all how to do this. Taking a look at the curtain remote, I found the brand to be '<em>Somfy'</em>. After some Google image searches I found the name of my remote model, the Somfy Telis 1-RTS:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/SOMFY-TELIS-1-RTS-old.jpeg\" class=\"kg-image\" alt loading=\"lazy\" width=\"300\" height=\"300\"><figcaption>My curtain remote. The goal is to emulate whatever signal it is sending to the curtains using a Raspberry Pi.</figcaption></figure><p>I want to emulate the RF (Radio Frequency) signal the remote is emitting. Such that, instead of pressing a button on the remote, I can control the curtains programmatically using code. Then, because the Raspberry Pi will always be on, I can configure certain times to open/close the curtains.</p><p>But surely, other people have wanted to do this too. Somfy is a popular brand for electric curtains after all. So, I searched, and found <a href=\"https://github.com/Nickduino/Pi-Somfy\">Github project</a> containing code to control the curtains using a Raspberry Pi, if correctly assembled. Let's start!</p><h3 id=\"preparation\">Preparation</h3><p>I need a couple things to make this work.</p><ol><li>Raspberry Pi (I am using a Raspberry Pi 2011 edition - Model B)</li><li>RF (Radio Frequency) transmitter (with an oscillator at 433.42 Mhz)</li><li>Cables to connect the RF emitter to the Raspberry Pi</li></ol><p>Most parts could easily be ordered through Ebay. However, Somfy did something smart in their product. They intentionally set their oscillator frequency to an odd number, 433.42 Mhz. Most other RF emitters run at 433.93 Mhz. There are, luckily, some places you can order a 433.42 oscillator. But only the oscillator. This means we are going to have to do some soldering to replace the oscillator. After a couple weeks, my parts arrived.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/Photo-from-Jeroen-Overschie-3.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1000\" height=\"600\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/Photo-from-Jeroen-Overschie-3.png 600w, __GHOST_URL__/content/images/2021/11/Photo-from-Jeroen-Overschie-3.png 1000w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The RF emitter on the left and a replacement part for changing its oscillator frequency on the right.</figcaption></figure><h3 id=\"building-the-pi-emitter\">Building the Pi emitter</h3><p>My friend happened to possess a soldering set, so after a quick visit I managed to solder the correct oscillator onto the RF emitter board. ¬†Using a set of cables, I could attach the RF transmitter to the Raspberry Pi üôåüèª.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/Screen-Shot-2021-11-26-at-14.49.31.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1008\" height=\"942\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/Screen-Shot-2021-11-26-at-14.49.31.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/Screen-Shot-2021-11-26-at-14.49.31.png 1000w, __GHOST_URL__/content/images/2021/11/Screen-Shot-2021-11-26-at-14.49.31.png 1008w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The fully assembled Raspberry Pi, with its RF emitter attached via a cable.</figcaption></figure><p>I also bought an extra enclosure to keep the thing a bit more safe:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/image00003.jpeg\" class=\"kg-image\" alt loading=\"lazy\" width=\"540\" height=\"720\"><figcaption>Assembled Raspberry Pi RF transmitter, with enclosure.</figcaption></figure><p>Now all there's left is configure the correct software on the Raspberry Pi. Using the Github project I found, I was able to install the software and make the software automatically start on a reboot. It has a pretty neat interface, allowing one to set CRON jobs to open/close the curtains. In non-nerd speech we would just call this 'an alarm' üòÖ.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/p3.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"982\" height=\"545\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/p3.png 600w, __GHOST_URL__/content/images/2021/11/p3.png 982w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The Pi-Somfy interface. One can easily connect to a web server running on the Pi if on the same network, allowing me to configure the alarms even on my phone.</figcaption></figure><p>I now just had to execute a certain pattern of button presses to emulate pairing a new remote. And then ... it worked! üéâ</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/ezgif-2-a5aab328d979.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"320\" height=\"569\"><figcaption>Opening my curtains using the Raspberry Pi and its RF sensor.</figcaption></figure><p>Now, I can go to sleep in darkness, and wake up with sunlight hitting my face üåû. Awesome! The project has succeeded and the cool thing is I have been using this every day ever since. The cool thing about doing a Computer Science degree is when you can apply your knowledge to solve real-world problems. When I leave this student dormitory, I will leave the Raspberry Pi right where it is, so others can also benefit from automated curtains üòä. Cheers!</p>","comment_id":"61a0e5ee72c7ac1e20461f81","plaintext":"An idea sprung up in my mind some while ago. In my student dorm, I have electric curtains. They can be operated using a little remote, allowing one to open or close the curtains. This is pretty useful, because I don't even have to get out of bed to open my curtains ‚Äì I can just use the remote. But the remote uses radio waves to operate the curtains - and I have a Raspberry Pi laying around, doing nothing. What if I could operate the curtains using my Raspberry Pi? Such, that the curtains open at a certain time in the morning. In this way, my curtains would function as an alarm clock! In this project, I did exactly that üòâ.\n\n\nHow\n\nFirst, I have to figure out at all how to do this. Taking a look at the curtain remote, I found the brand to be 'Somfy'. After some Google image searches I found the name of my remote model, the Somfy Telis 1-RTS:\n\nI want to emulate the RF (Radio Frequency) signal the remote is emitting. Such that, instead of pressing a button on the remote, I can control the curtains programmatically using code. Then, because the Raspberry Pi will always be on, I can configure certain times to open/close the curtains.\n\nBut surely, other people have wanted to do this too. Somfy is a popular brand for electric curtains after all. So, I searched, and found Github project containing code to control the curtains using a Raspberry Pi, if correctly assembled. Let's start!\n\n\nPreparation\n\nI need a couple things to make this work.\n\n 1. Raspberry Pi (I am using a Raspberry Pi 2011 edition - Model B)\n 2. RF (Radio Frequency) transmitter (with an oscillator at 433.42 Mhz)\n 3. Cables to connect the RF emitter to the Raspberry Pi\n\nMost parts could easily be ordered through Ebay. However, Somfy did something smart in their product. They intentionally set their oscillator frequency to an odd number, 433.42 Mhz. Most other RF emitters run at 433.93 Mhz. There are, luckily, some places you can order a 433.42 oscillator. But only the oscillator. This means we are going to have to do some soldering to replace the oscillator. After a couple weeks, my parts arrived.\n\n\nBuilding the Pi emitter\n\nMy friend happened to possess a soldering set, so after a quick visit I managed to solder the correct oscillator onto the RF emitter board. ¬†Using a set of cables, I could attach the RF transmitter to the Raspberry Pi üôåüèª.\n\nI also bought an extra enclosure to keep the thing a bit more safe:\n\nNow all there's left is configure the correct software on the Raspberry Pi. Using the Github project I found, I was able to install the software and make the software automatically start on a reboot. It has a pretty neat interface, allowing one to set CRON jobs to open/close the curtains. In non-nerd speech we would just call this 'an alarm' üòÖ.\n\nI now just had to execute a certain pattern of button presses to emulate pairing a new remote. And then ... it worked! üéâ\n\nNow, I can go to sleep in darkness, and wake up with sunlight hitting my face üåû. Awesome! The project has succeeded and the cool thing is I have been using this every day ever since. The cool thing about doing a Computer Science degree is when you can apply your knowledge to solve real-world problems. When I leave this student dormitory, I will leave the Raspberry Pi right where it is, so others can also benefit from automated curtains üòä. Cheers!","feature_image":"__GHOST_URL__/content/images/2021/11/automated-curtains-cover-2.png","featured":1,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","created_at":"2021-11-26 13:49:34","created_by":"1","updated_at":"2021-11-29 23:29:53","updated_by":null,"published_at":"2020-02-09 23:00:00","published_by":"1","custom_excerpt":"My electric curtains can already be controlled by a remote. It would be cool if they could open in the morning, like an alarm clock. What if I could do this using a Raspberry Pi, by emulating the remote?","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c276","uuid":"63cbb582-3d59-4940-8d39-55dc124f8bfe","title":"School break time friend finder","slug":"school-breaktime-friend-finder","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"html\",{\"html\":\"<figure class=\\\"kg-card kg-image-card kg-card-hascaption\\\">\\n    <img src=\\\"__GHOST_URL__/content/images/2022/01/PWS-roosters-infrastructuur.svg\\\" class=\\\"kg-image\\\" alt=\\\"An overview of the app architecture. A Node.js app scrapes and parses student schedules, puts it in a database, which an Ember.js app then consumes through a REST API.\\\" loading=\\\"lazy\\\">\\n    <figcaption>An overview of the app architecture. A Node.js app scrapes and parses student schedules, puts it in a database, which an Ember.js app then consumes through a REST API.</figcaption>\\n</figure>\"}],[\"html\",{\"html\":\"<figure class=\\\"kg-card kg-image-card kg-card-hascaption\\\">\\n    <img src=\\\"__GHOST_URL__/content/images/2022/01/PWS-Roosters-ORM---Object-Relational-Mapping.svg\\\" class=\\\"kg-image\\\" alt=\\\"An Object-Relational-Mapping (ORM) of the school. Most important is a lesson, which then relates teachers, students and a room.\\\" loading=\\\"lazy\\\">\\n    <figcaption>An Object-Relational-Mapping (ORM) of the school. Most important is a lesson, which then relates teachers, students and a room.</figcaption>\\n</figure>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/01/Screen-Shot-2022-01-06-at-13.53.37.png\",\"width\":626,\"height\":445,\"caption\":\"The working break-time friend finder app. Using a simple search, a student can find his schedule.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/01/Screen-Shot-2022-01-06-at-13.52.57.png\",\"width\":609,\"height\":290,\"caption\":\"In the app, you can click any class or break to see with whom you share the hour. It's no longer a guessing game! ‚úì\"}]],\"markups\":[[\"a\",[\"href\",\"https://github.com/dunnkers/roosters-api\"]],[\"a\",[\"href\",\"https://cheerio.js.org/\"]],[\"a\",[\"href\",\"https://github.com/mongo-js/mongojs\"]],[\"a\",[\"href\",\"https://github.com/dunnkers/roosters\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"At my school, students often had gaps in their schedules. In between lessons scheduled for the day, one would often have breaks in between. But because you chose a personalized package of classes to follow, everyone's schedule was also different. So, it would be hard to know with whom you could spend those breaks! To solve this, I developed this app. It allows students to find with whom they have breaks so they can hang out with them whilst waiting for the next class üòä. The app was actually used by students in my school. Very cool! \"]]],[1,\"h3\",[[0,[],0,\"Building the app\"]]],[1,\"p\",[[0,[],0,\"The entire app is quite sophisticated. The various components can be laid out as follows:\"]]],[3,\"ul\",[[[0,[],0,\"Node.js backend (\"],[0,[0],1,\"Github\"],[0,[],0,\")\"],[1,[],0,0],[0,[],0,\"- Has three main responsibilities:\"],[1,[],0,1],[0,[],0,\"(1) to scrape student schedules off HTML pages into a MongoDB database. Scraping is done using \"],[0,[1],1,\"Cheerio\"],[0,[],0,\" and communication with MongoDB via \"],[0,[2],1,\"MongoJS\"],[0,[],0,\".\"],[1,[],0,2],[0,[],0,\"(2) parse the schedules into a relational format and compute what odd break-time hours exist.\"],[1,[],0,3],[0,[],0,\"(3) expose the MongoDB database as an API.\"]],[[0,[],0,\"Ember.js frontend (\"],[0,[3],1,\"Github\"],[0,[],0,\")\"],[1,[],0,4],[0,[],0,\"- This front-end then consumes the API data using ember-data. I'm using Bootstrap as a UI framework so I don't have to build all the buttons, tables and interfacing myself.\"]]]],[1,\"p\",[]],[10,0],[1,\"p\",[[0,[],0,\"... the relational mapping in the database is as follows:\"]]],[10,1],[1,\"p\",[[0,[],0,\"And our working app looks as follows:\"]]],[10,2],[1,\"p\",[[0,[],0,\"But most importantly, the functionality to see whoever shares your break-time ('tussen' in the picture below) or any classes with you:\"]]],[10,3],[1,\"p\",[[0,[],0,\"ü•≥\"]]],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>At my school, students often had gaps in their schedules. In between lessons scheduled for the day, one would often have breaks in between. But because you chose a personalized package of classes to follow, everyone's schedule was also different. So, it would be hard to know with whom you could spend those breaks! To solve this, I developed this app. It allows students to find with whom they have breaks so they can hang out with them whilst waiting for the next class üòä. The app was actually used by students in my school. Very cool! </p><h3 id=\"building-the-app\">Building the app</h3><p>The entire app is quite sophisticated. The various components can be laid out as follows:</p><ul><li>Node.js backend (<a href=\"https://github.com/dunnkers/roosters-api\">Github</a>)<br>- Has three main responsibilities:<br>(1) to scrape student schedules off HTML pages into a MongoDB database. Scraping is done using <a href=\"https://cheerio.js.org/\">Cheerio</a> and communication with MongoDB via <a href=\"https://github.com/mongo-js/mongojs\">MongoJS</a>.<br>(2) parse the schedules into a relational format and compute what odd break-time hours exist.<br>(3) expose the MongoDB database as an API.</li><li>Ember.js frontend (<a href=\"https://github.com/dunnkers/roosters\">Github</a>)<br>- This front-end then consumes the API data using ember-data. I'm using Bootstrap as a UI framework so I don't have to build all the buttons, tables and interfacing myself.</li></ul><p></p><!--kg-card-begin: html--><figure class=\"kg-card kg-image-card kg-card-hascaption\">\n    <img src=\"__GHOST_URL__/content/images/2022/01/PWS-roosters-infrastructuur.svg\" class=\"kg-image\" alt=\"An overview of the app architecture. A Node.js app scrapes and parses student schedules, puts it in a database, which an Ember.js app then consumes through a REST API.\" loading=\"lazy\">\n    <figcaption>An overview of the app architecture. A Node.js app scrapes and parses student schedules, puts it in a database, which an Ember.js app then consumes through a REST API.</figcaption>\n</figure><!--kg-card-end: html--><p>... the relational mapping in the database is as follows:</p><!--kg-card-begin: html--><figure class=\"kg-card kg-image-card kg-card-hascaption\">\n    <img src=\"__GHOST_URL__/content/images/2022/01/PWS-Roosters-ORM---Object-Relational-Mapping.svg\" class=\"kg-image\" alt=\"An Object-Relational-Mapping (ORM) of the school. Most important is a lesson, which then relates teachers, students and a room.\" loading=\"lazy\">\n    <figcaption>An Object-Relational-Mapping (ORM) of the school. Most important is a lesson, which then relates teachers, students and a room.</figcaption>\n</figure><!--kg-card-end: html--><p>And our working app looks as follows:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2022/01/Screen-Shot-2022-01-06-at-13.53.37.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"626\" height=\"445\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/01/Screen-Shot-2022-01-06-at-13.53.37.png 600w, __GHOST_URL__/content/images/2022/01/Screen-Shot-2022-01-06-at-13.53.37.png 626w\"><figcaption>The working break-time friend finder app. Using a simple search, a student can find his schedule.</figcaption></figure><p>But most importantly, the functionality to see whoever shares your break-time ('tussen' in the picture below) or any classes with you:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2022/01/Screen-Shot-2022-01-06-at-13.52.57.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"609\" height=\"290\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/01/Screen-Shot-2022-01-06-at-13.52.57.png 600w, __GHOST_URL__/content/images/2022/01/Screen-Shot-2022-01-06-at-13.52.57.png 609w\"><figcaption>In the app, you can click any class or break to see with whom you share the hour. It's no longer a guessing game! ‚úì</figcaption></figure><p>ü•≥</p><p></p>","comment_id":"61a2265672c7ac1e2046209d","plaintext":"At my school, students often had gaps in their schedules. In between lessons scheduled for the day, one would often have breaks in between. But because you chose a personalized package of classes to follow, everyone's schedule was also different. So, it would be hard to know with whom you could spend those breaks! To solve this, I developed this app. It allows students to find with whom they have breaks so they can hang out with them whilst waiting for the next class üòä. The app was actually used by students in my school. Very cool!\n\n\nBuilding the app\n\nThe entire app is quite sophisticated. The various components can be laid out as follows:\n\n * Node.js backend (Github)\n   - Has three main responsibilities:\n   (1) to scrape student schedules off HTML pages into a MongoDB database. Scraping is done using Cheerio and communication with MongoDB via MongoJS.\n   (2) parse the schedules into a relational format and compute what odd break-time hours exist.\n   (3) expose the MongoDB database as an API.\n * Ember.js frontend (Github)\n   - This front-end then consumes the API data using ember-data. I'm using Bootstrap as a UI framework so I don't have to build all the buttons, tables and interfacing myself.\n\n\n\n\n\n\n... the relational mapping in the database is as follows:\n\n\n\n\nAnd our working app looks as follows:\n\nBut most importantly, the functionality to see whoever shares your break-time ('tussen' in the picture below) or any classes with you:\n\nü•≥\n\n","feature_image":"__GHOST_URL__/content/images/2022/01/Screen-Shot-2022-01-06-at-13.54.22.png","featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","created_at":"2021-11-27 12:36:38","created_by":"1","updated_at":"2022-01-06 13:09:24","updated_by":null,"published_at":"2015-02-20 14:00:00","published_by":"1","custom_excerpt":"Spending school breaks alone is lame. That's why I developed an app so students can find with whom they share their breaks.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c277","uuid":"fe81586b-9c85-4358-af30-a6c86ee7125e","title":"Data & privacy","slug":"privacy","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/eat-cookie.gif\",\"width\":220,\"height\":218}],[\"markdown\",{\"markdown\":\"<small>P.S. I do still like cookies, as a food, though. Yummy. üç™</small>\"}]],\"markups\":[[\"u\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Hi! Just like you, I value my privacy. So, I decided to put \"],[0,[0],1,\"no cookies\"],[0,[],0,\" on this website whatsoever. Your privacy remains totally yours! ‚≠êÔ∏è\"]]],[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>Hi! Just like you, I value my privacy. So, I decided to put <u>no cookies</u> on this website whatsoever. Your privacy remains totally yours! ‚≠êÔ∏è</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/eat-cookie.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"220\" height=\"218\"></figure><!--kg-card-begin: markdown--><p><small>P.S. I do still like cookies, as a food, though. Yummy. üç™</small></p>\n<!--kg-card-end: markdown-->","comment_id":"61a3adce72c7ac1e204621b0","plaintext":"Hi! Just like you, I value my privacy. So, I decided to put no cookies on this website whatsoever. Your privacy remains totally yours! ‚≠êÔ∏è\n\nP.S. I do still like cookies, as a food, though. Yummy. üç™\n","feature_image":null,"featured":0,"type":"page","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","created_at":"2021-11-28 16:26:54","created_by":"1","updated_at":"2021-11-28 22:00:44","updated_by":null,"published_at":"2021-11-28 16:28:06","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c278","uuid":"5da60094-aa3f-41c0-8141-027417bc8faa","title":"COVID-19 Dashboard","slug":"covid-19-dashboard","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Architecture_Batch.svg\",\"alt\":\"Batch architecture\",\"title\":\"\",\"caption\":\"The Corona dashboard <b>batch</b> processing architecture.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Architecture_Streaming.svg\",\"alt\":\"Stream architecture\",\"title\":\"\",\"caption\":\"The Corona dashboard <b>stream</b> processing architecture.\"}],[\"html\",{\"html\":\"<figure class=\\\"kg-card kg-image-card kg-card-hascaption\\\">\\n    <img src=\\\"__GHOST_URL__/content/images/2021/12/Architecture_Full--1-.svg\\\" class=\\\"kg-image\\\" alt=\\\"Full architecture\\\" loading=\\\"lazy\\\">\\n    <figcaption>Both the batch- and stream processing pipelines visualized in a single diagram.</figcaption>\\n</figure>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/github32-1.png\",\"width\":32,\"height\":32,\"cardWidth\":\"\",\"caption\":\"<a href=\\\"https://github.com/dunnkers/disease-spread\\\">disease-spread</a>\",\"href\":\"https://github.com/dunnkers/disease-spread\"}]],\"markups\":[[\"a\",[\"href\",\"https://github.com/CSSEGISandData/COVID-19\"]],[\"a\",[\"href\",\"https://www.worldpop.org/\"]],[\"a\",[\"href\",\"https://dunnkers.com/disease-spread/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"We are in the midst of a global pandemic. At the time this project started, the Corona virus was still just a headline for most - but in the meantime it reached and impacted all of our lives. Fighting such a pandemic happens in many ways on multiple scales. We are interested in how this can be done on the societal level: using data. In this project, me and my teammates built a pipeline capable of processing a large dataset and created a visualization of the areas most vulnerable to Corona which includes reported cases in real-time.\"]]],[1,\"h3\",[[0,[],0,\"Architecture\"]]],[1,\"p\",[[0,[],0,\"To quickly summarize the application: a backend downloads- and processes \"],[0,[0],1,\"Corona data\"],[0,[],0,\" and \"],[0,[1],1,\"population data\"],[0,[],0,\". A clustering algorithm is applied to determine the most 'vulnerable' areas to Corona outbreak. Then, all resulting insights are stored in a MongoDB database and exposes through an API. A frontend then integrates with Mapbox to show the data visually, on a map. Because we were working with large amounts of data, some sophisticated technologies were required to properly process the data:\"]]],[3,\"ul\",[[[0,[],0,\"Apache Kafka\"]],[[0,[],0,\"Apache Spark\"]],[[0,[],0,\"Apache Zeppelin to author PySpark scripts\"]]]],[1,\"p\",[[0,[],0,\"Brought together, this can be put in a diagram as follows:\"]]],[10,0],[1,\"p\",[[0,[],0,\"All components are hosted on Google Cloud Platform (GCP). To also demonstrate merging both batch- and stream data in a single dashboard, also another architecture was built. This time, we took in tweets that are concerned about Corona through the keyword 'Corona' and used a Map-Reduce technique to compute the total amount of Corona-tweets sent by each country in the world. This was then again, stored in a MongoDB database and exposed as an API. See the stream processing architecture below:\"]]],[10,1],[1,\"p\",[[0,[],0,\"To conclude both architectures and how they come together in a single application, see the following diagram:\"]]],[10,2],[1,\"p\",[[0,[],0,\"To see the front-end in action, see the \"],[0,[2],1,\"live dashboard\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Full report\"]]],[1,\"p\",[[0,[],0,\"For further reading, check out the GitHub repository:\"]]],[10,3],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>We are in the midst of a global pandemic. At the time this project started, the Corona virus was still just a headline for most - but in the meantime it reached and impacted all of our lives. Fighting such a pandemic happens in many ways on multiple scales. We are interested in how this can be done on the societal level: using data. In this project, me and my teammates built a pipeline capable of processing a large dataset and created a visualization of the areas most vulnerable to Corona which includes reported cases in real-time.</p><h3 id=\"architecture\">Architecture</h3><p>To quickly summarize the application: a backend downloads- and processes <a href=\"https://github.com/CSSEGISandData/COVID-19\">Corona data</a> and <a href=\"https://www.worldpop.org/\">population data</a>. A clustering algorithm is applied to determine the most 'vulnerable' areas to Corona outbreak. Then, all resulting insights are stored in a MongoDB database and exposes through an API. A frontend then integrates with Mapbox to show the data visually, on a map. Because we were working with large amounts of data, some sophisticated technologies were required to properly process the data:</p><ul><li>Apache Kafka</li><li>Apache Spark</li><li>Apache Zeppelin to author PySpark scripts</li></ul><p>Brought together, this can be put in a diagram as follows:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/Architecture_Batch.svg\" class=\"kg-image\" alt=\"Batch architecture\" loading=\"lazy\"><figcaption>The Corona dashboard <b>batch</b> processing architecture.</figcaption></figure><p>All components are hosted on Google Cloud Platform (GCP). To also demonstrate merging both batch- and stream data in a single dashboard, also another architecture was built. This time, we took in tweets that are concerned about Corona through the keyword 'Corona' and used a Map-Reduce technique to compute the total amount of Corona-tweets sent by each country in the world. This was then again, stored in a MongoDB database and exposed as an API. See the stream processing architecture below:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/Architecture_Streaming.svg\" class=\"kg-image\" alt=\"Stream architecture\" loading=\"lazy\"><figcaption>The Corona dashboard <b>stream</b> processing architecture.</figcaption></figure><p>To conclude both architectures and how they come together in a single application, see the following diagram:</p><!--kg-card-begin: html--><figure class=\"kg-card kg-image-card kg-card-hascaption\">\n    <img src=\"__GHOST_URL__/content/images/2021/12/Architecture_Full--1-.svg\" class=\"kg-image\" alt=\"Full architecture\" loading=\"lazy\">\n    <figcaption>Both the batch- and stream processing pipelines visualized in a single diagram.</figcaption>\n</figure><!--kg-card-end: html--><p>To see the front-end in action, see the <a href=\"https://dunnkers.com/disease-spread/\">live dashboard</a>.</p><h3 id=\"full-report\">Full report</h3><p>For further reading, check out the GitHub repository:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><a href=\"https://github.com/dunnkers/disease-spread\"><img src=\"__GHOST_URL__/content/images/2021/11/github32-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"32\" height=\"32\"></a><figcaption><a href=\"https://github.com/dunnkers/disease-spread\">disease-spread</a></figcaption></figure>","comment_id":"61a3b81e72c7ac1e204621d0","plaintext":"We are in the midst of a global pandemic. At the time this project started, the Corona virus was still just a headline for most - but in the meantime it reached and impacted all of our lives. Fighting such a pandemic happens in many ways on multiple scales. We are interested in how this can be done on the societal level: using data. In this project, me and my teammates built a pipeline capable of processing a large dataset and created a visualization of the areas most vulnerable to Corona which includes reported cases in real-time.\n\n\nArchitecture\n\nTo quickly summarize the application: a backend downloads- and processes Corona data and population data. A clustering algorithm is applied to determine the most 'vulnerable' areas to Corona outbreak. Then, all resulting insights are stored in a MongoDB database and exposes through an API. A frontend then integrates with Mapbox to show the data visually, on a map. Because we were working with large amounts of data, some sophisticated technologies were required to properly process the data:\n\n * Apache Kafka\n * Apache Spark\n * Apache Zeppelin to author PySpark scripts\n\nBrought together, this can be put in a diagram as follows:\n\nAll components are hosted on Google Cloud Platform (GCP). To also demonstrate merging both batch- and stream data in a single dashboard, also another architecture was built. This time, we took in tweets that are concerned about Corona through the keyword 'Corona' and used a Map-Reduce technique to compute the total amount of Corona-tweets sent by each country in the world. This was then again, stored in a MongoDB database and exposed as an API. See the stream processing architecture below:\n\nTo conclude both architectures and how they come together in a single application, see the following diagram:\n\n\n\n\nTo see the front-end in action, see the live dashboard.\n\n\nFull report\n\nFor further reading, check out the GitHub repository:","feature_image":"__GHOST_URL__/content/images/2021/11/Screen-Shot-2021-11-28-at-18.12.40-1.png","featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","created_at":"2021-11-28 17:10:54","created_by":"1","updated_at":"2022-01-06 13:06:59","updated_by":null,"published_at":"2020-02-29 23:00:00","published_by":"1","custom_excerpt":"What parts of the world are susceptible to Corona outbreak? We used Big Data and Data Engineering in this project to find out.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c279","uuid":"e8e08a7c-c02d-4969-bc41-211b9dca2c6e","title":"Backdoors in Neural Networks","slug":"backdoors-in-neural-networks","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-10.52.55.png\",\"width\":1322,\"height\":476,\"caption\":\"Backdoor <em>triggers</em>. Triggers can be single-pixel or a pattern. (Gu et al. 2017)\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-11.41.40.png\",\"width\":724,\"height\":548,\"cardWidth\":\"\",\"caption\":\"A stop sign with a trigger (a yellow sticker üü®) applied. The NN mistakes it for a speed limit sign. That's dangerous! (Gu et al. 2017)\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-12.32.37.png\",\"width\":1436,\"height\":550,\"caption\":\"Infecting a sample in a Latent Backdoor. Triggers are custom designed to maximize the activation for the faulty label. (Yao et al. 2019)\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-10.59.43.png\",\"width\":1920,\"height\":1364}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-12.08.27.png\",\"width\":1936,\"height\":914}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-11.46.53.png\",\"width\":1876,\"height\":1090}],[\"markdown\",{\"markdown\":\"<p align=\\\"center\\\">\\n    <a href=\\\"https://dunnkers.com/neural-network-backdoors/\\\">\\n        https://dunnkers.com/neural-network-backdoors/\\n    </a>\\n</p>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/github32-2.png\",\"width\":32,\"height\":32,\"caption\":\"<a href=\\\"https://github.com/dunnkers/neural-network-backdoors/\\\">neural-network-backdoors</a>\",\"href\":\"https://github.com/dunnkers/neural-network-backdoors/\"}]],\"markups\":[[\"em\"],[\"strong\"],[\"a\",[\"href\",\"https://pytorch.org/\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1708.06733\"]],[\"a\",[\"href\",\"https://mxnet.apache.org/\"]],[\"a\",[\"href\",\"https://image-net.org/\"]],[\"a\",[\"href\",\"https://dl.acm.org/doi/abs/10.1145/3319535.3354209\"]],[\"a\",[\"href\",\"https://onnx.ai/\"]],[\"a\",[\"href\",\"https://github.com/microsoft/onnxjs\"]],[\"a\",[\"href\",\"https://dunnkers.com/neural-network-backdoors/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Large Neural Networks can take a long time to train. Hours, maybe even days. Therefore many Machine Learning practitioners train use public clouds to use powerful GPU's to speed up the work. Even, to save time, off-the-shelf pre-trained models can be used and then retrained for a specific task ‚Äì this is \"],[0,[0],1,\"transfer learning\"],[0,[],0,\". But using either approach means putting trust in someone else's hands. Can we be sure the cloud does not mess with our model? Are we sure the off-the-shelf pre-trained model is not malicious? In this article, we explore \"],[0,[0],1,\"how\"],[0,[],0,\" an attacker could mess with your model, by means of inserting \"],[0,[0],1,\"backdoors\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Inserting a backdoor\"]]],[1,\"p\",[[0,[],0,\"The idea of a backdoor is to have the Neural Network output a wrong answer \"],[0,[1],1,\"only\"],[0,[],0,\" when a \"],[0,[0],1,\"trigger\"],[0,[],0,\" is present. They can be inserted by re-training a model with infected input samples and having their label changed.\"]]],[10,0],[1,\"p\",[[0,[],0,\"This makes a backdoor particularly hard to spot. Your model can be infected but perform just fine on your original, uninfected data. Predictions are completely off, though, when the trigger is present. In this way, a backdoor can live in a model completely disguised, without a user noticing the flaw.\"]]],[10,1],[1,\"p\",[[0,[],0,\"Besides inconvenience, infected networks might actually be dangerous. Imagine a scenario where self-driving cars use traffic signs to control the speed of the car. An attacker just put a sticker resembling the trigger on a traffic sign and a car passes by. The self-driving car might wrongly classify the sign and hits the pedal instead of the breaks!\"]]],[1,\"h2\",[[0,[],0,\"A latent backdoor\"]]],[1,\"p\",[[0,[],0,\"This backdoor, however, will not survive the transfer-learning process. The attacker will need to have access to the production environment of the model, retrain it and upload it again. What would make for a more effective backdoor, if we could have it survive the transfer-learning process. This is exactly what a \"],[0,[0],1,\"Latent backdoor\"],[0,[],0,\" aims to do.\"]]],[1,\"p\",[[0,[],0,\"A latent backdoor has two components the \"],[0,[0],1,\"teacher\"],[0,[],0,\" model and the \"],[0,[0],1,\"student\"],[0,[],0,\" model.\"]]],[3,\"ul\",[[[0,[1],1,\"üòà Teacher model\"],[0,[],0,\". The attacker creates and trains a \"],[0,[0],1,\"teacher\"],[0,[],0,\" model. Then, some samples get a trigger inserted, and have their labels changed. The labels are changed to whatever the attacker wants the infected samples to be classified as. For example, the attacker might add a label for a speed limit sign.\"],[1,[],0,0],[0,[],0,\"Then, after the training process, the attacker removes the neuron related to classifying the infected label in the Fully Connected layer ‚Äì thus removing any trace of the backdoor.\"]],[[0,[1],1,\"üòø Student model\"],[0,[],0,\". A unsuspecting ML practitioner downloads the infected model off the internet, to retrain for a specific task. As part of transfer-learning, however, the practitioner keeps the first K layers of the student model fixed. In other words: its weights are not changed. Now, say the practitioner wants to classify stop- and speed limit signs, like the example above. Note that now, \"],[0,[0],1,\"the classification target that was removed before is added again\"],[0,[],0,\"! But this time, by the unsuspecting practitioner itself.\"],[1,[],0,1],[0,[],0,\"Now, with a trigger in place, the model completely misclassifies stop signs for speed limits. Bad business.\"]]]],[1,\"p\",[[0,[],0,\"Triggers in the Latent Backdoor are not just simple pixel configurations. Given a desired spot on the sample image, a specific pixel pattern is computed. Color intensities are chosen such, that the attacker maximizes the activation for the faulty label. \"]]],[10,2],[1,\"h2\",[[0,[],0,\"Demonstration\"]]],[1,\"p\",[[0,[],0,\"We built a demonstration for both backdoors.\"]]],[3,\"ul\",[[[0,[],0,\"Normal backdoor: inserted in a \"],[0,[2],1,\"PyTorch\"],[0,[],0,\" handwriting recognition CNN model by infecting the MNIST training dataset with single-pixel backdoors. Implementation of \"],[0,[3],1,\"Gu et al. (2017)\"],[0,[],0,\".\"]],[[0,[],0,\"Latent backdoor: inserted in an \"],[0,[4],1,\"MXNet\"],[0,[],0,\" model trained to recognize dogs. Model was first pre-trained on \"],[0,[5],1,\"ImageNet\"],[0,[],0,\" and fine-tuned for dogs. With a backdoor in place, the model would mistake dogs for Donald Trump. Implementation of \"],[0,[6],1,\"Yao et al. (2019)\"],[0,[],0,\".\"]]]],[1,\"p\",[[0,[],0,\"‚Üí To demonstrate these backdoors, both the infected and normal models were exported to \"],[0,[7],1,\"ONNX\"],[0,[],0,\" format. Then, using \"],[0,[8],1,\"ONNX.js\"],[0,[],0,\", we built a React.js web page allowing one to do live-inference. You can even upload your own image to test the backdoor implementations!\"]]],[1,\"p\",[[0,[],0,\"Check out the\"],[0,[1],0,\" \"],[0,[9],2,\"demonstration\"],[0,[],0,\":\"]]],[10,3],[10,4],[10,5],[10,6],[1,\"p\",[[0,[],0,\"So, let's all be careful about using Neural Networks in production environments. For the consequences can be large.\"]]],[1,\"h3\",[[0,[],0,\"Source code\"]]],[1,\"p\",[[0,[],0,\"The demo source code is freely available on GitHub. Don't forget to leave a star ‚≠êÔ∏è if you like the project:\"]]],[10,7],[1,\"p\",[[0,[],0,\"I wish you all a good one. Cheers! üôèüèª\"]]]],\"ghostVersion\":\"4.0\"}","html":"<p>Large Neural Networks can take a long time to train. Hours, maybe even days. Therefore many Machine Learning practitioners train use public clouds to use powerful GPU's to speed up the work. Even, to save time, off-the-shelf pre-trained models can be used and then retrained for a specific task ‚Äì this is <em>transfer learning</em>. But using either approach means putting trust in someone else's hands. Can we be sure the cloud does not mess with our model? Are we sure the off-the-shelf pre-trained model is not malicious? In this article, we explore <em>how</em> an attacker could mess with your model, by means of inserting <em>backdoors</em>.</p><h2 id=\"inserting-a-backdoor\">Inserting a backdoor</h2><p>The idea of a backdoor is to have the Neural Network output a wrong answer <strong>only</strong> when a <em>trigger</em> is present. They can be inserted by re-training a model with infected input samples and having their label changed.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-10.52.55.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1322\" height=\"476\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/12/Screen-Shot-2021-12-22-at-10.52.55.png 600w, __GHOST_URL__/content/images/size/w1000/2021/12/Screen-Shot-2021-12-22-at-10.52.55.png 1000w, __GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-10.52.55.png 1322w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Backdoor <em>triggers</em>. Triggers can be single-pixel or a pattern. (Gu et al. 2017)</figcaption></figure><p>This makes a backdoor particularly hard to spot. Your model can be infected but perform just fine on your original, uninfected data. Predictions are completely off, though, when the trigger is present. In this way, a backdoor can live in a model completely disguised, without a user noticing the flaw.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-11.41.40.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"724\" height=\"548\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/12/Screen-Shot-2021-12-22-at-11.41.40.png 600w, __GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-11.41.40.png 724w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A stop sign with a trigger (a yellow sticker üü®) applied. The NN mistakes it for a speed limit sign. That's dangerous! (Gu et al. 2017)</figcaption></figure><p>Besides inconvenience, infected networks might actually be dangerous. Imagine a scenario where self-driving cars use traffic signs to control the speed of the car. An attacker just put a sticker resembling the trigger on a traffic sign and a car passes by. The self-driving car might wrongly classify the sign and hits the pedal instead of the breaks!</p><h2 id=\"a-latent-backdoor\">A latent backdoor</h2><p>This backdoor, however, will not survive the transfer-learning process. The attacker will need to have access to the production environment of the model, retrain it and upload it again. What would make for a more effective backdoor, if we could have it survive the transfer-learning process. This is exactly what a <em>Latent backdoor</em> aims to do.</p><p>A latent backdoor has two components the <em>teacher</em> model and the <em>student</em> model.</p><ul><li><strong>üòà Teacher model</strong>. The attacker creates and trains a <em>teacher</em> model. Then, some samples get a trigger inserted, and have their labels changed. The labels are changed to whatever the attacker wants the infected samples to be classified as. For example, the attacker might add a label for a speed limit sign.<br>Then, after the training process, the attacker removes the neuron related to classifying the infected label in the Fully Connected layer ‚Äì thus removing any trace of the backdoor.</li><li><strong>üòø Student model</strong>. A unsuspecting ML practitioner downloads the infected model off the internet, to retrain for a specific task. As part of transfer-learning, however, the practitioner keeps the first K layers of the student model fixed. In other words: its weights are not changed. Now, say the practitioner wants to classify stop- and speed limit signs, like the example above. Note that now, <em>the classification target that was removed before is added again</em>! But this time, by the unsuspecting practitioner itself.<br>Now, with a trigger in place, the model completely misclassifies stop signs for speed limits. Bad business.</li></ul><p>Triggers in the Latent Backdoor are not just simple pixel configurations. Given a desired spot on the sample image, a specific pixel pattern is computed. Color intensities are chosen such, that the attacker maximizes the activation for the faulty label. </p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-12.32.37.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1436\" height=\"550\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/12/Screen-Shot-2021-12-22-at-12.32.37.png 600w, __GHOST_URL__/content/images/size/w1000/2021/12/Screen-Shot-2021-12-22-at-12.32.37.png 1000w, __GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-12.32.37.png 1436w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Infecting a sample in a Latent Backdoor. Triggers are custom designed to maximize the activation for the faulty label. (Yao et al. 2019)</figcaption></figure><h2 id=\"demonstration\">Demonstration</h2><p>We built a demonstration for both backdoors.</p><ul><li>Normal backdoor: inserted in a <a href=\"https://pytorch.org/\">PyTorch</a> handwriting recognition CNN model by infecting the MNIST training dataset with single-pixel backdoors. Implementation of <a href=\"https://arxiv.org/abs/1708.06733\">Gu et al. (2017)</a>.</li><li>Latent backdoor: inserted in an <a href=\"https://mxnet.apache.org/\">MXNet</a> model trained to recognize dogs. Model was first pre-trained on <a href=\"https://image-net.org/\">ImageNet</a> and fine-tuned for dogs. With a backdoor in place, the model would mistake dogs for Donald Trump. Implementation of <a href=\"https://dl.acm.org/doi/abs/10.1145/3319535.3354209\">Yao et al. (2019)</a>.</li></ul><p>‚Üí To demonstrate these backdoors, both the infected and normal models were exported to <a href=\"https://onnx.ai/\">ONNX</a> format. Then, using <a href=\"https://github.com/microsoft/onnxjs\">ONNX.js</a>, we built a React.js web page allowing one to do live-inference. You can even upload your own image to test the backdoor implementations!</p><p>Check out the<strong> <a href=\"https://dunnkers.com/neural-network-backdoors/\">demonstration</a></strong>:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-10.59.43.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1920\" height=\"1364\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/12/Screen-Shot-2021-12-22-at-10.59.43.png 600w, __GHOST_URL__/content/images/size/w1000/2021/12/Screen-Shot-2021-12-22-at-10.59.43.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/12/Screen-Shot-2021-12-22-at-10.59.43.png 1600w, __GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-10.59.43.png 1920w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-12.08.27.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1936\" height=\"914\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/12/Screen-Shot-2021-12-22-at-12.08.27.png 600w, __GHOST_URL__/content/images/size/w1000/2021/12/Screen-Shot-2021-12-22-at-12.08.27.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/12/Screen-Shot-2021-12-22-at-12.08.27.png 1600w, __GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-12.08.27.png 1936w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-11.46.53.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1876\" height=\"1090\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/12/Screen-Shot-2021-12-22-at-11.46.53.png 600w, __GHOST_URL__/content/images/size/w1000/2021/12/Screen-Shot-2021-12-22-at-11.46.53.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/12/Screen-Shot-2021-12-22-at-11.46.53.png 1600w, __GHOST_URL__/content/images/2021/12/Screen-Shot-2021-12-22-at-11.46.53.png 1876w\" sizes=\"(min-width: 720px) 720px\"></figure><!--kg-card-begin: markdown--><p align=\"center\">\n    <a href=\"https://dunnkers.com/neural-network-backdoors/\">\n        https://dunnkers.com/neural-network-backdoors/\n    </a>\n</p><!--kg-card-end: markdown--><p>So, let's all be careful about using Neural Networks in production environments. For the consequences can be large.</p><h3 id=\"source-code\">Source code</h3><p>The demo source code is freely available on GitHub. Don't forget to leave a star ‚≠êÔ∏è if you like the project:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><a href=\"https://github.com/dunnkers/neural-network-backdoors/\"><img src=\"__GHOST_URL__/content/images/2021/11/github32-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"32\" height=\"32\"></a><figcaption><a href=\"https://github.com/dunnkers/neural-network-backdoors/\">neural-network-backdoors</a></figcaption></figure><p>I wish you all a good one. Cheers! üôèüèª</p>","comment_id":"61a3be5d72c7ac1e20462270","plaintext":"Large Neural Networks can take a long time to train. Hours, maybe even days. Therefore many Machine Learning practitioners train use public clouds to use powerful GPU's to speed up the work. Even, to save time, off-the-shelf pre-trained models can be used and then retrained for a specific task ‚Äì this is transfer learning. But using either approach means putting trust in someone else's hands. Can we be sure the cloud does not mess with our model? Are we sure the off-the-shelf pre-trained model is not malicious? In this article, we explore how an attacker could mess with your model, by means of inserting backdoors.\n\n\nInserting a backdoor\n\nThe idea of a backdoor is to have the Neural Network output a wrong answer only when a trigger is present. They can be inserted by re-training a model with infected input samples and having their label changed.\n\nThis makes a backdoor particularly hard to spot. Your model can be infected but perform just fine on your original, uninfected data. Predictions are completely off, though, when the trigger is present. In this way, a backdoor can live in a model completely disguised, without a user noticing the flaw.\n\nBesides inconvenience, infected networks might actually be dangerous. Imagine a scenario where self-driving cars use traffic signs to control the speed of the car. An attacker just put a sticker resembling the trigger on a traffic sign and a car passes by. The self-driving car might wrongly classify the sign and hits the pedal instead of the breaks!\n\n\nA latent backdoor\n\nThis backdoor, however, will not survive the transfer-learning process. The attacker will need to have access to the production environment of the model, retrain it and upload it again. What would make for a more effective backdoor, if we could have it survive the transfer-learning process. This is exactly what a Latent backdoor aims to do.\n\nA latent backdoor has two components the teacher model and the student model.\n\n * üòà Teacher model. The attacker creates and trains a teacher model. Then, some samples get a trigger inserted, and have their labels changed. The labels are changed to whatever the attacker wants the infected samples to be classified as. For example, the attacker might add a label for a speed limit sign.\n   Then, after the training process, the attacker removes the neuron related to classifying the infected label in the Fully Connected layer ‚Äì thus removing any trace of the backdoor.\n * üòø Student model. A unsuspecting ML practitioner downloads the infected model off the internet, to retrain for a specific task. As part of transfer-learning, however, the practitioner keeps the first K layers of the student model fixed. In other words: its weights are not changed. Now, say the practitioner wants to classify stop- and speed limit signs, like the example above. Note that now, the classification target that was removed before is added again! But this time, by the unsuspecting practitioner itself.\n   Now, with a trigger in place, the model completely misclassifies stop signs for speed limits. Bad business.\n\nTriggers in the Latent Backdoor are not just simple pixel configurations. Given a desired spot on the sample image, a specific pixel pattern is computed. Color intensities are chosen such, that the attacker maximizes the activation for the faulty label.\n\n\nDemonstration\n\nWe built a demonstration for both backdoors.\n\n * Normal backdoor: inserted in a PyTorch handwriting recognition CNN model by infecting the MNIST training dataset with single-pixel backdoors. Implementation of Gu et al. (2017).\n * Latent backdoor: inserted in an MXNet model trained to recognize dogs. Model was first pre-trained on ImageNet and fine-tuned for dogs. With a backdoor in place, the model would mistake dogs for Donald Trump. Implementation of Yao et al. (2019).\n\n‚Üí To demonstrate these backdoors, both the infected and normal models were exported to ONNX format. Then, using ONNX.js, we built a React.js web page allowing one to do live-inference. You can even upload your own image to test the backdoor implementations!\n\nCheck out the demonstration:\n\n\n\nhttps://dunnkers.com/neural-network-backdoors/\n\n\n\nSo, let's all be careful about using Neural Networks in production environments. For the consequences can be large.\n\n\nSource code\n\nThe demo source code is freely available on GitHub. Don't forget to leave a star ‚≠êÔ∏è if you like the project:\n\nI wish you all a good one. Cheers! üôèüèª","feature_image":"__GHOST_URL__/content/images/2021/11/neural-network-backdoors.png","featured":1,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","created_at":"2021-11-28 17:37:33","created_by":"1","updated_at":"2021-12-22 11:42:26","updated_by":null,"published_at":"2020-10-28 23:00:00","published_by":"1","custom_excerpt":"In this project, we demonstrated how Neural Networks can be vulnerable to a Backdoor attack.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c27a","uuid":"c7a9d3f6-33cf-40f2-91c2-9d54bcf62d81","title":"Finding 'God' components in Apache Tika","slug":"finding-god-components-in-apache-tika","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/tika.png\",\"width\":292,\"height\":100,\"caption\":\"Apache Tika is a software package for extracting metadata and text from many file extensions.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/gc-lineplot.png\",\"width\":1118,\"height\":388,\"caption\":\"Chart indicating when components started- and stopped being a 'God Component'.\"}],[\"bookmark\",{\"version\":\"1.0\",\"type\":\"bookmark\",\"url\":\"https://dunnkers.com/god-components/\",\"metadata\":{\"url\":\"https://dunnkers.com/god-components/\",\"title\":\"God Components in Apache Tika\",\"description\":\"How do God Components evolve in Apache Tika? A qualitative and quantitative analysis.\",\"author\":\"Jeroen Overschie\",\"publisher\":null,\"thumbnail\":null,\"icon\":null},\"caption\":\"A Jupyter Notebook showing the final results of the analysis.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/github32-2.png\",\"width\":32,\"height\":32,\"caption\":\"<a href=\\\"https://github.com/dunnkers/god-components/\\\">god-components</a>\"}]],\"markups\":[[\"em\"],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/God_object\"]],[\"a\",[\"href\",\"https://tika.apache.org/\",\"rel\",\"nofollow\"]],[\"strong\"],[\"a\",[\"href\",\"https://www.designite-tools.com/\"]],[\"a\",[\"href\",\"https://www.rug.nl/society-business/centre-for-information-technology/research/services/hpc/facilities/peregrine-hpc-cluster?lang=en\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"How did big, bulky software components come into being? In this project, we explore the evolution of so-called \"],[0,[0,1],2,\"God Components\"],[0,[],0,\"; pieces of software with a large number of classes or lines of code that got very large over time. Our analysis was run on the \"],[0,[2],1,\"Apache Tika\"],[0,[],0,\" codebase.\"]]],[10,0],[1,\"p\",[[0,[],0,\"In this project, we set the following \"],[0,[3],1,\"goals\"],[0,[],0,\":\"]]],[3,\"ul\",[[[0,[],0,\"Search through the Java code programmatically and find components that exceed a certain size threshold\"]],[[0,[],0,\"Find out how those components evolved over time. Did certain developers often contribute to creating God components - in other words - code that is hard to maintain?\"]]]],[1,\"p\",[[0,[],0,\"To find out, we took roughly the following \"],[0,[3],1,\"steps\"],[0,[],0,\":\"]]],[3,\"ol\",[[[0,[],0,\"Using a Python script, we created an index of the Tika codebase at every point in time. That is, we created a list of every Commit ID in the project.\"]],[[0,[],0,\"For every commit, we run \"],[0,[4],1,\"Designite\"],[0,[],0,\" - which is a tool to find architectural smells in Java projects. Because so many versions of the codebase had to be analyzed, this stage of the analysis was done on the University's supercomputer, \"],[0,[5],1,\"Peregrine\"],[0,[],0,\".\"]],[[0,[],0,\"Using a Jupyter Notebook, we aggregate and summarize all information outputted by Designite. The amount of data to parse was large, so it was important to map-reduce as quickly as possible without losing critical information.\"]]]],[1,\"p\",[[0,[],0,\"Such, we were able to visualize exactly at which time a component has been a God Component in the Tika codebase:\"]]],[10,1],[1,\"p\",[[0,[],0,\"For more results, check out the complete Jupyter Notebook:\"]]],[10,2],[1,\"h3\",[[0,[],0,\"Further reading\"]]],[1,\"p\",[[0,[],0,\"For more information, check out the Github page:\"]]],[10,3],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>How did big, bulky software components come into being? In this project, we explore the evolution of so-called <em><a href=\"https://en.wikipedia.org/wiki/God_object\">God Components</a></em>; pieces of software with a large number of classes or lines of code that got very large over time. Our analysis was run on the <a href=\"https://tika.apache.org/\" rel=\"nofollow\">Apache Tika</a> codebase.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/tika.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"292\" height=\"100\"><figcaption>Apache Tika is a software package for extracting metadata and text from many file extensions.</figcaption></figure><p>In this project, we set the following <strong>goals</strong>:</p><ul><li>Search through the Java code programmatically and find components that exceed a certain size threshold</li><li>Find out how those components evolved over time. Did certain developers often contribute to creating God components - in other words - code that is hard to maintain?</li></ul><p>To find out, we took roughly the following <strong>steps</strong>:</p><ol><li>Using a Python script, we created an index of the Tika codebase at every point in time. That is, we created a list of every Commit ID in the project.</li><li>For every commit, we run <a href=\"https://www.designite-tools.com/\">Designite</a> - which is a tool to find architectural smells in Java projects. Because so many versions of the codebase had to be analyzed, this stage of the analysis was done on the University's supercomputer, <a href=\"https://www.rug.nl/society-business/centre-for-information-technology/research/services/hpc/facilities/peregrine-hpc-cluster?lang=en\">Peregrine</a>.</li><li>Using a Jupyter Notebook, we aggregate and summarize all information outputted by Designite. The amount of data to parse was large, so it was important to map-reduce as quickly as possible without losing critical information.</li></ol><p>Such, we were able to visualize exactly at which time a component has been a God Component in the Tika codebase:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/gc-lineplot.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1118\" height=\"388\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/gc-lineplot.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/gc-lineplot.png 1000w, __GHOST_URL__/content/images/2021/11/gc-lineplot.png 1118w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Chart indicating when components started- and stopped being a 'God Component'.</figcaption></figure><p>For more results, check out the complete Jupyter Notebook:</p><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"https://dunnkers.com/god-components/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">God Components in Apache Tika</div><div class=\"kg-bookmark-description\">How do God Components evolve in Apache Tika? A qualitative and quantitative analysis.</div><div class=\"kg-bookmark-metadata\"><span class=\"kg-bookmark-publisher\">Jeroen Overschie</span></div></div></a><figcaption>A Jupyter Notebook showing the final results of the analysis.</figcaption></figure><h3 id=\"further-reading\">Further reading</h3><p>For more information, check out the Github page:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/github32-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"32\" height=\"32\"><figcaption><a href=\"https://github.com/dunnkers/god-components/\">god-components</a></figcaption></figure><p></p>","comment_id":"61a3cbd172c7ac1e20462353","plaintext":"How did big, bulky software components come into being? In this project, we explore the evolution of so-called God Components; pieces of software with a large number of classes or lines of code that got very large over time. Our analysis was run on the Apache Tika codebase.\n\nIn this project, we set the following goals:\n\n * Search through the Java code programmatically and find components that exceed a certain size threshold\n * Find out how those components evolved over time. Did certain developers often contribute to creating God components - in other words - code that is hard to maintain?\n\nTo find out, we took roughly the following steps:\n\n 1. Using a Python script, we created an index of the Tika codebase at every point in time. That is, we created a list of every Commit ID in the project.\n 2. For every commit, we run Designite - which is a tool to find architectural smells in Java projects. Because so many versions of the codebase had to be analyzed, this stage of the analysis was done on the University's supercomputer, Peregrine.\n 3. Using a Jupyter Notebook, we aggregate and summarize all information outputted by Designite. The amount of data to parse was large, so it was important to map-reduce as quickly as possible without losing critical information.\n\nSuch, we were able to visualize exactly at which time a component has been a God Component in the Tika codebase:\n\nFor more results, check out the complete Jupyter Notebook:\n\nGod Components in Apache TikaHow do God Components evolve in Apache Tika? A qualitative and quantitative analysis.Jeroen Overschie\n\n\nFurther reading\n\nFor more information, check out the Github page:\n\n","feature_image":"__GHOST_URL__/content/images/2021/11/god-components-apache-tika.png","featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","created_at":"2021-11-28 18:34:57","created_by":"1","updated_at":"2021-11-28 20:19:15","updated_by":null,"published_at":"2021-01-16 23:00:00","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c27b","uuid":"7852a134-a08a-40db-b854-a6a586101a42","title":"Musical Key Recognition using a Hidden Markov Model","slug":"musical-key-recognition-using-a-hidden-markov-model","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/Circle_of_5ths-1024x1020-1.png\",\"width\":512,\"height\":510,\"caption\":\"Musical keys illustrated in a circle diagram. Courtesy of <a href=\\\"http://www.wildflowerharmonica.com/4ths/\\\">Tad Dreis</a>.\",\"cardWidth\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/music-key-classification-1.png\",\"width\":1360,\"height\":1142,\"caption\":\"Illustration of training an HMM using Chroma vectors. Courtesy of Peeters G (2006).\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/github32-2.png\",\"width\":32,\"height\":32,\"caption\":\"<a href=\\\"https://github.com/dunnkers/music-key-classification\\\">music-key-classification</a>\"}]],\"markups\":[[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Key_(music)\"]],[\"em\"],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Chroma_feature\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Underlying every musical piece is its \"],[0,[0],1,\"key\"],[0,[],0,\". It determines the group of sound pitches that are used, and tells really a lot about its sound. Among others, it's useful for DJ's, who can benefit from selecting tracks that have similar key, so the sound matches nicely. Now, in this project, we took on the challenge of trying to train a model to predict such a key. Let's see how we did this.\"]]],[1,\"h2\",[[0,[],0,\"Intuition\"]]],[1,\"p\",[[0,[],0,\"First of all, we must know there are 24 keys, 12 in major and 12 in minor. They can be illustrated like so:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Now, we chose Hidden Markov Models (HMMs) as our main instrument to try to predict the correct musical key, given a set of \"],[0,[1,2],2,\"Chroma vectors\"],[0,[],0,\". Such vectors represent the relative strength of each pitch in different segments of the track, which data we have for about 10,000 tracks. We obtain such Chroma vectors using Spotify's web API, which additionally gives us a ground-truth indication of the actual music key, such that we can use supervised learning to train our HMM. \"]]],[1,\"p\",[[0,[],0,\"The key insight is to train an HMM for both major and minor, separately. Then, we create copies of those models and retrain them with a circular shift in its key. In this way, we train a model for every key: such, we can predict the probability of a song belonging to a certain key, by searching for the model assigning the highest probability to its output. The process can be illustrated as follows:\"]]],[10,1],[1,\"p\",[]],[1,\"h2\",[[0,[],0,\"Execution\"]]],[1,\"p\",[[0,[],0,\"The actual implementation of the code and project can be found on GitHub:\"]]],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>Underlying every musical piece is its <a href=\"https://en.wikipedia.org/wiki/Key_(music)\">key</a>. It determines the group of sound pitches that are used, and tells really a lot about its sound. Among others, it's useful for DJ's, who can benefit from selecting tracks that have similar key, so the sound matches nicely. Now, in this project, we took on the challenge of trying to train a model to predict such a key. Let's see how we did this.</p><h2 id=\"intuition\">Intuition</h2><p>First of all, we must know there are 24 keys, 12 in major and 12 in minor. They can be illustrated like so:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/Circle_of_5ths-1024x1020-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"512\" height=\"510\"><figcaption>Musical keys illustrated in a circle diagram. Courtesy of <a href=\"http://www.wildflowerharmonica.com/4ths/\">Tad Dreis</a>.</figcaption></figure><p>Now, we chose Hidden Markov Models (HMMs) as our main instrument to try to predict the correct musical key, given a set of <em><a href=\"https://en.wikipedia.org/wiki/Chroma_feature\">Chroma vectors</a></em>. Such vectors represent the relative strength of each pitch in different segments of the track, which data we have for about 10,000 tracks. We obtain such Chroma vectors using Spotify's web API, which additionally gives us a ground-truth indication of the actual music key, such that we can use supervised learning to train our HMM. </p><p>The key insight is to train an HMM for both major and minor, separately. Then, we create copies of those models and retrain them with a circular shift in its key. In this way, we train a model for every key: such, we can predict the probability of a song belonging to a certain key, by searching for the model assigning the highest probability to its output. The process can be illustrated as follows:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/music-key-classification-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1360\" height=\"1142\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/music-key-classification-1.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/music-key-classification-1.png 1000w, __GHOST_URL__/content/images/2021/11/music-key-classification-1.png 1360w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Illustration of training an HMM using Chroma vectors. Courtesy of Peeters G (2006).</figcaption></figure><p></p><h2 id=\"execution\">Execution</h2><p>The actual implementation of the code and project can be found on GitHub:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/github32-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"32\" height=\"32\"><figcaption><a href=\"https://github.com/dunnkers/music-key-classification\">music-key-classification</a></figcaption></figure>","comment_id":"61a3e47372c7ac1e204623c6","plaintext":"Underlying every musical piece is its key. It determines the group of sound pitches that are used, and tells really a lot about its sound. Among others, it's useful for DJ's, who can benefit from selecting tracks that have similar key, so the sound matches nicely. Now, in this project, we took on the challenge of trying to train a model to predict such a key. Let's see how we did this.\n\n\nIntuition\n\nFirst of all, we must know there are 24 keys, 12 in major and 12 in minor. They can be illustrated like so:\n\nNow, we chose Hidden Markov Models (HMMs) as our main instrument to try to predict the correct musical key, given a set of Chroma vectors. Such vectors represent the relative strength of each pitch in different segments of the track, which data we have for about 10,000 tracks. We obtain such Chroma vectors using Spotify's web API, which additionally gives us a ground-truth indication of the actual music key, such that we can use supervised learning to train our HMM.\n\nThe key insight is to train an HMM for both major and minor, separately. Then, we create copies of those models and retrain them with a circular shift in its key. In this way, we train a model for every key: such, we can predict the probability of a song belonging to a certain key, by searching for the model assigning the highest probability to its output. The process can be illustrated as follows:\n\n\n\n\nExecution\n\nThe actual implementation of the code and project can be found on GitHub:","feature_image":"https://images.unsplash.com/photo-1516110833967-0b5716ca1387?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fG11c2ljJTIwcm9ib3R8ZW58MHx8fHwxNjM4MTMwOTI5&ixlib=rb-1.2.1&q=80&w=2000","featured":0,"type":"post","status":"draft","locale":null,"visibility":"public","email_recipient_filter":"all","created_at":"2021-11-28 20:20:03","created_by":"1","updated_at":"2021-12-09 08:32:31","updated_by":null,"published_at":"2021-02-11 23:00:00","published_by":null,"custom_excerpt":"Every musical piece has a distinct key. In this project, a Hidden Markov Model is trained to try and predict such a key.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c27c","uuid":"4f464bb5-8d38-4d35-ba1b-c8de24d3b283","title":"Making Art with Generative Adversarial Networks","slug":"making-art-with-generative-adversarial-networks","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/retrain_morphing.png\",\"width\":1621,\"height\":540,\"cardWidth\":\"wide\",\"caption\":\"Progressively grown StyleGAN. The adversarial network first takes on the task of creating low-resolution art, and then progressively makes sharper images (fakes).\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/github32-2.png\",\"width\":32,\"height\":32,\"caption\":\"<a href=\\\"https://github.com/dunnkers/generative-adversarial-networks\\\">generative-adversarial-networks</a>\",\"href\":\"https://github.com/dunnkers/generative-adversarial-networks\"}]],\"markups\":[[\"a\",[\"href\",\"https://arxiv.org/abs/1406.2661\"]],[\"strong\"],[\"em\"],[\"a\",[\"href\",\"https://arxiv.org/abs/1511.06434\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1812.04948\"]],[\"a\",[\"href\",\"https://www.tensorflow.org/\"]],[\"a\",[\"href\",\"https://www.kaggle.com/ipythonx/van-gogh-paintings\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Generative Adversarial Networks (\"],[0,[0],1,\"GAN's\"],[0,[],0,\") are a relatively new type of technique for generating samples from a learned distribution, in which two networks are simultaneously trained whilst competing against each other. Applications for GAN‚Äôs are numerous, including image up-sampling, image generation, and the recently quite popular \"],[0,[1],1,\"Deep Fakes\"],[0,[],0,\". In this project, we aim to train such a Generative Adversarial Network ourselves, with the purpose of image generation, specifically. As the generation of human faces has been widely studied, we have chosen a different topic, namely: the generation of paintings. While large datasets of paintings are available, we have opted to restrict ourselves to one artist, as we believe this will give a better chance at producing realistic paintings. For this, we have chosen the Dutch artist \"],[0,[2],1,\"Vincent van Gogh\"],[0,[],0,\", who is known for his unique style.\"]]],[1,\"h2\",[[0,[],0,\"How\"]]],[1,\"p\",[[0,[],0,\"There are many GAN architectures around. Some popular of which the \"],[0,[3],1,\"DCGAN\"],[0,[],0,\" and the \"],[0,[4],1,\"StyleGAN\"],[0,[],0,\". We decided to train both and compare the results.\"]]],[3,\"ul\",[[[0,[],0,\"DCGAN. A GAN architecture that has been around for a while. Was trained using \"],[0,[5],1,\"TensorFlow\"],[0,[],0,\".\"]],[[0,[],0,\"StyleGAN. A popular GAN architecture for generating faces, provisioned by NVIDIA Research. Also trained using TensorFlow.\"]]]],[1,\"p\",[[0,[],0,\"Both were trained on the \"],[0,[6],1,\"Van Gogh dataset\"],[0,[],0,\", as available on Kaggle. Because the dataset contained only a limited amount of paintings (painting is, of course, a very time consuming activity), we decided to augment the dataset. Among others, we applied rotation- and shearing operations, and modified the brightness, such that we get more training data.\"]]],[1,\"p\",[[0,[],0,\"The StyleGAN showed the most promising results. Starting out with a seed previously used to generate a face, we managed to train a GAN that produced something that remotely resembled art. Given that a computer is doing this, that's pretty neat!\"]]],[10,0],[1,\"p\",[]],[1,\"h2\",[[0,[],0,\"More reading\"]]],[1,\"p\",[[0,[],0,\"To read a more detailed report on this project, check out the Github page:\"]]],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>Generative Adversarial Networks (<a href=\"https://arxiv.org/abs/1406.2661\">GAN's</a>) are a relatively new type of technique for generating samples from a learned distribution, in which two networks are simultaneously trained whilst competing against each other. Applications for GAN‚Äôs are numerous, including image up-sampling, image generation, and the recently quite popular <strong>Deep Fakes</strong>. In this project, we aim to train such a Generative Adversarial Network ourselves, with the purpose of image generation, specifically. As the generation of human faces has been widely studied, we have chosen a different topic, namely: the generation of paintings. While large datasets of paintings are available, we have opted to restrict ourselves to one artist, as we believe this will give a better chance at producing realistic paintings. For this, we have chosen the Dutch artist <em>Vincent van Gogh</em>, who is known for his unique style.</p><h2 id=\"how\">How</h2><p>There are many GAN architectures around. Some popular of which the <a href=\"https://arxiv.org/abs/1511.06434\">DCGAN</a> and the <a href=\"https://arxiv.org/abs/1812.04948\">StyleGAN</a>. We decided to train both and compare the results.</p><ul><li>DCGAN. A GAN architecture that has been around for a while. Was trained using <a href=\"https://www.tensorflow.org/\">TensorFlow</a>.</li><li>StyleGAN. A popular GAN architecture for generating faces, provisioned by NVIDIA Research. Also trained using TensorFlow.</li></ul><p>Both were trained on the <a href=\"https://www.kaggle.com/ipythonx/van-gogh-paintings\">Van Gogh dataset</a>, as available on Kaggle. Because the dataset contained only a limited amount of paintings (painting is, of course, a very time consuming activity), we decided to augment the dataset. Among others, we applied rotation- and shearing operations, and modified the brightness, such that we get more training data.</p><p>The StyleGAN showed the most promising results. Starting out with a seed previously used to generate a face, we managed to train a GAN that produced something that remotely resembled art. Given that a computer is doing this, that's pretty neat!</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/11/retrain_morphing.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1621\" height=\"540\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/retrain_morphing.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/retrain_morphing.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/11/retrain_morphing.png 1600w, __GHOST_URL__/content/images/2021/11/retrain_morphing.png 1621w\" sizes=\"(min-width: 1200px) 1200px\"><figcaption>Progressively grown StyleGAN. The adversarial network first takes on the task of creating low-resolution art, and then progressively makes sharper images (fakes).</figcaption></figure><p></p><h2 id=\"more-reading\">More reading</h2><p>To read a more detailed report on this project, check out the Github page:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><a href=\"https://github.com/dunnkers/generative-adversarial-networks\"><img src=\"__GHOST_URL__/content/images/2021/11/github32-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"32\" height=\"32\"></a><figcaption><a href=\"https://github.com/dunnkers/generative-adversarial-networks\">generative-adversarial-networks</a></figcaption></figure>","comment_id":"61a3ede672c7ac1e2046244e","plaintext":"Generative Adversarial Networks (GAN's) are a relatively new type of technique for generating samples from a learned distribution, in which two networks are simultaneously trained whilst competing against each other. Applications for GAN‚Äôs are numerous, including image up-sampling, image generation, and the recently quite popular Deep Fakes. In this project, we aim to train such a Generative Adversarial Network ourselves, with the purpose of image generation, specifically. As the generation of human faces has been widely studied, we have chosen a different topic, namely: the generation of paintings. While large datasets of paintings are available, we have opted to restrict ourselves to one artist, as we believe this will give a better chance at producing realistic paintings. For this, we have chosen the Dutch artist Vincent van Gogh, who is known for his unique style.\n\n\nHow\n\nThere are many GAN architectures around. Some popular of which the DCGAN and the StyleGAN. We decided to train both and compare the results.\n\n * DCGAN. A GAN architecture that has been around for a while. Was trained using TensorFlow.\n * StyleGAN. A popular GAN architecture for generating faces, provisioned by NVIDIA Research. Also trained using TensorFlow.\n\nBoth were trained on the Van Gogh dataset, as available on Kaggle. Because the dataset contained only a limited amount of paintings (painting is, of course, a very time consuming activity), we decided to augment the dataset. Among others, we applied rotation- and shearing operations, and modified the brightness, such that we get more training data.\n\nThe StyleGAN showed the most promising results. Starting out with a seed previously used to generate a face, we managed to train a GAN that produced something that remotely resembled art. Given that a computer is doing this, that's pretty neat!\n\n\n\n\nMore reading\n\nTo read a more detailed report on this project, check out the Github page:","feature_image":"__GHOST_URL__/content/images/2021/11/morphing-1.png","featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","created_at":"2021-11-28 21:00:22","created_by":"1","updated_at":"2021-11-28 21:28:08","updated_by":null,"published_at":"2021-04-08 22:00:00","published_by":"1","custom_excerpt":"Can computers make art? To find out, we tried ourselves. We used Generative Adversarial Networks to try to paint new Van Gogh paintings.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c27d","uuid":"2fb4797a-e0fa-4a71-b8d2-e403d23aa134","title":"From Linear Regression to Neural Networks","slug":"from-linear-regression-to-neural-networks","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<h2>Linear Regression <small style=\\\"color:#ccc;\\\">(<a  style=\\\"color:#ccc;\\\" href=\\\"https://dunnkers.com/linear-regression-to-neural-networks/linear-regression.html\\\">Code</a>)</small></h2>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/linear-regression-flipper-vs-bodymass.svg\",\"alt\":\"Linear Regression fit on Penguin data using the normal equation. Using a validation data split of ¬º testing data and ¬æ training data.\",\"title\":\"\",\"width\":527,\"height\":388,\"caption\":\"Linear Regression fit on Penguin data using the normal equation. Using a validation data split of ¬º testing data and ¬æ training data.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/polynomial-degrees.svg\",\"alt\":\"Polynomial fits of various degrees on just $n=10$ training dataset samples. Testing dataset remained unchanged.\",\"title\":\"\",\"width\":576,\"height\":384,\"caption\":\"Polynomial fits of various degrees on just $n=10$ training dataset samples. Testing dataset remained unchanged.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/polynomial-fit.gif\",\"alt\":\"https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b7abbcf6-2bfe-492e-aa73-c4644924ec24/polynomial-fit.gif\",\"title\":\"\",\"width\":432,\"height\":288}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/ridge-vs-loss.svg\",\"alt\":\"Ridge Regression using all quantitative variables in the Penguin dataset to predict body mass. Varying subset sizes of the dataset $n$ as well as different regularization strengths $\\\\lambda$ are shown.\",\"title\":\"\",\"width\":768,\"height\":384}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Analytic_lower-vs-higher-dimensional.svg\",\"alt\":\"Linear Regression fitting times for lower- and higher- dimensional Penguin data.\",\"title\":\"\",\"width\":225,\"height\":142,\"caption\":\"Linear Regression fitting times for lower- and higher- dimensional Penguin data.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/SVGvsAnalytic_p2000.svg\",\"alt\":\"Fitting time and MSE loss differences of Linear Regression solved using SGD and analytically using the normal equation. 10 experiments are shown; each one is a dot. SGD uses $\\\\gamma^0=0.001$ with an inverse scaling schedule of $\\\\gamma^{r+1} = \\\\frac{\\\\gamma^0}{t^{0.25}}$ and 20 thousand iterations maximum.\",\"title\":\"\",\"width\":948,\"height\":460,\"caption\":\"Fitting time and MSE loss differences of Linear Regression solved using SGD and analytically using the normal equation. 10 experiments are shown; each one is a dot. SGD uses $\\\\gamma^0=0.001$ with an inverse scaling schedule of $\\\\gamma^{r+1} = \\\\frac{\\\\gamma^0}{t^{0.25}}$ and 20 thousand iterations maximum.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/SVGvsAnalytic_many_p.svg\",\"alt\":\"Fitting time and MSE loss for several degrees of dataset dimensionality. For each dimensionality, the average and its 95% confidence intervals over 10 experiments are shown. Loss plot is the average of the training and testing set.\",\"title\":\"\",\"width\":957,\"height\":442,\"caption\":\"Fitting time and MSE loss for several degrees of dataset dimensionality. For each dimensionality, the average and its 95% confidence intervals over 10 experiments are shown. Loss plot is the average of the training and testing set.\"}],[\"html\",{\"html\":\"<h2>Logistic Regression <small style=\\\"color:#ccc;\\\">(<a  style=\\\"color:#ccc;\\\" href=\\\"https://dunnkers.com/linear-regression-to-neural-networks/logistic-regression.html\\\">Code</a>)</small></h2>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/Logistic-curve.svg\",\"alt\":\"Sigmoid function $S(z)$. Given any number $z \\\\in \\\\mathbb{R}$ the function always returns a number in $[0, 1]$. Image: source.\",\"title\":\"\",\"width\":600,\"height\":400,\"caption\":\"Sigmoid function $S(z)$. Given any number $z \\\\in \\\\mathbb{R}$ the function always returns a number in $[0, 1]$. Image: <a href=\\\"https://en.wikipedia.org/wiki/Sigmoid_function#/media/File:Logistic-curve.svg\\\">source</a>.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/logistic-metrics.svg\",\"alt\":\"Logistic Regression model fit on a binary penguin classification task. The model converged at 88.2% training-, 89.7% testing accuracy and a loss of 0.304 on the training set.\",\"title\":\"\",\"width\":960,\"height\":336,\"caption\":\"Logistic Regression model fit on a binary penguin classification task. The model converged at 88.2% training-, 89.7% testing accuracy and a loss of 0.304 on the training set.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/logistic-fit.gif\",\"alt\":\"Logistic Regression model fit using SGD with constant learning rate of $\\\\gamma=0.001$ and $L^2$ regularization using $\\\\alpha=0.0005$ .\",\"title\":\"\",\"width\":432,\"height\":288,\"caption\":\"Logistic Regression model fit using SGD with constant learning rate of $\\\\gamma=0.001$ and $L^2$ regularization using $\\\\alpha=0.0005$.\"}],[\"html\",{\"html\":\"<h2>Neural Network <small style=\\\"color:#ccc;\\\">(<a  style=\\\"color:#ccc;\\\" href=\\\"https://dunnkers.com/linear-regression-to-neural-networks/neural-network.html\\\">Code</a>)</small></h2>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/nn.svg\",\"alt\":\"Neural Network architecture for 2-dimensional inputs and a 1-dimensional output with $l=3$ hidden layers each containing 5 neurons (image generated using NN-SVG).\",\"title\":\"\",\"caption\":\"Neural Network architecture for 2-dimensional inputs and a 1-dimensional output with $l=3$ hidden layers each containing 5 neurons (image generated using <a href=\\\"http://alexlenail.me/NN-SVG/\\\">NN-SVG</a>).\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/relu.svg\",\"alt\":\"ReLU activation function $\\\\sigma(z)=\\\\max \\\\{0,z\\\\}$. The function is easily seen to be piecewise-linear.\",\"title\":\"\",\"width\":480,\"height\":384,\"caption\":\"ReLU activation function $\\\\sigma(z)=\\\\max \\\\{0,z\\\\}$. The function is easily seen to be piecewise-linear.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/neural-metrics.svg\",\"alt\":\"Neural Network fit on a binary penguin classification task. The model converged at 96.5% training-, 94.9% testing accuracy and a loss of 0.108 on the training set.\",\"title\":\"\",\"width\":960,\"height\":336,\"caption\":\"Neural Network fit on a binary penguin classification task. The model converged at 96.5% training-, 94.9% testing accuracy and a loss of 0.108 on the training set.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/neural-fit.gif\",\"alt\":\"Neural Network fit performing a binary classification task on penguin species. Has 3 hidden layers of 5 nodes each; uses $L^2$ regularization with $\\\\alpha=0.0005$ and a constant learning rate of $\\\\gamma=0.001$.\",\"title\":\"\",\"width\":432,\"height\":288,\"caption\":\"Neural Network fit performing a binary classification task on penguin species. Has 3 hidden layers of 5 nodes each; uses $L^2$ regularization with $\\\\alpha=0.0005$ and a constant learning rate of $\\\\gamma=0.001$.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/github32-2.png\",\"width\":32,\"height\":32,\"caption\":\"<a href=\\\"https://github.com/dunnkers/linear-regression-to-neural-networks\\\">linear-regression-to-neural-networks</a>\",\"href\":\"https://github.com/dunnkers/linear-regression-to-neural-networks\"}]],\"markups\":[[\"a\",[\"href\",\"https://github.com/allisonhorst/penguins\"]],[\"em\"],[\"strong\"],[\"a\",[\"href\",\"https://dunnkers.com/linear-regression-to-neural-networks/images/penguin-pairplot.svg\"]],[\"a\",[\"href\",\"https://doi.org/10.1371/journal.pone.0090081\"]],[\"a\",[\"href\",\"https://web.stanford.edu/~hastie/ElemStatLearn/\"]],[\"a\",[\"href\",\"https://ieeexplore.ieee.org/abstract/document/8769211\"]],[\"a\",[\"href\",\"http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf\"]],[\"a\",[\"href\",\"https://www.deeplearningbook.org/\"]],[\"a\",[\"href\",\"https://www.sciencedirect.com/science/article/pii/S0893608098001166?casa_token=1Cj40vh2xXcAAAAA:Km2rWQK3qSQfFRp5u8RFongBdcCNOAGpBpa3g0nQO3lq7lUSG9ocYx2ExZfaz55dOWsAl102MDc\"]],[\"a\",[\"href\",\"https://dl.acm.org/doi/abs/10.1145/279232.279236?casa_token=vPvVfjPO5LYAAAAA:HRqyyBJ8KBVy09S8331ZV2pKZOfJrK820r6kuf9kxvpXi5y5DVQxGZzKN4eHeHYBaZ-DGqubi-oUaw\"]],[\"a\",[\"href\",\"https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf?source=post_page---------------------------\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1811.03378\"]],[\"a\",[\"href\",\"https://books.google.nl/books?hl=en&lr=&id=Mgs2FwtgNxwC&oi=fnd&pg=PA294&dq=occams+razor&ots=EMXQ4ohtev&sig=KRoX-dtpPwJNdPLujn4Qz7O3sI0&redir_esc=y#v=onepage&q&f=false\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"These days there exists much hype around sophisticated machine learning methods such as Neural Networks ‚Äî they are massively powerful models that allow us to fit very flexible models. However, we do not always require the full complexity of a Neural Network: sometimes, a simpler model will do the job just fine. In this project, we take a journey starting from the most fundamental statistical machinery to model data distributions, linear regression, to then explain the benefits of constructing more complex models, such as logistic regression or a Neural Network. In this way, this text aims to build a bridge from the statistical, analytical world to the more approximative world of Machine Learning. We will not shy away from the math, whilst still working with tangible examples at all times: we will work with real-world datasets and we will get to apply our models as we go on. Let's start!\"]]],[10,0],[1,\"p\",[[0,[],0,\"First, we will explore linear regression, for it is an easy to understand model upon which we can build more sophisticated concepts. We will use a \"],[0,[0],1,\"dataset\"],[0,[],0,\" on Antarctican penguins (Gorman et al., 2014) to conduct a regression between the penguin \"],[0,[1],1,\"flipper length\"],[0,[],0,\" as independent variable $X$ and the penguin \"],[0,[1],1,\"body mass\"],[0,[],0,\" as the dependent variable $Y$. We can analytically solve Linear Regression by minimizing the \"],[0,[1],1,\"Residual Sum-of-Squares\"],[0,[],0,\" cost function (Hastie et al., 2009):\"]]],[1,\"p\",[[0,[],0,\"$$\\\\text{R}(\\\\beta) = (Y - X \\\\beta)^T (Y - X \\\\beta)$$\"]]],[1,\"p\",[[0,[],0,\"In which $X$ is our \"],[0,[1],1,\"design matrix.\"],[0,[],0,\" Regression using this loss function is also referred to as \\\"Ordinary Least Squares\\\". The mean of the cost function $\\\\text{R}$ over all samples is called Mean Squared Error, or MSE. Our design matrix is built by appending each data row with a bias constant of 1 - an alternative would be to first center our data to get rid of the intercept entirely. To now minimize our cost function we differentiate $\\\\text{R}$ with respect to $\\\\beta$, giving us the following unique minimum:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\hat{\\\\beta} = (X^T X)^{-1} X^T Y$$\"]]],[1,\"p\",[[0,[],0,\"... which results in the estimated least-squares coefficients given the training data, also called the \"],[0,[1],1,\"normal equation\"],[0,[],0,\". We can classify by simply multiplying our input data with the found coefficient matrix: $\\\\hat{Y} = X \\\\hat{\\\\beta}$. Let's observe our fitted regression line onto the data:\"]]],[10,1],[1,\"p\",[[0,[],0,\"We can observe visually that our estimator explains both the training and testing data reasonably well: the line positioned itself along the mean of the data. This is in fact the proposition we make in least-squares - we assume the target to be Gaussian distributed; which in the case of modeling this natural phenomenon, penguins, seems to fit quite well.\"]]],[1,\"p\",[[0,[],0,\"Because at the moment we are very curious, we would also like to explore using a more flexible model. Note that our normal equation we defined above tries to find whatever parameters make the system of linear equations produce the best predictions on our target variable. This means, that hypothetically, we could add any linear combination of explanatory variables we like: such create estimators of a higher-order polynomial form. This is called \"],[0,[2],1,\"polynomial regression\"],[0,[],0,\". To illustrate, a design matrix for one explanatory variable $X_1$ would look as follows:\"]]],[1,\"p\",[[0,[],0,\"$$X= \\\\left[\\\\begin{array}{ccccc}1 & x_{1} & x_{1}^{2} & \\\\ldots & x_{1}^{d} \\\\\\\\ 1 & x_{2} & x_{2}^{2} & \\\\ldots & x_{2}^{d} \\\\\\\\ 1 & x_{3} & x_{3}^{2} & \\\\ldots & x_{3}^{d} \\\\\\\\ \\\\vdots & \\\\vdots & \\\\vdots & \\\\ddots & \\\\vdots \\\\\\\\ 1 & x_{n} & x_{n}^{2} & \\\\ldots & x_{n}^{d}\\\\end{array}\\\\right]$$\"]]],[1,\"p\",[[0,[],0,\"Which results in $d$-th degree polynomial regression. The case $d=1$ is just normal linear regression. For example sake, let us sample only $n=10$ samples from our training dataset, and try to fit those with a polynomial regressors of increasing degrees. Let us observe what happens to the training and testing loss accordingly:\"]]],[10,2],[1,\"p\",[[0,[],0,\"It can be observed that although for some degrees the losses remain almost the same, we suffer from overfitting after the degree passes $d=30$. We can also visually show how the polynomials of varying degrees fit our data:\"]]],[10,3],[1,\"p\",[[0,[],0,\"We can indeed observe that the polynomials of higher degree definitely do not better explain our data. Also, the polynomials tend to get rather erratic beyond the last data points of the training data - which is important to consider whenever predicting outside the training data value ranges. Generally, polynomials of exceedingly high degree can overfit too easily and should only be considered in very special cases.\"]]],[1,\"p\",[[0,[],0,\"Up till now our experiments have been relatively simple - we used only one explanatory and one response variable. Let us now explore an example in which we use all available explanatory variables to predict body mass, to see whether we can achieve an even better fit. Because we are now at risk of suffering from \"],[0,[1],1,\"multicolinearity\"],[0,[],0,\"; the situation where multiple explanatory variables are highly linearly related to each other, we will use an extension of linear regression which can deal with such a situation. The technique is called \"],[0,[2],1,\"Ridge Regression\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Ridge Regression\"]]],[1,\"p\",[[0,[],0,\"In Ridge Regression, we aim to tamper the least squares tendency to get as 'flexible' as possible to fit the data best it can. This might, however, cause parameters to get very large. We therefore like to add a penalty on the regression parameters $\\\\beta$; we penalise the loss function with a square of the parameter vector $\\\\beta$ scaled by new hyperparameter $\\\\lambda$. This is called a \"],[0,[1],1,\"shrinkage method\"],[0,[],0,\", or also: \"],[0,[2],1,\"regularization.\"],[0,[],0,\" This causes the squared loss function to become:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\text{R}(\\\\beta) = (Y - X \\\\beta)^T (Y - X \\\\beta)+\\\\lambda \\\\beta^T \\\\beta$$\"]]],[1,\"p\",[[0,[],0,\"This is called regularization with an $L^2$ norm; which generalization is called Tikhonov regularization, which allows for the case where not every parameter scalar is regularized equally. If we were to use an $L^1$ norm instead, we would speak of LASSO regression. If we were to now derive the solutions of $\\\\beta$ given this new cost function by differentiation w.r.t. $\\\\beta$:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\hat{\\\\beta}^{\\\\text {ridge }}=\\\\left(\\\\mathbf{X}^{T} \\\\mathbf{X}+\\\\lambda \\\\mathbf{I}\\\\right)^{-1} \\\\mathbf{X}^{T} \\\\mathbf{Y}$$\"]]],[1,\"p\",[[0,[],0,\"In which $\\\\lambda$ will be a scaling constant that controls the amount of regularization that is applied. Note $\\\\mathbf{I}$ is the $p\\\\times p$ identity matrix - in which $p$ are the amount of data dimensions used. An important intuition to be known about Ridge Regression, is that directions in the column space of $X$ with small variance will be shrinked the most; this behavior can be easily shown be deconstructing the least-squares fitted vector using a Singular Value Decomposition. That said, let us see whether we can benefit from this new technique in our experiment.\"]]],[1,\"p\",[[0,[],0,\"In the next experiment, we will now use \"],[0,[2],1,\"all\"],[0,[],0,\" available quantitative variables to try and predict the Penguin body mass. The Penguin- bill length, bill depth and flipper length will be used as independent variables. Note, however, they might be somewhat correlated: see \"],[0,[3],1,\"this pairplot\"],[0,[],0,\" on the Penguin data for details. This poses an interesting challenge for our regression. Let us combine this with varying dataset sample sizes and varying settings of $\\\\lambda$ to see the effects on our loss.\"]]],[10,4],[1,\"p\",[[0,[],0,\"Ridge Regression using all quantitative variables in the Penguin dataset to predict body mass. Varying subset sizes of the dataset $n$ as well as different regularization strengths $\\\\lambda$ are shown.\"]]],[1,\"p\",[[0,[],0,\"It can be observed, that using including all quantitative variables did improve the loss on predicting the Penguin body mass using Ridge Regression. In fact, the penalty imposed probably pulled the hyperplane angle down such that the error in fact increased. Ridge Regression is a very powerful technique, nonetheless, and most importantly introduced us to the concept of regularization. In the next chapters on Logistic Regression in Neural Networks, we assume all our models to use $L^2$ regularization.\"]]],[1,\"p\",[[0,[],0,\"Now, the data we fit up until now had only a small dimensionality - this is perhaps a drastic oversimplification in comparison to the real world. How does the analytic way of solving linear regression using the normal equation fare with \"],[0,[2],1,\"higher-dimensional data\"],[0,[],0,\"?\"]]],[1,\"h3\",[[0,[],0,\"High-dimensional data\"]]],[1,\"p\",[[0,[],0,\"In the real world, datasets might be of very high dimensionality: think of images, speech, or a biomedical dataset storing DNA sequences. These datasets cause different computational strain on the equations to be solved to fit a linear regression model: so let us \"],[0,[2],1,\"simulate\"],[0,[],0,\" such a high-dimensional situation.\"]]],[1,\"p\",[[0,[],0,\"In our simulation the amount of dimensions will configured to outmatch the amount of dataset samples ($p \\\\gg n$), which extra dimensions we will create by simply adding some noise columns to the design matrix $X$. The noise will be drawn from a Gaussian distribution $\\\\epsilon \\\\sim \\\\mathcal{N}(0, 1)$. We can now run an experiment by fitting our linear regression model to the higher-dimensional noised dataset, benchmarking the fitting times of the algorithm.\"]]],[10,5],[1,\"p\",[[0,[],0,\"We can observe that the normal equation takes \"],[0,[2],1,\"a lot\"],[0,[],0,\" longer to compute for higher-dimensional data. In fact, numerically computing the matrix inverse is very computationally expensive, i.e. computing $(X^TX)^{-1}$. Luckily, there are computationally cheaper techniques to do a regression in higher-dimensional spaces. One such technique is an iterative procedure, called \"],[0,[2],1,\"Gradient Descent\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Gradient Descent\"]]],[1,\"p\",[[0,[],0,\"Instead of trying to analytically solve the system of linear equations at once, we can choose an iterative procedure instead, such as Gradient Descent. It works by computing the gradient of the cost function with respect to the model weights - such that we can then move in the opposite direction of the gradient in parameter space. Given some loss function $R(\\\\beta)$ and $R_i(\\\\beta)$, which computes the empirical loss for entire dataset and for the $i$-th observation, respectively, we can define one gradient descent step as:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\begin{aligned} \\\\beta^{(r + 1)} &= \\\\beta^{(r)} - \\\\gamma \\\\nabla_{\\\\beta^{(r)}} R(\\\\beta^{(r)}) \\\\\\\\ &= \\\\beta^{(r)} - \\\\gamma \\\\sum_{i=1}^N \\\\frac{\\\\partial R_i(\\\\beta^{(r)})}{\\\\partial \\\\beta^{(r)}}\\\\\\\\ \\\\end{aligned}$$\"]]],[1,\"p\",[[0,[],0,\"In which $\\\\gamma$ is the learning rate and $r$ indicates some iteration - given some initial parameters $\\\\beta^0$ and $N$ training samples. Using this equation, we are able to reduce the loss in every iteration, until we converge. Convergence occurs when every element of the gradient is zero - or very close to it. Although gradient descent is used in this vanilla form, two modifications are common: (1) \"],[0,[2],1,\"subsampling\"],[0,[],0,\" and  using a (2) \"],[0,[2],1,\"learning rate schedule\"],[0,[],0,\".\"]]],[3,\"ol\",[[[0,[],0,\"Although in a scenario in which our loss function landscape is convex the vanilla variant does converge toward the global optimum relatively easily, this might not be the case for non-convex error landscapes. We are at risk of getting stuck in local extremes. In this case, it is desirable to introduce some randomness ‚Äî allowing us to jump out local extrema. We can introduce randomness by instead of computing the gradient over the entire sample set, we can do so for a random sample of the dataset called a \"],[0,[1],1,\"minibatch\"],[0,[],0,\" (Goodfellow et al., 2014). A side effect is a lighter computational burden per iteration; sometimes causing faster convergence. Because the introduced randomness makes the procedure stochastic instead of deterministic, we call this algorithm \"],[0,[1],1,\"Stochastic\"],[0,[],0,\" Gradient Descent, or simply \"],[0,[2],1,\"SGD\"],[0,[],0,\".\"]],[[0,[],0,\"Accommodating SGD is often a learning rate schedule: making the learning rate parameter $\\\\gamma$ dependent on the iteration number $r$ such that $\\\\gamma = \\\\gamma^{(r)}$. In this way, we made the learning rate adaptive over time, allowing us to create a custom learning rate scheme. Many schemes (Dogo et al., 2018) exist - which can be used to avoid spending a long time on flat areas in the error landscape called plateaus, or to avoid 'overshooting' the optimal solution. Even, a technique analogous with \"],[0,[1],1,\"momentum\"],[0,[],0,\" (Qian, 1999) in physics might be used: a particle traveling through space is 'accelerated' by the loss gradient, causing the gradient to change faster if it keeps going in the same direction.\"]]]],[1,\"p\",[[0,[],0,\"So, let's now redefine our gradient descent formula to accommodate for these modifications:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\beta^{(r+1)}=\\\\beta^{(r)}-\\\\gamma^{(r)} \\\\frac{1}{m} \\\\sum_{i=1}^m \\\\frac{\\\\partial R_i(\\\\beta^{(r)})}{\\\\partial \\\\beta^{(r)}} $$\"]]],[1,\"p\",[[0,[],0,\"... where we, before each iteration, randomly shuffle our training dataset such that we draw $m$ random samples each step. The variable $m$ denotes the \"],[0,[1],1,\"batch size\"],[0,[],0,\" - which can be anywhere between 1 and the amount of dataset samples minus one $N - 1$. The smaller the batch size, the more stochastic the procedure will get.\"]]],[1,\"p\",[[0,[],0,\"Using gradient descent for our linear regression is straight-forward. We differentiate the cost function with respect to the weights; the least squares derivative is then as follows:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\begin{aligned} \\\\frac{\\\\partial R_i(\\\\beta^{(r)})}{\\\\partial \\\\beta^{(r)}} &= \\\\frac{\\\\partial}{\\\\partial \\\\beta^{(r)}} (y_i - x_i \\\\beta^{(r)})^2\\\\\\\\ &= 2 (y_i - x_i \\\\beta^{(r)})\\\\\\\\ \\\\end{aligned}$$\"]]],[1,\"p\",[[0,[],0,\"We then run the algorithm in a loop, to iteratively get closer to the optimum parameter values.\"]]],[1,\"p\",[[0,[],0,\"Now, using this newly introduced iterative optimization procedure, let's see whether we can solve linear regression faster. First, we will compare SGD and the analytic method for our Penguin dataset with standard Gaussian noise dimensions added such that $p=2000$.\"]]],[10,6],[1,\"p\",[[0,[],0,\"Indeed - our iterative procedure is faster for such a high-dimensional dataset. Because the analytic method always finds the optimum value, it is most plausible that SGD does not achieve the same performance - as can be seen in the MSE loss in the figure. Only in a couple of runs does SGD achieve near-optimum performance - in the other cases the algorithm was either stopped by its maximum iterations limit or it got stuck in some local extrema and has not gotten out yet. If we wanted to get better results, we could have used a more lenient maximum amount of iterations or a stricter convergence condition. This is a clear trade-off between computational workload and the optimality of the solution. We can run some more experiments for various levels of augmented dimensions:\"]]],[10,7],[1,\"p\",[[0,[],0,\"In which we can empirically show that for our experiment, the analytic computation time grows about exponentially whilst SGD causes only a mild increase in computational time. SGD does suffer a higher loss due to its approximative nature - but this might just be worth the trade-off.\"]]],[1,\"p\",[[0,[],0,\"Now that we have gotten familiar with Gradient Descent, we can explore a realm of techniques that rely on being solved iteratively. Instead of doing regression, we will now try to \"],[0,[2],1,\"classify\"],[0,[],0,\" penguins by their species type ‚Äî a method for doing so is \"],[0,[2],1,\"Logistic Regression\"],[0,[],0,\".\"]]],[10,8],[1,\"p\",[[0,[],0,\"In general, linear regression is no good for classification. There is no notion incorporated into the objective function to desire a hyperplane that best separates two classes. Even if we would encode qualitative target variables in a quantitative way, i.e. in zeros or ones, a normal equation fit would result in predicted values outside the target range.\"]]],[1,\"p\",[[0,[],0,\"Therefore, we require a different scheme. In Logistic Regression, we first want to make sure all estimations remain in $[0,1]$. This can be done using the \"],[0,[2],1,\"Sigmoid function\"],[0,[],0,\":\"]]],[1,\"p\",[[0,[],0,\"$$S(z)=\\\\frac{e^z}{e^z+1}=\\\\frac{1}{1+e^{-z}}$$\"]]],[10,9],[1,\"p\",[[0,[],0,\"Also called the \"],[0,[1],1,\"Logistic function.\"],[0,[],0,\" So, the goal is to predict some class $G \\\\in \\\\{1,\\\\dots,K\\\\}$ given inputs $X$. We assume an intercept constant of 1 to be embedded in $X$. Now let us take a closer look at the case where $K=2$, i.e. the binary or \"],[0,[2],1,\"binomial\"],[0,[],0,\" case.\"]]],[1,\"p\",[[0,[],0,\"If we were to encode our class targets $Y$ as either ones or zeros, i.e. $Y \\\\in \\\\{0,1\\\\}$, we can predict values using $X \\\\beta$ and pull them through a sigmoid $S(X\\\\beta)$ to obtain the probabilities whether samples belongs to the class encoded as 1. This can be written as:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\begin{aligned} \\\\Pr(G=2|X;\\\\beta)&=S(X\\\\beta)\\\\\\\\ &=\\\\frac{1}{1+\\\\exp(-X\\\\beta)}\\\\\\\\ &=p(X;\\\\beta) \\\\end{aligned}$$\"]]],[1,\"p\",[[0,[],0,\"Because we consider only two classes, we can compute one probability and infer the other one, like so:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\begin{aligned} \\\\Pr(G=1|X;\\\\beta)&=1-p(X;\\\\beta) \\\\end{aligned}$$\"]]],[1,\"p\",[[0,[],0,\"For which it can be easily seen that both probabilities form a \"],[0,[1],1,\"probability vector\"],[0,[],0,\", i.e. their values sum to 1. Note we can consider the targets as a sequence of \"],[0,[1],1,\"Bernoulli trials\"],[0,[],0,\" $y_i,\\\\dots,y_N$ - each outcome a binary - assuming all observations are independent of one another. This allows us to write:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\begin{aligned} \\\\Pr (y| X;\\\\beta)&=p(X;\\\\beta)^y(1-p(X;\\\\beta))^{(1-y)}\\\\\\\\ \\\\end{aligned}$$\"]]],[1,\"p\",[[0,[],0,\"So, how to approximate $\\\\beta$? Like in linear regression, we can optimize a loss function to obtain an estimator $\\\\hat{\\\\beta}$. We can express the loss function as a likelihood using \"],[0,[1],1,\"Maximum Likelihood Estimation\"],[0,[],0,\". First, we express our objective into a conditional \"],[0,[2],1,\"likelihood\"],[0,[],0,\" function.\"]]],[1,\"p\",[[0,[],0,\"$$\\\\begin{aligned} L(\\\\beta)&=\\\\Pr (Y| X;\\\\beta)\\\\\\\\ &=\\\\prod_{i=1}^N \\\\Pr (y_i|X=x_i;\\\\beta)\\\\\\\\ &=\\\\prod_{i=1}^N p(x_i;\\\\beta)^{y_i}(1-p(x_i;\\\\beta))^{(1-y_i)} \\\\end{aligned}$$\"]]],[1,\"p\",[[0,[],0,\"The likelihood becomes easier to maximize in practice if we rewrite the product to a sum using a logarithm; such scaling does not change the resulting parameters. We obtain the \"],[0,[2],1,\"log-likelihood\"],[0,[],0,\" (Bischop, 2006):\"]]],[1,\"p\",[[0,[],0,\"$$\\\\begin{aligned} \\\\ell(\\\\beta)&=\\\\log L(\\\\beta)\\\\\\\\ &=\\\\sum_{i=1}^{N}\\\\left\\\\{y_{i} \\\\log p\\\\left(x_{i} ; \\\\beta\\\\right)+\\\\left(1-y_{i}\\\\right) \\\\log \\\\left(1-p\\\\left(x_{i} ; \\\\beta\\\\right)\\\\right)\\\\right\\\\}\\\\\\\\ &=\\\\sum_{i=1}^{N}\\\\left\\\\{y_{i} \\\\beta^{T} x_{i}-\\\\log \\\\left(1+e^{\\\\beta^{T} x_{i}}\\\\right)\\\\right\\\\} \\\\end{aligned}$$\"]]],[1,\"p\",[[0,[],0,\"Also called the \"],[0,[2,1],2,\"logistic loss\"],[0,[],0,\"; which multi-dimensional counterpart is the \"],[0,[1],1,\"cross-entropy\"],[0,[],0,\" loss. We can maximize this likelihood function by computing its gradient:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\frac{\\\\partial \\\\ell(\\\\beta)}{\\\\partial \\\\beta}=\\\\sum_{i=1}^{N} x_{i}\\\\left(y_{i}-p\\\\left(x_{i} ; \\\\beta\\\\right)\\\\right)$$\"]]],[1,\"p\",[[0,[],0,\"...resulting in $p+1$ equations nonlinear in $\\\\beta$. The equation is \"],[0,[1],1,\"transcendental\"],[0,[],0,\": meaning no closed-form solution exists and hence we cannot simply solve for zero. It is possible, however, to use numerical approximations: Newton-Raphson method based strategies can be used, such as Newton Conjugate-Gradient, or quasi-Newton procedures might be used such as L-BFGS (Zhu et al., 1997). Different strategies have varying benefits based on the problem type, e.g. the amount of samples $n$ or dimensions $p$. Since the gradient can be approximated just fine, we can also simply use Gradient Descent, i.e. SGD.\"]]],[1,\"p\",[[0,[],0,\"In the case where more response variables are to be predicted, i.e. $K>2$, a \"],[0,[2],1,\"multinomial\"],[0,[],0,\" variant of Logistic Regression can be used. For easier implementation, some software implementations just perform multiple binomial logistic regressions in order to conduct a multinomial one; which is called a One-versus-All strategy. The resulting probabilities are then normalized to still output a probability vector (Pedregosa et al., 2001).\"]]],[1,\"p\",[[0,[],0,\"That theory out of the way, let's fit a Logistic Regression model to our penguin data! We will try to classify whether a penguin is a Chinstrap yes or no, in other words: we will perform a binomial logistic regression. We will perform 30K iterations, each iteration an epoch over the training data:\"]]],[10,10],[1,\"p\",[[0,[],0,\"We can observe that the model converged to a stable state already after about 10K epochs - we could have implemented an early stopping rule; for example by checking whether validation scores stop improving or when our loss is no longer changing much. We can also visualize our model fit over time: by predicting over a grid of values at every time step during training. This yields the following animation:\"]]],[10,11],[1,\"p\",[[0,[],0,\"Clearly, our decision boundary is not optimal yet - whilst the data is somewhat Gaussian distributed our model linearly separates the data. We can do better ‚Äî we need some way to introduce more non-linearity into our model. A model that does just so is a \"],[0,[2],1,\"Neural Network\"],[0,[],0,\".\"]]],[10,12],[1,\"p\",[[0,[],0,\"At last, we arrive at the Neural Network. Using the previously learned concepts, we are really not that far off from assembling a Neural Network. Really, a single-layer Neural Network essentially just a linear model, like before. The difference is, that we conduct some extra projections in order to make the data better linearly separable. In a Neural Network, we aim to find the parameters facilitating such projections automatically. We call each such projection a \"],[0,[1],1,\"Hidden Layer\"],[0,[],0,\". After having conducted a suitable projection,  we can pull the projected data through a logistic function to estimate a probability - similarly to logistic regression. One such architecture is like so:\"]]],[10,13],[1,\"p\",[[0,[],0,\"So, given one input vector $x_i$, we can compute its estimated value by feeding its values through the network from left to right, in each layer multiplying with its parameter vector. We call this type of network \"],[0,[1],1,\"feed-forward\"],[0,[],0,\". Networks that do not feed forward include \"],[0,[1],1,\"recurrent\"],[0,[],0,\" or \"],[0,[1],1,\"recursive\"],[0,[],0,\" networks, though we will only concern ourselves with feed-forward networks for now.\"]]],[1,\"p\",[[0,[],0,\"An essential component of any such network is an \"],[0,[2,1],1,\"activation function\"],[0,[],1,\";\"],[0,[],0,\" a \"],[0,[1],1,\"non-linear\"],[0,[],0,\" differentiable function mapping $\\\\mathbb{R} \\\\rightarrow \\\\mathbb{R}$, aimed to overcome model linearity constraints. We apply the activation function to every hidden node; we compute the total input, add a bias, and then activate. This process is somewhat analogous to what happens in neurons in the brain - hence the name Neural Network. Among many possible activation functions (Nwankpa et al., 2018), a popular choice is the Rectified Linear Unit, or \"],[0,[2],1,\"ReLU\"],[0,[],0,\": $\\\\sigma(z)=\\\\max\\\\{0, z\\\\}$. It looks as follows:\"]]],[10,14],[1,\"p\",[[0,[],0,\"Also because ReLU is just a max operation, it is fast to compute (e.g. compared to a sigmoid). Using our activation function, we can define a \"],[0,[1],1,\"forward-pass\"],[0,[],0,\" through our network, as follows:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\begin{aligned} h^{(1)}&=\\\\sigma(X W^{(1)} + b^{(1)})\\\\\\\\ h^{(2)}&=\\\\sigma(h^{(1)} W^{(2)} + b^{(2)})\\\\\\\\ h^{(3)}&=\\\\sigma(h^{(2)} W^{(3)} + b^{(3)})\\\\\\\\ \\\\hat{Y}&=S(h^{(3)}W^{(4)}+b^{(4)}) \\\\end{aligned}$$\"]]],[1,\"p\",[[0,[],0,\"In which $h$ resembles the intermediate projections indexed by its hidden layer; and the parameters $\\\\beta$ mapping every two layers together are accessible through $W$. A bias vector is accessible through $b$, such to add a bias term to every node in the layer. Finally, we apply a Sigmoid to the results of the last layer to receive probability estimates; in the case of multi-class outputs its multi-dimensional counterpart is used, the \"],[0,[1],1,\"Softmax\"],[0,[],0,\", which normalizes the logistic function such to produce a probability vector. Do note that the activation function \"],[0,[1],1,\"could\"],[0,[],0,\" differ per layer; and in practice, this might happen. In our case, we will just use one activation function for all hidden layers in our network.\"]]],[1,\"p\",[[0,[],0,\"We are also going to have to define a \"],[0,[2],1,\"cost function\"],[0,[],0,\", such to be able to optimize the parameters based on its gradient. We can do so using the minimizing the negative log-likelihood using Maximum Likelihood, given some loss function such as:\"]]],[1,\"p\",[[0,[],0,\"$$ R(\\\\theta)=-\\\\mathbb{E}_{\\\\mathbf{x}, \\\\mathbf{y}\\\\sim\\\\hat{p}_{\\\\text{data }}}\\\\log p_{\\\\operatorname{model}}(\\\\boldsymbol{y}\\\\mid\\\\boldsymbol{x}) $$\"]]],[1,\"p\",[[0,[],0,\"In which we combined weights $W$ and biases $b$ into a single parameter term $\\\\theta$. Our cost function says to quantify the chance of encountering a target $y$ given an input vector $x$. Suitable loss functions to be used are log-loss/cross-entropy, or simply squared error:\"]]],[1,\"p\",[[0,[],0,\"$$ R(\\\\theta)=\\\\frac{1}{2}\\\\mathbb{E}_{\\\\mathbf{x}, \\\\mathbf{y}\\\\sim\\\\hat{p}_{\\\\text{data }}}\\\\|\\\\boldsymbol{y}-f(\\\\boldsymbol{x} ; \\\\boldsymbol{\\\\theta})\\\\|^{2}+ \\\\text{const} $$\"]]],[1,\"p\",[[0,[],0,\"Assuming $p_{\\\\text{model}}(y|x)$ to be Gaussian distributed. Of course, in any implementation we can only approach the expected value by averaging over a discrete set of observations; thus allowing us to compute the loss of our network.\"]]],[1,\"p\",[[0,[],0,\"Now that we are able to do a forward pass by (1) making predictions given a set of parameters $\\\\theta$ and (2) computing its loss using a cost function $R(\\\\theta)$, we will have to figure out how to actually \"],[0,[2],1,\"train\"],[0,[],0,\" our network. Because our computation involves quite some operations by now, computing the gradient of the cost function is not trivial - to approximate the full gradient one would have to compute partial derivatives with respect to every weight separately. Luckily, we can exploit the calculus chain rule to break up the problem into smaller pieces: allowing us to much more efficiently re-use previously computed answers. The algorithm using this trick is called \"],[0,[2],1,\"back-propagation\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"In back-propagation, we re-visit the network in reverse order; i.e. starting at the output layer and working our way back to the input layer. We then use the calculus derivative chain rule (Goodfellow et al., 2014):\"]]],[1,\"p\",[[0,[],0,\"$$\\\\begin{aligned} \\\\frac{\\\\partial z}{\\\\partial x_{i}}&=\\\\sum_{j} \\\\frac{\\\\partial z}{\\\\partial y_{j}} \\\\frac{\\\\partial y_{j}}{\\\\partial x_{i}}\\\\\\\\ &\\\\text{in vector notation:}\\\\\\\\ \\\\nabla_{\\\\boldsymbol{x}} z&=\\\\left(\\\\frac{\\\\partial \\\\boldsymbol{y}}{\\\\partial \\\\boldsymbol{x}}\\\\right)^{\\\\top} \\\\nabla_{\\\\boldsymbol{y}} z \\\\end{aligned}$$\"]]],[1,\"p\",[[0,[],0,\"...to compute the gradient in modular fashion. Note we need to consider the network in its entirety when computing the partial derivatives; the output activation, the loss function, node activations and the biases. To systematically apply back-prop to a network often these functions are abstracted as being an \"],[0,[1],1,\"operation\"],[0,[],0,\" - which can then be assembled in a \"],[0,[1],1,\"computational graph\"],[0,[],0,\". Given a suitable such graph, many generic back-prop implementations can be used.\"]]],[1,\"p\",[[0,[],0,\"Once we have now computed the derivative of the cost function $R(\\\\theta)$, our situation became similar to when we iteratively solved linear- or logistic regression: we can now use just Gradient Descent to move in the error landscape.\"]]],[1,\"p\",[[0,[],0,\"Now that we know how to train a Neural Network, let's apply it! We aim to get better accuracy for our Penguin classification problem than using our Logistic Regression model.\"]]],[10,15],[1,\"p\",[[0,[],0,\"Indeed, our more flexible Neural Network model better fits the data. The NN achieves 94.9% testing accuracy, in comparison to 89.7% testing accuracy for the Logistic Regression model. Let's see how our model is fitted over time:\"]]],[10,16],[1,\"p\",[[0,[],0,\"In which it can be observed that the model converged after some 750 iterations. Intuitively, the decision region looks to have been approximated fairly well - it might just have been slightly 'stretched' out.\"]]],[1,\"h3\",[[0,[],0,\"Ending note\"]]],[1,\"p\",[[0,[],0,\"Now that we have been able to fit a more 'complicated' data distribution, we conclude our journey from simple statistical models such a linear regression up to Neural Networks. Having a diverse set of statistical and iterative techniques in your tool belt is essential for any Machine Learning practitioner: even though immensely powerful models are available and widespread today, sometimes a simpler model will do just fine.\"]]],[1,\"p\",[[0,[],0,\"In tandem with how the bias/variance dilemma is fundamental to understanding how to construct good distribution learning models, one should always take into account not to overreach on model complexity given a learning task (Occam's Razor; Rasmussen et al., 2001): use an as simple as possible model, wherever possible.\"]]],[1,\"h2\",[[0,[],0,\"Citations\"]]],[3,\"ul\",[[[0,[4],1,\"Gorman KB, Williams TD, Fraser WR (2014). Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis). PLoS ONE 9(3):e90081.\"]],[[0,[5],1,\"Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Springer Science & Business Media.\"]],[[0,[6],1,\"Dogo, E. M., Afolabi, O. J., Nwulu, N. I., Twala, B., & Aigbavboa, C. O. (2018, December). A comparative analysis of gradient descent-based optimization algorithms on convolutional neural networks. In 2018 International Conference on Computational Techniques, Electronics and Mechanical Systems (CTEMS) (pp. 92-99). IEEE.\"]],[[0,[7],1,\"Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\"]],[[0,[8],1,\"Goodfellow, I., Bengio, Y., Courville, A., & Bengio, Y. (2016). Deep learning (Vol. 1, No. 2). Cambridge: MIT press.\"]],[[0,[9],1,\"Qian, N. (1999). On the momentum term in gradient descent learning algorithms. Neural networks, 12(1), 145-151.\"]],[[0,[10],1,\"Zhu, C., Byrd, R. H., Lu, P., & Nocedal, J. (1997). Algorithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained optimization. ACM Transactions on Mathematical Software (TOMS), 23(4), 550-560.\"]],[[0,[11],1,\"Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. the Journal of machine Learning research, 12, 2825-2830.\"]],[[0,[12],1,\"Nwankpa, C., Ijomah, W., Gachagan, A., & Marshall, S. (2018). Activation functions: Comparison of trends in practice and research for deep learning. arXiv preprint arXiv:1811.03378.\"]],[[0,[13],1,\"Rasmussen, C. E., & Ghahramani, Z. (2001). Occam's razor. Advances in neural information processing systems, 294-300.\"]]]],[1,\"p\",[]],[1,\"h2\",[[0,[],0,\"Code\"]]],[1,\"p\",[[0,[],0,\"The code is freely available on Github, see:\"]]],[10,17],[1,\"p\",[]],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>These days there exists much hype around sophisticated machine learning methods such as Neural Networks ‚Äî they are massively powerful models that allow us to fit very flexible models. However, we do not always require the full complexity of a Neural Network: sometimes, a simpler model will do the job just fine. In this project, we take a journey starting from the most fundamental statistical machinery to model data distributions, linear regression, to then explain the benefits of constructing more complex models, such as logistic regression or a Neural Network. In this way, this text aims to build a bridge from the statistical, analytical world to the more approximative world of Machine Learning. We will not shy away from the math, whilst still working with tangible examples at all times: we will work with real-world datasets and we will get to apply our models as we go on. Let's start!</p><!--kg-card-begin: html--><h2>Linear Regression <small style=\"color:#ccc;\">(<a  style=\"color:#ccc;\" href=\"https://dunnkers.com/linear-regression-to-neural-networks/linear-regression.html\">Code</a>)</small></h2><!--kg-card-end: html--><p>First, we will explore linear regression, for it is an easy to understand model upon which we can build more sophisticated concepts. We will use a <a href=\"https://github.com/allisonhorst/penguins\">dataset</a> on Antarctican penguins (Gorman et al., 2014) to conduct a regression between the penguin <em>flipper length</em> as independent variable $X$ and the penguin <em>body mass</em> as the dependent variable $Y$. We can analytically solve Linear Regression by minimizing the <em>Residual Sum-of-Squares</em> cost function (Hastie et al., 2009):</p><p>$$\\text{R}(\\beta) = (Y - X \\beta)^T (Y - X \\beta)$$</p><p>In which $X$ is our <em>design matrix.</em> Regression using this loss function is also referred to as \"Ordinary Least Squares\". The mean of the cost function $\\text{R}$ over all samples is called Mean Squared Error, or MSE. Our design matrix is built by appending each data row with a bias constant of 1 - an alternative would be to first center our data to get rid of the intercept entirely. To now minimize our cost function we differentiate $\\text{R}$ with respect to $\\beta$, giving us the following unique minimum:</p><p>$$\\hat{\\beta} = (X^T X)^{-1} X^T Y$$</p><p>... which results in the estimated least-squares coefficients given the training data, also called the <em>normal equation</em>. We can classify by simply multiplying our input data with the found coefficient matrix: $\\hat{Y} = X \\hat{\\beta}$. Let's observe our fitted regression line onto the data:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/linear-regression-flipper-vs-bodymass.svg\" class=\"kg-image\" alt=\"Linear Regression fit on Penguin data using the normal equation. Using a validation data split of ¬º testing data and ¬æ training data.\" loading=\"lazy\" width=\"527\" height=\"388\"><figcaption>Linear Regression fit on Penguin data using the normal equation. Using a validation data split of ¬º testing data and ¬æ training data.</figcaption></figure><p>We can observe visually that our estimator explains both the training and testing data reasonably well: the line positioned itself along the mean of the data. This is in fact the proposition we make in least-squares - we assume the target to be Gaussian distributed; which in the case of modeling this natural phenomenon, penguins, seems to fit quite well.</p><p>Because at the moment we are very curious, we would also like to explore using a more flexible model. Note that our normal equation we defined above tries to find whatever parameters make the system of linear equations produce the best predictions on our target variable. This means, that hypothetically, we could add any linear combination of explanatory variables we like: such create estimators of a higher-order polynomial form. This is called <strong>polynomial regression</strong>. To illustrate, a design matrix for one explanatory variable $X_1$ would look as follows:</p><p>$$X= \\left[\\begin{array}{ccccc}1 &amp; x_{1} &amp; x_{1}^{2} &amp; \\ldots &amp; x_{1}^{d} \\\\ 1 &amp; x_{2} &amp; x_{2}^{2} &amp; \\ldots &amp; x_{2}^{d} \\\\ 1 &amp; x_{3} &amp; x_{3}^{2} &amp; \\ldots &amp; x_{3}^{d} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_{n} &amp; x_{n}^{2} &amp; \\ldots &amp; x_{n}^{d}\\end{array}\\right]$$</p><p>Which results in $d$-th degree polynomial regression. The case $d=1$ is just normal linear regression. For example sake, let us sample only $n=10$ samples from our training dataset, and try to fit those with a polynomial regressors of increasing degrees. Let us observe what happens to the training and testing loss accordingly:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/polynomial-degrees.svg\" class=\"kg-image\" alt=\"Polynomial fits of various degrees on just $n=10$ training dataset samples. Testing dataset remained unchanged.\" loading=\"lazy\" width=\"576\" height=\"384\"><figcaption>Polynomial fits of various degrees on just $n=10$ training dataset samples. Testing dataset remained unchanged.</figcaption></figure><p>It can be observed that although for some degrees the losses remain almost the same, we suffer from overfitting after the degree passes $d=30$. We can also visually show how the polynomials of varying degrees fit our data:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/12/polynomial-fit.gif\" class=\"kg-image\" alt=\"https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b7abbcf6-2bfe-492e-aa73-c4644924ec24/polynomial-fit.gif\" loading=\"lazy\" width=\"432\" height=\"288\"></figure><p>We can indeed observe that the polynomials of higher degree definitely do not better explain our data. Also, the polynomials tend to get rather erratic beyond the last data points of the training data - which is important to consider whenever predicting outside the training data value ranges. Generally, polynomials of exceedingly high degree can overfit too easily and should only be considered in very special cases.</p><p>Up till now our experiments have been relatively simple - we used only one explanatory and one response variable. Let us now explore an example in which we use all available explanatory variables to predict body mass, to see whether we can achieve an even better fit. Because we are now at risk of suffering from <em>multicolinearity</em>; the situation where multiple explanatory variables are highly linearly related to each other, we will use an extension of linear regression which can deal with such a situation. The technique is called <strong>Ridge Regression</strong>.</p><h3 id=\"ridge-regression\">Ridge Regression</h3><p>In Ridge Regression, we aim to tamper the least squares tendency to get as 'flexible' as possible to fit the data best it can. This might, however, cause parameters to get very large. We therefore like to add a penalty on the regression parameters $\\beta$; we penalise the loss function with a square of the parameter vector $\\beta$ scaled by new hyperparameter $\\lambda$. This is called a <em>shrinkage method</em>, or also: <strong>regularization.</strong> This causes the squared loss function to become:</p><p>$$\\text{R}(\\beta) = (Y - X \\beta)^T (Y - X \\beta)+\\lambda \\beta^T \\beta$$</p><p>This is called regularization with an $L^2$ norm; which generalization is called Tikhonov regularization, which allows for the case where not every parameter scalar is regularized equally. If we were to use an $L^1$ norm instead, we would speak of LASSO regression. If we were to now derive the solutions of $\\beta$ given this new cost function by differentiation w.r.t. $\\beta$:</p><p>$$\\hat{\\beta}^{\\text {ridge }}=\\left(\\mathbf{X}^{T} \\mathbf{X}+\\lambda \\mathbf{I}\\right)^{-1} \\mathbf{X}^{T} \\mathbf{Y}$$</p><p>In which $\\lambda$ will be a scaling constant that controls the amount of regularization that is applied. Note $\\mathbf{I}$ is the $p\\times p$ identity matrix - in which $p$ are the amount of data dimensions used. An important intuition to be known about Ridge Regression, is that directions in the column space of $X$ with small variance will be shrinked the most; this behavior can be easily shown be deconstructing the least-squares fitted vector using a Singular Value Decomposition. That said, let us see whether we can benefit from this new technique in our experiment.</p><p>In the next experiment, we will now use <strong>all</strong> available quantitative variables to try and predict the Penguin body mass. The Penguin- bill length, bill depth and flipper length will be used as independent variables. Note, however, they might be somewhat correlated: see <a href=\"https://dunnkers.com/linear-regression-to-neural-networks/images/penguin-pairplot.svg\">this pairplot</a> on the Penguin data for details. This poses an interesting challenge for our regression. Let us combine this with varying dataset sample sizes and varying settings of $\\lambda$ to see the effects on our loss.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/12/ridge-vs-loss.svg\" class=\"kg-image\" alt=\"Ridge Regression using all quantitative variables in the Penguin dataset to predict body mass. Varying subset sizes of the dataset $n$ as well as different regularization strengths $\\lambda$ are shown.\" loading=\"lazy\" width=\"768\" height=\"384\"></figure><p>Ridge Regression using all quantitative variables in the Penguin dataset to predict body mass. Varying subset sizes of the dataset $n$ as well as different regularization strengths $\\lambda$ are shown.</p><p>It can be observed, that using including all quantitative variables did improve the loss on predicting the Penguin body mass using Ridge Regression. In fact, the penalty imposed probably pulled the hyperplane angle down such that the error in fact increased. Ridge Regression is a very powerful technique, nonetheless, and most importantly introduced us to the concept of regularization. In the next chapters on Logistic Regression in Neural Networks, we assume all our models to use $L^2$ regularization.</p><p>Now, the data we fit up until now had only a small dimensionality - this is perhaps a drastic oversimplification in comparison to the real world. How does the analytic way of solving linear regression using the normal equation fare with <strong>higher-dimensional data</strong>?</p><h3 id=\"high-dimensional-data\">High-dimensional data</h3><p>In the real world, datasets might be of very high dimensionality: think of images, speech, or a biomedical dataset storing DNA sequences. These datasets cause different computational strain on the equations to be solved to fit a linear regression model: so let us <strong>simulate</strong> such a high-dimensional situation.</p><p>In our simulation the amount of dimensions will configured to outmatch the amount of dataset samples ($p \\gg n$), which extra dimensions we will create by simply adding some noise columns to the design matrix $X$. The noise will be drawn from a Gaussian distribution $\\epsilon \\sim \\mathcal{N}(0, 1)$. We can now run an experiment by fitting our linear regression model to the higher-dimensional noised dataset, benchmarking the fitting times of the algorithm.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/Analytic_lower-vs-higher-dimensional.svg\" class=\"kg-image\" alt=\"Linear Regression fitting times for lower- and higher- dimensional Penguin data.\" loading=\"lazy\" width=\"225\" height=\"142\"><figcaption>Linear Regression fitting times for lower- and higher- dimensional Penguin data.</figcaption></figure><p>We can observe that the normal equation takes <strong>a lot</strong> longer to compute for higher-dimensional data. In fact, numerically computing the matrix inverse is very computationally expensive, i.e. computing $(X^TX)^{-1}$. Luckily, there are computationally cheaper techniques to do a regression in higher-dimensional spaces. One such technique is an iterative procedure, called <strong>Gradient Descent</strong>.</p><h3 id=\"gradient-descent\">Gradient Descent</h3><p>Instead of trying to analytically solve the system of linear equations at once, we can choose an iterative procedure instead, such as Gradient Descent. It works by computing the gradient of the cost function with respect to the model weights - such that we can then move in the opposite direction of the gradient in parameter space. Given some loss function $R(\\beta)$ and $R_i(\\beta)$, which computes the empirical loss for entire dataset and for the $i$-th observation, respectively, we can define one gradient descent step as:</p><p>$$\\begin{aligned} \\beta^{(r + 1)} &amp;= \\beta^{(r)} - \\gamma \\nabla_{\\beta^{(r)}} R(\\beta^{(r)}) \\\\ &amp;= \\beta^{(r)} - \\gamma \\sum_{i=1}^N \\frac{\\partial R_i(\\beta^{(r)})}{\\partial \\beta^{(r)}}\\\\ \\end{aligned}$$</p><p>In which $\\gamma$ is the learning rate and $r$ indicates some iteration - given some initial parameters $\\beta^0$ and $N$ training samples. Using this equation, we are able to reduce the loss in every iteration, until we converge. Convergence occurs when every element of the gradient is zero - or very close to it. Although gradient descent is used in this vanilla form, two modifications are common: (1) <strong>subsampling</strong> and ¬†using a (2) <strong>learning rate schedule</strong>.</p><ol><li>Although in a scenario in which our loss function landscape is convex the vanilla variant does converge toward the global optimum relatively easily, this might not be the case for non-convex error landscapes. We are at risk of getting stuck in local extremes. In this case, it is desirable to introduce some randomness ‚Äî allowing us to jump out local extrema. We can introduce randomness by instead of computing the gradient over the entire sample set, we can do so for a random sample of the dataset called a <em>minibatch</em> (Goodfellow et al., 2014). A side effect is a lighter computational burden per iteration; sometimes causing faster convergence. Because the introduced randomness makes the procedure stochastic instead of deterministic, we call this algorithm <em>Stochastic</em> Gradient Descent, or simply <strong>SGD</strong>.</li><li>Accommodating SGD is often a learning rate schedule: making the learning rate parameter $\\gamma$ dependent on the iteration number $r$ such that $\\gamma = \\gamma^{(r)}$. In this way, we made the learning rate adaptive over time, allowing us to create a custom learning rate scheme. Many schemes (Dogo et al., 2018) exist - which can be used to avoid spending a long time on flat areas in the error landscape called plateaus, or to avoid 'overshooting' the optimal solution. Even, a technique analogous with <em>momentum</em> (Qian, 1999) in physics might be used: a particle traveling through space is 'accelerated' by the loss gradient, causing the gradient to change faster if it keeps going in the same direction.</li></ol><p>So, let's now redefine our gradient descent formula to accommodate for these modifications:</p><p>$$\\beta^{(r+1)}=\\beta^{(r)}-\\gamma^{(r)} \\frac{1}{m} \\sum_{i=1}^m \\frac{\\partial R_i(\\beta^{(r)})}{\\partial \\beta^{(r)}} $$</p><p>... where we, before each iteration, randomly shuffle our training dataset such that we draw $m$ random samples each step. The variable $m$ denotes the <em>batch size</em> - which can be anywhere between 1 and the amount of dataset samples minus one $N - 1$. The smaller the batch size, the more stochastic the procedure will get.</p><p>Using gradient descent for our linear regression is straight-forward. We differentiate the cost function with respect to the weights; the least squares derivative is then as follows:</p><p>$$\\begin{aligned} \\frac{\\partial R_i(\\beta^{(r)})}{\\partial \\beta^{(r)}} &amp;= \\frac{\\partial}{\\partial \\beta^{(r)}} (y_i - x_i \\beta^{(r)})^2\\\\ &amp;= 2 (y_i - x_i \\beta^{(r)})\\\\ \\end{aligned}$$</p><p>We then run the algorithm in a loop, to iteratively get closer to the optimum parameter values.</p><p>Now, using this newly introduced iterative optimization procedure, let's see whether we can solve linear regression faster. First, we will compare SGD and the analytic method for our Penguin dataset with standard Gaussian noise dimensions added such that $p=2000$.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/SVGvsAnalytic_p2000.svg\" class=\"kg-image\" alt=\"Fitting time and MSE loss differences of Linear Regression solved using SGD and analytically using the normal equation. 10 experiments are shown; each one is a dot. SGD uses $\\gamma^0=0.001$ with an inverse scaling schedule of $\\gamma^{r+1} = \\frac{\\gamma^0}{t^{0.25}}$ and 20 thousand iterations maximum.\" loading=\"lazy\" width=\"948\" height=\"460\"><figcaption>Fitting time and MSE loss differences of Linear Regression solved using SGD and analytically using the normal equation. 10 experiments are shown; each one is a dot. SGD uses $\\gamma^0=0.001$ with an inverse scaling schedule of $\\gamma^{r+1} = \\frac{\\gamma^0}{t^{0.25}}$ and 20 thousand iterations maximum.</figcaption></figure><p>Indeed - our iterative procedure is faster for such a high-dimensional dataset. Because the analytic method always finds the optimum value, it is most plausible that SGD does not achieve the same performance - as can be seen in the MSE loss in the figure. Only in a couple of runs does SGD achieve near-optimum performance - in the other cases the algorithm was either stopped by its maximum iterations limit or it got stuck in some local extrema and has not gotten out yet. If we wanted to get better results, we could have used a more lenient maximum amount of iterations or a stricter convergence condition. This is a clear trade-off between computational workload and the optimality of the solution. We can run some more experiments for various levels of augmented dimensions:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/SVGvsAnalytic_many_p.svg\" class=\"kg-image\" alt=\"Fitting time and MSE loss for several degrees of dataset dimensionality. For each dimensionality, the average and its 95% confidence intervals over 10 experiments are shown. Loss plot is the average of the training and testing set.\" loading=\"lazy\" width=\"957\" height=\"442\"><figcaption>Fitting time and MSE loss for several degrees of dataset dimensionality. For each dimensionality, the average and its 95% confidence intervals over 10 experiments are shown. Loss plot is the average of the training and testing set.</figcaption></figure><p>In which we can empirically show that for our experiment, the analytic computation time grows about exponentially whilst SGD causes only a mild increase in computational time. SGD does suffer a higher loss due to its approximative nature - but this might just be worth the trade-off.</p><p>Now that we have gotten familiar with Gradient Descent, we can explore a realm of techniques that rely on being solved iteratively. Instead of doing regression, we will now try to <strong>classify</strong> penguins by their species type ‚Äî a method for doing so is <strong>Logistic Regression</strong>.</p><!--kg-card-begin: html--><h2>Logistic Regression <small style=\"color:#ccc;\">(<a  style=\"color:#ccc;\" href=\"https://dunnkers.com/linear-regression-to-neural-networks/logistic-regression.html\">Code</a>)</small></h2><!--kg-card-end: html--><p>In general, linear regression is no good for classification. There is no notion incorporated into the objective function to desire a hyperplane that best separates two classes. Even if we would encode qualitative target variables in a quantitative way, i.e. in zeros or ones, a normal equation fit would result in predicted values outside the target range.</p><p>Therefore, we require a different scheme. In Logistic Regression, we first want to make sure all estimations remain in $[0,1]$. This can be done using the <strong>Sigmoid function</strong>:</p><p>$$S(z)=\\frac{e^z}{e^z+1}=\\frac{1}{1+e^{-z}}$$</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/Logistic-curve.svg\" class=\"kg-image\" alt=\"Sigmoid function $S(z)$. Given any number $z \\in \\mathbb{R}$ the function always returns a number in $[0, 1]$. Image: source.\" loading=\"lazy\" width=\"600\" height=\"400\"><figcaption>Sigmoid function $S(z)$. Given any number $z \\in \\mathbb{R}$ the function always returns a number in $[0, 1]$. Image: <a href=\"https://en.wikipedia.org/wiki/Sigmoid_function#/media/File:Logistic-curve.svg\">source</a>.</figcaption></figure><p>Also called the <em>Logistic function.</em> So, the goal is to predict some class $G \\in \\{1,\\dots,K\\}$ given inputs $X$. We assume an intercept constant of 1 to be embedded in $X$. Now let us take a closer look at the case where $K=2$, i.e. the binary or <strong>binomial</strong> case.</p><p>If we were to encode our class targets $Y$ as either ones or zeros, i.e. $Y \\in \\{0,1\\}$, we can predict values using $X \\beta$ and pull them through a sigmoid $S(X\\beta)$ to obtain the probabilities whether samples belongs to the class encoded as 1. This can be written as:</p><p>$$\\begin{aligned} \\Pr(G=2|X;\\beta)&amp;=S(X\\beta)\\\\ &amp;=\\frac{1}{1+\\exp(-X\\beta)}\\\\ &amp;=p(X;\\beta) \\end{aligned}$$</p><p>Because we consider only two classes, we can compute one probability and infer the other one, like so:</p><p>$$\\begin{aligned} \\Pr(G=1|X;\\beta)&amp;=1-p(X;\\beta) \\end{aligned}$$</p><p>For which it can be easily seen that both probabilities form a <em>probability vector</em>, i.e. their values sum to 1. Note we can consider the targets as a sequence of <em>Bernoulli trials</em> $y_i,\\dots,y_N$ - each outcome a binary - assuming all observations are independent of one another. This allows us to write:</p><p>$$\\begin{aligned} \\Pr (y| X;\\beta)&amp;=p(X;\\beta)^y(1-p(X;\\beta))^{(1-y)}\\\\ \\end{aligned}$$</p><p>So, how to approximate $\\beta$? Like in linear regression, we can optimize a loss function to obtain an estimator $\\hat{\\beta}$. We can express the loss function as a likelihood using <em>Maximum Likelihood Estimation</em>. First, we express our objective into a conditional <strong>likelihood</strong> function.</p><p>$$\\begin{aligned} L(\\beta)&amp;=\\Pr (Y| X;\\beta)\\\\ &amp;=\\prod_{i=1}^N \\Pr (y_i|X=x_i;\\beta)\\\\ &amp;=\\prod_{i=1}^N p(x_i;\\beta)^{y_i}(1-p(x_i;\\beta))^{(1-y_i)} \\end{aligned}$$</p><p>The likelihood becomes easier to maximize in practice if we rewrite the product to a sum using a logarithm; such scaling does not change the resulting parameters. We obtain the <strong>log-likelihood</strong> (Bischop, 2006):</p><p>$$\\begin{aligned} \\ell(\\beta)&amp;=\\log L(\\beta)\\\\ &amp;=\\sum_{i=1}^{N}\\left\\{y_{i} \\log p\\left(x_{i} ; \\beta\\right)+\\left(1-y_{i}\\right) \\log \\left(1-p\\left(x_{i} ; \\beta\\right)\\right)\\right\\}\\\\ &amp;=\\sum_{i=1}^{N}\\left\\{y_{i} \\beta^{T} x_{i}-\\log \\left(1+e^{\\beta^{T} x_{i}}\\right)\\right\\} \\end{aligned}$$</p><p>Also called the <strong><em>logistic loss</em></strong>; which multi-dimensional counterpart is the <em>cross-entropy</em> loss. We can maximize this likelihood function by computing its gradient:</p><p>$$\\frac{\\partial \\ell(\\beta)}{\\partial \\beta}=\\sum_{i=1}^{N} x_{i}\\left(y_{i}-p\\left(x_{i} ; \\beta\\right)\\right)$$</p><p>...resulting in $p+1$ equations nonlinear in $\\beta$. The equation is <em>transcendental</em>: meaning no closed-form solution exists and hence we cannot simply solve for zero. It is possible, however, to use numerical approximations: Newton-Raphson method based strategies can be used, such as Newton Conjugate-Gradient, or quasi-Newton procedures might be used such as L-BFGS (Zhu et al., 1997). Different strategies have varying benefits based on the problem type, e.g. the amount of samples $n$ or dimensions $p$. Since the gradient can be approximated just fine, we can also simply use Gradient Descent, i.e. SGD.</p><p>In the case where more response variables are to be predicted, i.e. $K&gt;2$, a <strong>multinomial</strong> variant of Logistic Regression can be used. For easier implementation, some software implementations just perform multiple binomial logistic regressions in order to conduct a multinomial one; which is called a One-versus-All strategy. The resulting probabilities are then normalized to still output a probability vector (Pedregosa et al., 2001).</p><p>That theory out of the way, let's fit a Logistic Regression model to our penguin data! We will try to classify whether a penguin is a Chinstrap yes or no, in other words: we will perform a binomial logistic regression. We will perform 30K iterations, each iteration an epoch over the training data:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/logistic-metrics.svg\" class=\"kg-image\" alt=\"Logistic Regression model fit on a binary penguin classification task. The model converged at 88.2% training-, 89.7% testing accuracy and a loss of 0.304 on the training set.\" loading=\"lazy\" width=\"960\" height=\"336\"><figcaption>Logistic Regression model fit on a binary penguin classification task. The model converged at 88.2% training-, 89.7% testing accuracy and a loss of 0.304 on the training set.</figcaption></figure><p>We can observe that the model converged to a stable state already after about 10K epochs - we could have implemented an early stopping rule; for example by checking whether validation scores stop improving or when our loss is no longer changing much. We can also visualize our model fit over time: by predicting over a grid of values at every time step during training. This yields the following animation:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/logistic-fit.gif\" class=\"kg-image\" alt=\"Logistic Regression model fit using SGD with constant learning rate of $\\gamma=0.001$ and $L^2$ regularization using $\\alpha=0.0005$ .\" loading=\"lazy\" width=\"432\" height=\"288\"><figcaption>Logistic Regression model fit using SGD with constant learning rate of $\\gamma=0.001$ and $L^2$ regularization using $\\alpha=0.0005$.</figcaption></figure><p>Clearly, our decision boundary is not optimal yet - whilst the data is somewhat Gaussian distributed our model linearly separates the data. We can do better ‚Äî we need some way to introduce more non-linearity into our model. A model that does just so is a <strong>Neural Network</strong>.</p><!--kg-card-begin: html--><h2>Neural Network <small style=\"color:#ccc;\">(<a  style=\"color:#ccc;\" href=\"https://dunnkers.com/linear-regression-to-neural-networks/neural-network.html\">Code</a>)</small></h2><!--kg-card-end: html--><p>At last, we arrive at the Neural Network. Using the previously learned concepts, we are really not that far off from assembling a Neural Network. Really, a single-layer Neural Network essentially just a linear model, like before. The difference is, that we conduct some extra projections in order to make the data better linearly separable. In a Neural Network, we aim to find the parameters facilitating such projections automatically. We call each such projection a <em>Hidden Layer</em>. After having conducted a suitable projection, ¬†we can pull the projected data through a logistic function to estimate a probability - similarly to logistic regression. One such architecture is like so:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/nn.svg\" class=\"kg-image\" alt=\"Neural Network architecture for 2-dimensional inputs and a 1-dimensional output with $l=3$ hidden layers each containing 5 neurons (image generated using NN-SVG).\" loading=\"lazy\"><figcaption>Neural Network architecture for 2-dimensional inputs and a 1-dimensional output with $l=3$ hidden layers each containing 5 neurons (image generated using <a href=\"http://alexlenail.me/NN-SVG/\">NN-SVG</a>).</figcaption></figure><p>So, given one input vector $x_i$, we can compute its estimated value by feeding its values through the network from left to right, in each layer multiplying with its parameter vector. We call this type of network <em>feed-forward</em>. Networks that do not feed forward include <em>recurrent</em> or <em>recursive</em> networks, though we will only concern ourselves with feed-forward networks for now.</p><p>An essential component of any such network is an <strong><em>activation function</em>;</strong> a <em>non-linear</em> differentiable function mapping $\\mathbb{R} \\rightarrow \\mathbb{R}$, aimed to overcome model linearity constraints. We apply the activation function to every hidden node; we compute the total input, add a bias, and then activate. This process is somewhat analogous to what happens in neurons in the brain - hence the name Neural Network. Among many possible activation functions (Nwankpa et al., 2018), a popular choice is the Rectified Linear Unit, or <strong>ReLU</strong>: $\\sigma(z)=\\max\\{0, z\\}$. It looks as follows:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/relu.svg\" class=\"kg-image\" alt=\"ReLU activation function $\\sigma(z)=\\max \\{0,z\\}$. The function is easily seen to be piecewise-linear.\" loading=\"lazy\" width=\"480\" height=\"384\"><figcaption>ReLU activation function $\\sigma(z)=\\max \\{0,z\\}$. The function is easily seen to be piecewise-linear.</figcaption></figure><p>Also because ReLU is just a max operation, it is fast to compute (e.g. compared to a sigmoid). Using our activation function, we can define a <em>forward-pass</em> through our network, as follows:</p><p>$$\\begin{aligned} h^{(1)}&amp;=\\sigma(X W^{(1)} + b^{(1)})\\\\ h^{(2)}&amp;=\\sigma(h^{(1)} W^{(2)} + b^{(2)})\\\\ h^{(3)}&amp;=\\sigma(h^{(2)} W^{(3)} + b^{(3)})\\\\ \\hat{Y}&amp;=S(h^{(3)}W^{(4)}+b^{(4)}) \\end{aligned}$$</p><p>In which $h$ resembles the intermediate projections indexed by its hidden layer; and the parameters $\\beta$ mapping every two layers together are accessible through $W$. A bias vector is accessible through $b$, such to add a bias term to every node in the layer. Finally, we apply a Sigmoid to the results of the last layer to receive probability estimates; in the case of multi-class outputs its multi-dimensional counterpart is used, the <em>Softmax</em>, which normalizes the logistic function such to produce a probability vector. Do note that the activation function <em>could</em> differ per layer; and in practice, this might happen. In our case, we will just use one activation function for all hidden layers in our network.</p><p>We are also going to have to define a <strong>cost function</strong>, such to be able to optimize the parameters based on its gradient. We can do so using the minimizing the negative log-likelihood using Maximum Likelihood, given some loss function such as:</p><p>$$ R(\\theta)=-\\mathbb{E}_{\\mathbf{x}, \\mathbf{y}\\sim\\hat{p}_{\\text{data }}}\\log p_{\\operatorname{model}}(\\boldsymbol{y}\\mid\\boldsymbol{x}) $$</p><p>In which we combined weights $W$ and biases $b$ into a single parameter term $\\theta$. Our cost function says to quantify the chance of encountering a target $y$ given an input vector $x$. Suitable loss functions to be used are log-loss/cross-entropy, or simply squared error:</p><p>$$ R(\\theta)=\\frac{1}{2}\\mathbb{E}_{\\mathbf{x}, \\mathbf{y}\\sim\\hat{p}_{\\text{data }}}\\|\\boldsymbol{y}-f(\\boldsymbol{x} ; \\boldsymbol{\\theta})\\|^{2}+ \\text{const} $$</p><p>Assuming $p_{\\text{model}}(y|x)$ to be Gaussian distributed. Of course, in any implementation we can only approach the expected value by averaging over a discrete set of observations; thus allowing us to compute the loss of our network.</p><p>Now that we are able to do a forward pass by (1) making predictions given a set of parameters $\\theta$ and (2) computing its loss using a cost function $R(\\theta)$, we will have to figure out how to actually <strong>train</strong> our network. Because our computation involves quite some operations by now, computing the gradient of the cost function is not trivial - to approximate the full gradient one would have to compute partial derivatives with respect to every weight separately. Luckily, we can exploit the calculus chain rule to break up the problem into smaller pieces: allowing us to much more efficiently re-use previously computed answers. The algorithm using this trick is called <strong>back-propagation</strong>.</p><p>In back-propagation, we re-visit the network in reverse order; i.e. starting at the output layer and working our way back to the input layer. We then use the calculus derivative chain rule (Goodfellow et al., 2014):</p><p>$$\\begin{aligned} \\frac{\\partial z}{\\partial x_{i}}&amp;=\\sum_{j} \\frac{\\partial z}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial x_{i}}\\\\ &amp;\\text{in vector notation:}\\\\ \\nabla_{\\boldsymbol{x}} z&amp;=\\left(\\frac{\\partial \\boldsymbol{y}}{\\partial \\boldsymbol{x}}\\right)^{\\top} \\nabla_{\\boldsymbol{y}} z \\end{aligned}$$</p><p>...to compute the gradient in modular fashion. Note we need to consider the network in its entirety when computing the partial derivatives; the output activation, the loss function, node activations and the biases. To systematically apply back-prop to a network often these functions are abstracted as being an <em>operation</em> - which can then be assembled in a <em>computational graph</em>. Given a suitable such graph, many generic back-prop implementations can be used.</p><p>Once we have now computed the derivative of the cost function $R(\\theta)$, our situation became similar to when we iteratively solved linear- or logistic regression: we can now use just Gradient Descent to move in the error landscape.</p><p>Now that we know how to train a Neural Network, let's apply it! We aim to get better accuracy for our Penguin classification problem than using our Logistic Regression model.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/neural-metrics.svg\" class=\"kg-image\" alt=\"Neural Network fit on a binary penguin classification task. The model converged at 96.5% training-, 94.9% testing accuracy and a loss of 0.108 on the training set.\" loading=\"lazy\" width=\"960\" height=\"336\"><figcaption>Neural Network fit on a binary penguin classification task. The model converged at 96.5% training-, 94.9% testing accuracy and a loss of 0.108 on the training set.</figcaption></figure><p>Indeed, our more flexible Neural Network model better fits the data. The NN achieves 94.9% testing accuracy, in comparison to 89.7% testing accuracy for the Logistic Regression model. Let's see how our model is fitted over time:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/12/neural-fit.gif\" class=\"kg-image\" alt=\"Neural Network fit performing a binary classification task on penguin species. Has 3 hidden layers of 5 nodes each; uses $L^2$ regularization with $\\alpha=0.0005$ and a constant learning rate of $\\gamma=0.001$.\" loading=\"lazy\" width=\"432\" height=\"288\"><figcaption>Neural Network fit performing a binary classification task on penguin species. Has 3 hidden layers of 5 nodes each; uses $L^2$ regularization with $\\alpha=0.0005$ and a constant learning rate of $\\gamma=0.001$.</figcaption></figure><p>In which it can be observed that the model converged after some 750 iterations. Intuitively, the decision region looks to have been approximated fairly well - it might just have been slightly 'stretched' out.</p><h3 id=\"ending-note\">Ending note</h3><p>Now that we have been able to fit a more 'complicated' data distribution, we conclude our journey from simple statistical models such a linear regression up to Neural Networks. Having a diverse set of statistical and iterative techniques in your tool belt is essential for any Machine Learning practitioner: even though immensely powerful models are available and widespread today, sometimes a simpler model will do just fine.</p><p>In tandem with how the bias/variance dilemma is fundamental to understanding how to construct good distribution learning models, one should always take into account not to overreach on model complexity given a learning task (Occam's Razor; Rasmussen et al., 2001): use an as simple as possible model, wherever possible.</p><h2 id=\"citations\">Citations</h2><ul><li><a href=\"https://doi.org/10.1371/journal.pone.0090081\">Gorman KB, Williams TD, Fraser WR (2014). Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis). PLoS ONE 9(3):e90081.</a></li><li><a href=\"https://web.stanford.edu/~hastie/ElemStatLearn/\">Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Springer Science &amp; Business Media.</a></li><li><a href=\"https://ieeexplore.ieee.org/abstract/document/8769211\">Dogo, E. M., Afolabi, O. J., Nwulu, N. I., Twala, B., &amp; Aigbavboa, C. O. (2018, December). A comparative analysis of gradient descent-based optimization algorithms on convolutional neural networks. In 2018 International Conference on Computational Techniques, Electronics and Mechanical Systems (CTEMS) (pp. 92-99). IEEE.</a></li><li><a href=\"http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf\">Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.</a></li><li><a href=\"https://www.deeplearningbook.org/\">Goodfellow, I., Bengio, Y., Courville, A., &amp; Bengio, Y. (2016). Deep learning (Vol. 1, No. 2). Cambridge: MIT press.</a></li><li><a href=\"https://www.sciencedirect.com/science/article/pii/S0893608098001166?casa_token=1Cj40vh2xXcAAAAA:Km2rWQK3qSQfFRp5u8RFongBdcCNOAGpBpa3g0nQO3lq7lUSG9ocYx2ExZfaz55dOWsAl102MDc\">Qian, N. (1999). On the momentum term in gradient descent learning algorithms. Neural networks, 12(1), 145-151.</a></li><li><a href=\"https://dl.acm.org/doi/abs/10.1145/279232.279236?casa_token=vPvVfjPO5LYAAAAA:HRqyyBJ8KBVy09S8331ZV2pKZOfJrK820r6kuf9kxvpXi5y5DVQxGZzKN4eHeHYBaZ-DGqubi-oUaw\">Zhu, C., Byrd, R. H., Lu, P., &amp; Nocedal, J. (1997). Algorithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained optimization. ACM Transactions on Mathematical Software (TOMS), 23(4), 550-560.</a></li><li><a href=\"https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf?source=post_page---------------------------\">Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... &amp; Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. the Journal of machine Learning research, 12, 2825-2830.</a></li><li><a href=\"https://arxiv.org/abs/1811.03378\">Nwankpa, C., Ijomah, W., Gachagan, A., &amp; Marshall, S. (2018). Activation functions: Comparison of trends in practice and research for deep learning. arXiv preprint arXiv:1811.03378.</a></li><li><a href=\"https://books.google.nl/books?hl=en&amp;lr=&amp;id=Mgs2FwtgNxwC&amp;oi=fnd&amp;pg=PA294&amp;dq=occams+razor&amp;ots=EMXQ4ohtev&amp;sig=KRoX-dtpPwJNdPLujn4Qz7O3sI0&amp;redir_esc=y#v=onepage&amp;q&amp;f=false\">Rasmussen, C. E., &amp; Ghahramani, Z. (2001). Occam's razor. Advances in neural information processing systems, 294-300.</a></li></ul><p></p><h2 id=\"code\">Code</h2><p>The code is freely available on Github, see:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><a href=\"https://github.com/dunnkers/linear-regression-to-neural-networks\"><img src=\"__GHOST_URL__/content/images/2021/11/github32-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"32\" height=\"32\"></a><figcaption><a href=\"https://github.com/dunnkers/linear-regression-to-neural-networks\">linear-regression-to-neural-networks</a></figcaption></figure><p></p><p></p>","comment_id":"61a3f4cf72c7ac1e204625a3","plaintext":"These days there exists much hype around sophisticated machine learning methods such as Neural Networks ‚Äî they are massively powerful models that allow us to fit very flexible models. However, we do not always require the full complexity of a Neural Network: sometimes, a simpler model will do the job just fine. In this project, we take a journey starting from the most fundamental statistical machinery to model data distributions, linear regression, to then explain the benefits of constructing more complex models, such as logistic regression or a Neural Network. In this way, this text aims to build a bridge from the statistical, analytical world to the more approximative world of Machine Learning. We will not shy away from the math, whilst still working with tangible examples at all times: we will work with real-world datasets and we will get to apply our models as we go on. Let's start!\n\n\nLinear Regression (Code)\n\nFirst, we will explore linear regression, for it is an easy to understand model upon which we can build more sophisticated concepts. We will use a dataset on Antarctican penguins (Gorman et al., 2014) to conduct a regression between the penguin flipper length as independent variable $X$ and the penguin body mass as the dependent variable $Y$. We can analytically solve Linear Regression by minimizing the Residual Sum-of-Squares cost function (Hastie et al., 2009):\n\n$$\\text{R}(\\beta) = (Y - X \\beta)^T (Y - X \\beta)$$\n\nIn which $X$ is our design matrix. Regression using this loss function is also referred to as \"Ordinary Least Squares\". The mean of the cost function $\\text{R}$ over all samples is called Mean Squared Error, or MSE. Our design matrix is built by appending each data row with a bias constant of 1 - an alternative would be to first center our data to get rid of the intercept entirely. To now minimize our cost function we differentiate $\\text{R}$ with respect to $\\beta$, giving us the following unique minimum:\n\n$$\\hat{\\beta} = (X^T X)^{-1} X^T Y$$\n\n... which results in the estimated least-squares coefficients given the training data, also called the normal equation. We can classify by simply multiplying our input data with the found coefficient matrix: $\\hat{Y} = X \\hat{\\beta}$. Let's observe our fitted regression line onto the data:\n\nWe can observe visually that our estimator explains both the training and testing data reasonably well: the line positioned itself along the mean of the data. This is in fact the proposition we make in least-squares - we assume the target to be Gaussian distributed; which in the case of modeling this natural phenomenon, penguins, seems to fit quite well.\n\nBecause at the moment we are very curious, we would also like to explore using a more flexible model. Note that our normal equation we defined above tries to find whatever parameters make the system of linear equations produce the best predictions on our target variable. This means, that hypothetically, we could add any linear combination of explanatory variables we like: such create estimators of a higher-order polynomial form. This is called polynomial regression. To illustrate, a design matrix for one explanatory variable $X_1$ would look as follows:\n\n$$X= \\left[\\begin{array}{ccccc}1 & x_{1} & x_{1}^{2} & \\ldots & x_{1}^{d} \\\\ 1 & x_{2} & x_{2}^{2} & \\ldots & x_{2}^{d} \\\\ 1 & x_{3} & x_{3}^{2} & \\ldots & x_{3}^{d} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n} & x_{n}^{2} & \\ldots & x_{n}^{d}\\end{array}\\right]$$\n\nWhich results in $d$-th degree polynomial regression. The case $d=1$ is just normal linear regression. For example sake, let us sample only $n=10$ samples from our training dataset, and try to fit those with a polynomial regressors of increasing degrees. Let us observe what happens to the training and testing loss accordingly:\n\nIt can be observed that although for some degrees the losses remain almost the same, we suffer from overfitting after the degree passes $d=30$. We can also visually show how the polynomials of varying degrees fit our data:\n\nWe can indeed observe that the polynomials of higher degree definitely do not better explain our data. Also, the polynomials tend to get rather erratic beyond the last data points of the training data - which is important to consider whenever predicting outside the training data value ranges. Generally, polynomials of exceedingly high degree can overfit too easily and should only be considered in very special cases.\n\nUp till now our experiments have been relatively simple - we used only one explanatory and one response variable. Let us now explore an example in which we use all available explanatory variables to predict body mass, to see whether we can achieve an even better fit. Because we are now at risk of suffering from multicolinearity; the situation where multiple explanatory variables are highly linearly related to each other, we will use an extension of linear regression which can deal with such a situation. The technique is called Ridge Regression.\n\n\nRidge Regression\n\nIn Ridge Regression, we aim to tamper the least squares tendency to get as 'flexible' as possible to fit the data best it can. This might, however, cause parameters to get very large. We therefore like to add a penalty on the regression parameters $\\beta$; we penalise the loss function with a square of the parameter vector $\\beta$ scaled by new hyperparameter $\\lambda$. This is called a shrinkage method, or also: regularization. This causes the squared loss function to become:\n\n$$\\text{R}(\\beta) = (Y - X \\beta)^T (Y - X \\beta)+\\lambda \\beta^T \\beta$$\n\nThis is called regularization with an $L^2$ norm; which generalization is called Tikhonov regularization, which allows for the case where not every parameter scalar is regularized equally. If we were to use an $L^1$ norm instead, we would speak of LASSO regression. If we were to now derive the solutions of $\\beta$ given this new cost function by differentiation w.r.t. $\\beta$:\n\n$$\\hat{\\beta}^{\\text {ridge }}=\\left(\\mathbf{X}^{T} \\mathbf{X}+\\lambda \\mathbf{I}\\right)^{-1} \\mathbf{X}^{T} \\mathbf{Y}$$\n\nIn which $\\lambda$ will be a scaling constant that controls the amount of regularization that is applied. Note $\\mathbf{I}$ is the $p\\times p$ identity matrix - in which $p$ are the amount of data dimensions used. An important intuition to be known about Ridge Regression, is that directions in the column space of $X$ with small variance will be shrinked the most; this behavior can be easily shown be deconstructing the least-squares fitted vector using a Singular Value Decomposition. That said, let us see whether we can benefit from this new technique in our experiment.\n\nIn the next experiment, we will now use all available quantitative variables to try and predict the Penguin body mass. The Penguin- bill length, bill depth and flipper length will be used as independent variables. Note, however, they might be somewhat correlated: see this pairplot on the Penguin data for details. This poses an interesting challenge for our regression. Let us combine this with varying dataset sample sizes and varying settings of $\\lambda$ to see the effects on our loss.\n\nRidge Regression using all quantitative variables in the Penguin dataset to predict body mass. Varying subset sizes of the dataset $n$ as well as different regularization strengths $\\lambda$ are shown.\n\nIt can be observed, that using including all quantitative variables did improve the loss on predicting the Penguin body mass using Ridge Regression. In fact, the penalty imposed probably pulled the hyperplane angle down such that the error in fact increased. Ridge Regression is a very powerful technique, nonetheless, and most importantly introduced us to the concept of regularization. In the next chapters on Logistic Regression in Neural Networks, we assume all our models to use $L^2$ regularization.\n\nNow, the data we fit up until now had only a small dimensionality - this is perhaps a drastic oversimplification in comparison to the real world. How does the analytic way of solving linear regression using the normal equation fare with higher-dimensional data?\n\n\nHigh-dimensional data\n\nIn the real world, datasets might be of very high dimensionality: think of images, speech, or a biomedical dataset storing DNA sequences. These datasets cause different computational strain on the equations to be solved to fit a linear regression model: so let us simulate such a high-dimensional situation.\n\nIn our simulation the amount of dimensions will configured to outmatch the amount of dataset samples ($p \\gg n$), which extra dimensions we will create by simply adding some noise columns to the design matrix $X$. The noise will be drawn from a Gaussian distribution $\\epsilon \\sim \\mathcal{N}(0, 1)$. We can now run an experiment by fitting our linear regression model to the higher-dimensional noised dataset, benchmarking the fitting times of the algorithm.\n\nWe can observe that the normal equation takes a lot longer to compute for higher-dimensional data. In fact, numerically computing the matrix inverse is very computationally expensive, i.e. computing $(X^TX)^{-1}$. Luckily, there are computationally cheaper techniques to do a regression in higher-dimensional spaces. One such technique is an iterative procedure, called Gradient Descent.\n\n\nGradient Descent\n\nInstead of trying to analytically solve the system of linear equations at once, we can choose an iterative procedure instead, such as Gradient Descent. It works by computing the gradient of the cost function with respect to the model weights - such that we can then move in the opposite direction of the gradient in parameter space. Given some loss function $R(\\beta)$ and $R_i(\\beta)$, which computes the empirical loss for entire dataset and for the $i$-th observation, respectively, we can define one gradient descent step as:\n\n$$\\begin{aligned} \\beta^{(r + 1)} &= \\beta^{(r)} - \\gamma \\nabla_{\\beta^{(r)}} R(\\beta^{(r)}) \\\\ &= \\beta^{(r)} - \\gamma \\sum_{i=1}^N \\frac{\\partial R_i(\\beta^{(r)})}{\\partial \\beta^{(r)}}\\\\ \\end{aligned}$$\n\nIn which $\\gamma$ is the learning rate and $r$ indicates some iteration - given some initial parameters $\\beta^0$ and $N$ training samples. Using this equation, we are able to reduce the loss in every iteration, until we converge. Convergence occurs when every element of the gradient is zero - or very close to it. Although gradient descent is used in this vanilla form, two modifications are common: (1) subsampling and ¬†using a (2) learning rate schedule.\n\n 1. Although in a scenario in which our loss function landscape is convex the vanilla variant does converge toward the global optimum relatively easily, this might not be the case for non-convex error landscapes. We are at risk of getting stuck in local extremes. In this case, it is desirable to introduce some randomness ‚Äî allowing us to jump out local extrema. We can introduce randomness by instead of computing the gradient over the entire sample set, we can do so for a random sample of the dataset called a minibatch (Goodfellow et al., 2014). A side effect is a lighter computational burden per iteration; sometimes causing faster convergence. Because the introduced randomness makes the procedure stochastic instead of deterministic, we call this algorithm Stochastic Gradient Descent, or simply SGD.\n 2. Accommodating SGD is often a learning rate schedule: making the learning rate parameter $\\gamma$ dependent on the iteration number $r$ such that $\\gamma = \\gamma^{(r)}$. In this way, we made the learning rate adaptive over time, allowing us to create a custom learning rate scheme. Many schemes (Dogo et al., 2018) exist - which can be used to avoid spending a long time on flat areas in the error landscape called plateaus, or to avoid 'overshooting' the optimal solution. Even, a technique analogous with momentum (Qian, 1999) in physics might be used: a particle traveling through space is 'accelerated' by the loss gradient, causing the gradient to change faster if it keeps going in the same direction.\n\nSo, let's now redefine our gradient descent formula to accommodate for these modifications:\n\n$$\\beta^{(r+1)}=\\beta^{(r)}-\\gamma^{(r)} \\frac{1}{m} \\sum_{i=1}^m \\frac{\\partial R_i(\\beta^{(r)})}{\\partial \\beta^{(r)}} $$\n\n... where we, before each iteration, randomly shuffle our training dataset such that we draw $m$ random samples each step. The variable $m$ denotes the batch size - which can be anywhere between 1 and the amount of dataset samples minus one $N - 1$. The smaller the batch size, the more stochastic the procedure will get.\n\nUsing gradient descent for our linear regression is straight-forward. We differentiate the cost function with respect to the weights; the least squares derivative is then as follows:\n\n$$\\begin{aligned} \\frac{\\partial R_i(\\beta^{(r)})}{\\partial \\beta^{(r)}} &= \\frac{\\partial}{\\partial \\beta^{(r)}} (y_i - x_i \\beta^{(r)})^2\\\\ &= 2 (y_i - x_i \\beta^{(r)})\\\\ \\end{aligned}$$\n\nWe then run the algorithm in a loop, to iteratively get closer to the optimum parameter values.\n\nNow, using this newly introduced iterative optimization procedure, let's see whether we can solve linear regression faster. First, we will compare SGD and the analytic method for our Penguin dataset with standard Gaussian noise dimensions added such that $p=2000$.\n\nIndeed - our iterative procedure is faster for such a high-dimensional dataset. Because the analytic method always finds the optimum value, it is most plausible that SGD does not achieve the same performance - as can be seen in the MSE loss in the figure. Only in a couple of runs does SGD achieve near-optimum performance - in the other cases the algorithm was either stopped by its maximum iterations limit or it got stuck in some local extrema and has not gotten out yet. If we wanted to get better results, we could have used a more lenient maximum amount of iterations or a stricter convergence condition. This is a clear trade-off between computational workload and the optimality of the solution. We can run some more experiments for various levels of augmented dimensions:\n\nIn which we can empirically show that for our experiment, the analytic computation time grows about exponentially whilst SGD causes only a mild increase in computational time. SGD does suffer a higher loss due to its approximative nature - but this might just be worth the trade-off.\n\nNow that we have gotten familiar with Gradient Descent, we can explore a realm of techniques that rely on being solved iteratively. Instead of doing regression, we will now try to classify penguins by their species type ‚Äî a method for doing so is Logistic Regression.\n\n\nLogistic Regression (Code)\n\nIn general, linear regression is no good for classification. There is no notion incorporated into the objective function to desire a hyperplane that best separates two classes. Even if we would encode qualitative target variables in a quantitative way, i.e. in zeros or ones, a normal equation fit would result in predicted values outside the target range.\n\nTherefore, we require a different scheme. In Logistic Regression, we first want to make sure all estimations remain in $[0,1]$. This can be done using the Sigmoid function:\n\n$$S(z)=\\frac{e^z}{e^z+1}=\\frac{1}{1+e^{-z}}$$\n\nAlso called the Logistic function. So, the goal is to predict some class $G \\in \\{1,\\dots,K\\}$ given inputs $X$. We assume an intercept constant of 1 to be embedded in $X$. Now let us take a closer look at the case where $K=2$, i.e. the binary or binomial case.\n\nIf we were to encode our class targets $Y$ as either ones or zeros, i.e. $Y \\in \\{0,1\\}$, we can predict values using $X \\beta$ and pull them through a sigmoid $S(X\\beta)$ to obtain the probabilities whether samples belongs to the class encoded as 1. This can be written as:\n\n$$\\begin{aligned} \\Pr(G=2|X;\\beta)&=S(X\\beta)\\\\ &=\\frac{1}{1+\\exp(-X\\beta)}\\\\ &=p(X;\\beta) \\end{aligned}$$\n\nBecause we consider only two classes, we can compute one probability and infer the other one, like so:\n\n$$\\begin{aligned} \\Pr(G=1|X;\\beta)&=1-p(X;\\beta) \\end{aligned}$$\n\nFor which it can be easily seen that both probabilities form a probability vector, i.e. their values sum to 1. Note we can consider the targets as a sequence of Bernoulli trials $y_i,\\dots,y_N$ - each outcome a binary - assuming all observations are independent of one another. This allows us to write:\n\n$$\\begin{aligned} \\Pr (y| X;\\beta)&=p(X;\\beta)^y(1-p(X;\\beta))^{(1-y)}\\\\ \\end{aligned}$$\n\nSo, how to approximate $\\beta$? Like in linear regression, we can optimize a loss function to obtain an estimator $\\hat{\\beta}$. We can express the loss function as a likelihood using Maximum Likelihood Estimation. First, we express our objective into a conditional likelihood function.\n\n$$\\begin{aligned} L(\\beta)&=\\Pr (Y| X;\\beta)\\\\ &=\\prod_{i=1}^N \\Pr (y_i|X=x_i;\\beta)\\\\ &=\\prod_{i=1}^N p(x_i;\\beta)^{y_i}(1-p(x_i;\\beta))^{(1-y_i)} \\end{aligned}$$\n\nThe likelihood becomes easier to maximize in practice if we rewrite the product to a sum using a logarithm; such scaling does not change the resulting parameters. We obtain the log-likelihood (Bischop, 2006):\n\n$$\\begin{aligned} \\ell(\\beta)&=\\log L(\\beta)\\\\ &=\\sum_{i=1}^{N}\\left\\{y_{i} \\log p\\left(x_{i} ; \\beta\\right)+\\left(1-y_{i}\\right) \\log \\left(1-p\\left(x_{i} ; \\beta\\right)\\right)\\right\\}\\\\ &=\\sum_{i=1}^{N}\\left\\{y_{i} \\beta^{T} x_{i}-\\log \\left(1+e^{\\beta^{T} x_{i}}\\right)\\right\\} \\end{aligned}$$\n\nAlso called the logistic loss; which multi-dimensional counterpart is the cross-entropy loss. We can maximize this likelihood function by computing its gradient:\n\n$$\\frac{\\partial \\ell(\\beta)}{\\partial \\beta}=\\sum_{i=1}^{N} x_{i}\\left(y_{i}-p\\left(x_{i} ; \\beta\\right)\\right)$$\n\n...resulting in $p+1$ equations nonlinear in $\\beta$. The equation is transcendental: meaning no closed-form solution exists and hence we cannot simply solve for zero. It is possible, however, to use numerical approximations: Newton-Raphson method based strategies can be used, such as Newton Conjugate-Gradient, or quasi-Newton procedures might be used such as L-BFGS (Zhu et al., 1997). Different strategies have varying benefits based on the problem type, e.g. the amount of samples $n$ or dimensions $p$. Since the gradient can be approximated just fine, we can also simply use Gradient Descent, i.e. SGD.\n\nIn the case where more response variables are to be predicted, i.e. $K>2$, a multinomial variant of Logistic Regression can be used. For easier implementation, some software implementations just perform multiple binomial logistic regressions in order to conduct a multinomial one; which is called a One-versus-All strategy. The resulting probabilities are then normalized to still output a probability vector (Pedregosa et al., 2001).\n\nThat theory out of the way, let's fit a Logistic Regression model to our penguin data! We will try to classify whether a penguin is a Chinstrap yes or no, in other words: we will perform a binomial logistic regression. We will perform 30K iterations, each iteration an epoch over the training data:\n\nWe can observe that the model converged to a stable state already after about 10K epochs - we could have implemented an early stopping rule; for example by checking whether validation scores stop improving or when our loss is no longer changing much. We can also visualize our model fit over time: by predicting over a grid of values at every time step during training. This yields the following animation:\n\nClearly, our decision boundary is not optimal yet - whilst the data is somewhat Gaussian distributed our model linearly separates the data. We can do better ‚Äî we need some way to introduce more non-linearity into our model. A model that does just so is a Neural Network.\n\n\nNeural Network (Code)\n\nAt last, we arrive at the Neural Network. Using the previously learned concepts, we are really not that far off from assembling a Neural Network. Really, a single-layer Neural Network essentially just a linear model, like before. The difference is, that we conduct some extra projections in order to make the data better linearly separable. In a Neural Network, we aim to find the parameters facilitating such projections automatically. We call each such projection a Hidden Layer. After having conducted a suitable projection, ¬†we can pull the projected data through a logistic function to estimate a probability - similarly to logistic regression. One such architecture is like so:\n\nSo, given one input vector $x_i$, we can compute its estimated value by feeding its values through the network from left to right, in each layer multiplying with its parameter vector. We call this type of network feed-forward. Networks that do not feed forward include recurrent or recursive networks, though we will only concern ourselves with feed-forward networks for now.\n\nAn essential component of any such network is an activation function; a non-linear differentiable function mapping $\\mathbb{R} \\rightarrow \\mathbb{R}$, aimed to overcome model linearity constraints. We apply the activation function to every hidden node; we compute the total input, add a bias, and then activate. This process is somewhat analogous to what happens in neurons in the brain - hence the name Neural Network. Among many possible activation functions (Nwankpa et al., 2018), a popular choice is the Rectified Linear Unit, or ReLU: $\\sigma(z)=\\max\\{0, z\\}$. It looks as follows:\n\nAlso because ReLU is just a max operation, it is fast to compute (e.g. compared to a sigmoid). Using our activation function, we can define a forward-pass through our network, as follows:\n\n$$\\begin{aligned} h^{(1)}&=\\sigma(X W^{(1)} + b^{(1)})\\\\ h^{(2)}&=\\sigma(h^{(1)} W^{(2)} + b^{(2)})\\\\ h^{(3)}&=\\sigma(h^{(2)} W^{(3)} + b^{(3)})\\\\ \\hat{Y}&=S(h^{(3)}W^{(4)}+b^{(4)}) \\end{aligned}$$\n\nIn which $h$ resembles the intermediate projections indexed by its hidden layer; and the parameters $\\beta$ mapping every two layers together are accessible through $W$. A bias vector is accessible through $b$, such to add a bias term to every node in the layer. Finally, we apply a Sigmoid to the results of the last layer to receive probability estimates; in the case of multi-class outputs its multi-dimensional counterpart is used, the Softmax, which normalizes the logistic function such to produce a probability vector. Do note that the activation function could differ per layer; and in practice, this might happen. In our case, we will just use one activation function for all hidden layers in our network.\n\nWe are also going to have to define a cost function, such to be able to optimize the parameters based on its gradient. We can do so using the minimizing the negative log-likelihood using Maximum Likelihood, given some loss function such as:\n\n$$ R(\\theta)=-\\mathbb{E}_{\\mathbf{x}, \\mathbf{y}\\sim\\hat{p}_{\\text{data }}}\\log p_{\\operatorname{model}}(\\boldsymbol{y}\\mid\\boldsymbol{x}) $$\n\nIn which we combined weights $W$ and biases $b$ into a single parameter term $\\theta$. Our cost function says to quantify the chance of encountering a target $y$ given an input vector $x$. Suitable loss functions to be used are log-loss/cross-entropy, or simply squared error:\n\n$$ R(\\theta)=\\frac{1}{2}\\mathbb{E}_{\\mathbf{x}, \\mathbf{y}\\sim\\hat{p}_{\\text{data }}}\\|\\boldsymbol{y}-f(\\boldsymbol{x} ; \\boldsymbol{\\theta})\\|^{2}+ \\text{const} $$\n\nAssuming $p_{\\text{model}}(y|x)$ to be Gaussian distributed. Of course, in any implementation we can only approach the expected value by averaging over a discrete set of observations; thus allowing us to compute the loss of our network.\n\nNow that we are able to do a forward pass by (1) making predictions given a set of parameters $\\theta$ and (2) computing its loss using a cost function $R(\\theta)$, we will have to figure out how to actually train our network. Because our computation involves quite some operations by now, computing the gradient of the cost function is not trivial - to approximate the full gradient one would have to compute partial derivatives with respect to every weight separately. Luckily, we can exploit the calculus chain rule to break up the problem into smaller pieces: allowing us to much more efficiently re-use previously computed answers. The algorithm using this trick is called back-propagation.\n\nIn back-propagation, we re-visit the network in reverse order; i.e. starting at the output layer and working our way back to the input layer. We then use the calculus derivative chain rule (Goodfellow et al., 2014):\n\n$$\\begin{aligned} \\frac{\\partial z}{\\partial x_{i}}&=\\sum_{j} \\frac{\\partial z}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial x_{i}}\\\\ &\\text{in vector notation:}\\\\ \\nabla_{\\boldsymbol{x}} z&=\\left(\\frac{\\partial \\boldsymbol{y}}{\\partial \\boldsymbol{x}}\\right)^{\\top} \\nabla_{\\boldsymbol{y}} z \\end{aligned}$$\n\n...to compute the gradient in modular fashion. Note we need to consider the network in its entirety when computing the partial derivatives; the output activation, the loss function, node activations and the biases. To systematically apply back-prop to a network often these functions are abstracted as being an operation - which can then be assembled in a computational graph. Given a suitable such graph, many generic back-prop implementations can be used.\n\nOnce we have now computed the derivative of the cost function $R(\\theta)$, our situation became similar to when we iteratively solved linear- or logistic regression: we can now use just Gradient Descent to move in the error landscape.\n\nNow that we know how to train a Neural Network, let's apply it! We aim to get better accuracy for our Penguin classification problem than using our Logistic Regression model.\n\nIndeed, our more flexible Neural Network model better fits the data. The NN achieves 94.9% testing accuracy, in comparison to 89.7% testing accuracy for the Logistic Regression model. Let's see how our model is fitted over time:\n\nIn which it can be observed that the model converged after some 750 iterations. Intuitively, the decision region looks to have been approximated fairly well - it might just have been slightly 'stretched' out.\n\n\nEnding note\n\nNow that we have been able to fit a more 'complicated' data distribution, we conclude our journey from simple statistical models such a linear regression up to Neural Networks. Having a diverse set of statistical and iterative techniques in your tool belt is essential for any Machine Learning practitioner: even though immensely powerful models are available and widespread today, sometimes a simpler model will do just fine.\n\nIn tandem with how the bias/variance dilemma is fundamental to understanding how to construct good distribution learning models, one should always take into account not to overreach on model complexity given a learning task (Occam's Razor; Rasmussen et al., 2001): use an as simple as possible model, wherever possible.\n\n\nCitations\n\n * Gorman KB, Williams TD, Fraser WR (2014). Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis). PLoS ONE 9(3):e90081.\n * Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Springer Science & Business Media.\n * Dogo, E. M., Afolabi, O. J., Nwulu, N. I., Twala, B., & Aigbavboa, C. O. (2018, December). A comparative analysis of gradient descent-based optimization algorithms on convolutional neural networks. In 2018 International Conference on Computational Techniques, Electronics and Mechanical Systems (CTEMS) (pp. 92-99). IEEE.\n * Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n * Goodfellow, I., Bengio, Y., Courville, A., & Bengio, Y. (2016). Deep learning (Vol. 1, No. 2). Cambridge: MIT press.\n * Qian, N. (1999). On the momentum term in gradient descent learning algorithms. Neural networks, 12(1), 145-151.\n * Zhu, C., Byrd, R. H., Lu, P., & Nocedal, J. (1997). Algorithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained optimization. ACM Transactions on Mathematical Software (TOMS), 23(4), 550-560.\n * Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. the Journal of machine Learning research, 12, 2825-2830.\n * Nwankpa, C., Ijomah, W., Gachagan, A., & Marshall, S. (2018). Activation functions: Comparison of trends in practice and research for deep learning. arXiv preprint arXiv:1811.03378.\n * Rasmussen, C. E., & Ghahramani, Z. (2001). Occam's razor. Advances in neural information processing systems, 294-300.\n\n\n\n\nCode\n\nThe code is freely available on Github, see:\n\n\n\n","feature_image":"__GHOST_URL__/content/images/2021/11/linear-regression-to-neural-networks.png","featured":1,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","created_at":"2021-11-28 21:29:51","created_by":"1","updated_at":"2021-12-23 10:57:41","updated_by":null,"published_at":"2021-04-17 22:00:00","published_by":"1","custom_excerpt":"How are linear regression, logistic regression and neural networks related? What is overfitting and how do we fight it? In this post, we find answers to these questions in an interactive way by working with a real-world dataset on penguins.","codeinjection_head":"<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css\" integrity=\"sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs\" crossorigin=\"anonymous\">\n<script defer src=\"https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js\" integrity=\"sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx\" crossorigin=\"anonymous\"></script>\n<script defer src=\"https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js\" integrity=\"sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR\" crossorigin=\"anonymous\"\n    onload=\"renderMathInElement(document.body, {delimiters: [ {left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}, {left: '\\\\(', right: '\\\\)', display: false}, {left: '\\\\begin{equation}', right: '\\\\end{equation}', display: true}, {left: '\\\\begin{align}', right: '\\\\end{align}', display: true}, {left: '\\\\begin{alignat}', right: '\\\\end{alignat}', display: true}, {left: '\\\\begin{gather}', right: '\\\\end{gather}', display: true}, {left: '\\\\begin{CD}', right: '\\\\end{CD}', display: true}, {left: '\\\\[', right: '\\\\]', display: true}]});\"></script>","codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c27e","uuid":"68e4021a-bfbc-4bbc-9915-650570fdccea","title":"ember-polymer & ember-polymer-paper","slug":"ember-polymer","mobiledoc":"{\"version\":\"0.3.1\",\"ghostVersion\":\"4.0\",\"markups\":[],\"atoms\":[],\"cards\":[],\"sections\":[[1,\"p\",[[0,[],0,\"\"]]]]}","html":null,"comment_id":"61a3f9b972c7ac1e204625cd","plaintext":null,"feature_image":null,"featured":0,"type":"post","status":"draft","locale":null,"visibility":"public","email_recipient_filter":"all","created_at":"2021-11-28 21:50:49","created_by":"1","updated_at":"2021-12-07 21:25:52","updated_by":null,"published_at":null,"published_by":null,"custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c27f","uuid":"329c65a7-83dd-4ea4-a363-00bfaa675eea","title":"My programming life when I was young","slug":"dunklunar","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"bookmark\",{\"version\":\"1.0\",\"type\":\"bookmark\",\"url\":\"https://code.google.com/archive/p/dunkscripts/downloads\",\"metadata\":{\"url\":\"https://code.google.com/archive/p/dunkscripts/downloads\",\"title\":\"Google Code Archive - Long-term storage for Google Code Project Hosting.\",\"description\":null,\"author\":null,\"publisher\":\"Long-term storage for Google Code Project Hosting.\",\"thumbnail\":\"https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_116x41dp.png\",\"icon\":\"https://code.google.com/archive/img/project-hosting.ico\"}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/12/2014-04-03-Eight-Media-projecten-overzicht.png\",\"width\":754,\"height\":1403}],[\"bookmark\",{\"version\":\"1.0\",\"type\":\"bookmark\",\"url\":\"https://dunnkers.com/DunkPathMaker/\",\"metadata\":{\"url\":\"https://dunnkers.com/DunkPathMaker/\",\"title\":\"DunkPathMaker\",\"description\":\"DunkPathMaker : A useful tool for RuneScape bot scripters\",\"author\":null,\"publisher\":null,\"thumbnail\":\"https://dunnkers.com/DunkPathMaker/images/osbot-logo.png\",\"icon\":\"https://dunnkers.com/DunkPathMaker/favicon.ico\"}}]],\"markups\":[[\"a\",[\"href\",\"https://www.youtube.com/watch?v=khaP5cAkvcs\"]]],\"sections\":[[10,0],[1,\"p\",[[0,[0],1,\"https://www.youtube.com/watch?v=khaP5cAkvcs\"]]],[1,\"p\",[]],[10,1],[1,\"p\",[]],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://code.google.com/archive/p/dunkscripts/downloads\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Google Code Archive - Long-term storage for Google Code Project Hosting.</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://code.google.com/archive/img/project-hosting.ico\" alt=\"\"><span class=\"kg-bookmark-author\">Long-term storage for Google Code Project Hosting.</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_116x41dp.png\" alt=\"\"></div></a></figure><p><a href=\"https://www.youtube.com/watch?v=khaP5cAkvcs\">https://www.youtube.com/watch?v=khaP5cAkvcs</a></p><p></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/12/2014-04-03-Eight-Media-projecten-overzicht.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"754\" height=\"1403\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/12/2014-04-03-Eight-Media-projecten-overzicht.png 600w, __GHOST_URL__/content/images/2021/12/2014-04-03-Eight-Media-projecten-overzicht.png 754w\" sizes=\"(min-width: 720px) 720px\"></figure><p></p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://dunnkers.com/DunkPathMaker/\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">DunkPathMaker</div><div class=\"kg-bookmark-description\">DunkPathMaker : A useful tool for RuneScape bot scripters</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://dunnkers.com/DunkPathMaker/favicon.ico\" alt=\"\"></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://dunnkers.com/DunkPathMaker/images/osbot-logo.png\" alt=\"\"></div></a></figure>","comment_id":"61ab38cc06ec530609ffafe8","plaintext":"Google Code Archive - Long-term storage for Google Code Project Hosting.Long-term storage for Google Code Project Hosting.\n\nhttps://www.youtube.com/watch?v=khaP5cAkvcs\n\n\n\n\n\nDunkPathMakerDunkPathMaker : A useful tool for RuneScape bot scripters","feature_image":null,"featured":0,"type":"post","status":"draft","locale":null,"visibility":"public","email_recipient_filter":"all","created_at":"2021-12-04 09:45:48","created_by":"1","updated_at":"2021-12-20 16:02:42","updated_by":null,"published_at":null,"published_by":null,"custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c280","uuid":"8c89d940-9dd5-4532-bde9-8f763b52615f","title":"Evaluating Feature selectors (msc thesis)","slug":"evaluating-feature-selectors-msc-thesis","mobiledoc":"{\"version\":\"0.3.1\",\"ghostVersion\":\"4.0\",\"markups\":[],\"atoms\":[],\"cards\":[],\"sections\":[[1,\"p\",[[0,[],0,\"\"]]]]}","html":null,"comment_id":"61be56c453632316a2934a2e","plaintext":null,"feature_image":null,"featured":0,"type":"post","status":"draft","locale":null,"visibility":"public","email_recipient_filter":"all","created_at":"2021-12-18 21:46:44","created_by":"1","updated_at":"2021-12-18 21:46:44","updated_by":null,"published_at":null,"published_by":null,"custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c281","uuid":"023dbdbb-f422-4632-8ad8-f0b64dc5cfa8","title":"Best books of 2021","slug":"best-books-of-2021","mobiledoc":"{\"version\":\"0.3.1\",\"ghostVersion\":\"4.0\",\"markups\":[],\"atoms\":[],\"cards\":[],\"sections\":[[1,\"p\",[[0,[],0,\"\"]]]]}","html":null,"comment_id":"61ebfde753632316a2934a6e","plaintext":null,"feature_image":null,"featured":0,"type":"post","status":"draft","locale":null,"visibility":"public","email_recipient_filter":"all","created_at":"2022-01-22 12:51:51","created_by":"1","updated_at":"2022-01-22 12:51:51","updated_by":null,"published_at":null,"published_by":null,"custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null},{"id":"62a48f659cd77522dc21c282","uuid":"6b3d651d-0781-4847-b60e-b68380d6600f","title":"Backpacking during the Corona pandemic","slug":"backpacking-during-the-corona-pandemic","mobiledoc":"{\"version\":\"0.3.1\",\"ghostVersion\":\"4.0\",\"markups\":[],\"atoms\":[],\"cards\":[],\"sections\":[[1,\"p\",[[0,[],0,\"\"]]]]}","html":null,"comment_id":"61ebfe0553632316a2934a72","plaintext":null,"feature_image":null,"featured":0,"type":"post","status":"draft","locale":null,"visibility":"public","email_recipient_filter":"all","created_at":"2022-01-22 12:52:21","created_by":"1","updated_at":"2022-01-22 12:52:21","updated_by":null,"published_at":null,"published_by":null,"custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"newsletter_id":null}],"posts_meta":[{"id":"62a48f659cd77522dc21c284","post_id":"62a48f659cd77522dc21c274","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null,"email_only":0},{"id":"62a48f659cd77522dc21c287","post_id":"62a48f659cd77522dc21c275","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":"This is how I can currently control my curtains: using a little remote.","email_only":0},{"id":"62a48f659cd77522dc21c28a","post_id":"62a48f659cd77522dc21c276","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":"The break time friend finder app. By clicking a break-hour, like 'tussen', students could see with whom they could spend their break time :).","email_only":0},{"id":"62a48f659cd77522dc21c28f","post_id":"62a48f659cd77522dc21c278","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":"A <a href=\"https://dunnkers.com/disease-spread\">dashboard</a> showing potential Corona hotspots based on population data.","email_only":0},{"id":"62a48f669cd77522dc21c292","post_id":"62a48f659cd77522dc21c279","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":"The idea of re-training a Neural Network to insert a backdoor, causing certain predictions to be wrong.","email_only":0},{"id":"62a48f669cd77522dc21c297","post_id":"62a48f659cd77522dc21c27b","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":"Photo by <a href=\"https://unsplash.com/@possessedphotography?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\">Possessed Photography</a> / <a href=\"https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit\">Unsplash</a>","email_only":0},{"id":"62a48f669cd77522dc21c29a","post_id":"62a48f659cd77522dc21c27c","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":"Note: the people on the left are <strong>not</strong> real people. Nor is the art next to it. They were created by an AI ‚Äì to be specific, by a Generative Adversarial Network.","email_only":0}],"users":[{"id":"1","name":"Jeroen Overschie","slug":"jeroen","password":"$2a$10$1Me.YVV/yWm/bSp.MYctbOvMiyNaj64luh8sFp7qEC0RFfuvIXYfq","email":"jeroenoverschie@gmail.com","profile_image":"https://www.gravatar.com/avatar/b37b136916ade32aada1f345482aafa4?s=250&r=x&d=mp","cover_image":null,"bio":null,"website":null,"location":null,"facebook":null,"twitter":null,"accessibility":null,"status":"active","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"tour":null,"last_seen":"2022-06-11 12:47:41","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:47:41","updated_by":"1"}],"posts_authors":[{"id":"62a48eba9cd77522dc21c0f9","post_id":"62a48eba9cd77522dc21c0f8","author_id":"1","sort_order":0},{"id":"62a48f659cd77522dc21c283","post_id":"62a48f659cd77522dc21c274","author_id":"1","sort_order":0},{"id":"62a48f659cd77522dc21c286","post_id":"62a48f659cd77522dc21c275","author_id":"1","sort_order":0},{"id":"62a48f659cd77522dc21c289","post_id":"62a48f659cd77522dc21c276","author_id":"1","sort_order":0},{"id":"62a48f659cd77522dc21c28b","post_id":"62a48f659cd77522dc21c277","author_id":"1","sort_order":0},{"id":"62a48f659cd77522dc21c28e","post_id":"62a48f659cd77522dc21c278","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c291","post_id":"62a48f659cd77522dc21c279","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c294","post_id":"62a48f659cd77522dc21c27a","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c296","post_id":"62a48f659cd77522dc21c27b","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c299","post_id":"62a48f659cd77522dc21c27c","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c29c","post_id":"62a48f659cd77522dc21c27d","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c29d","post_id":"62a48f659cd77522dc21c27e","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c29e","post_id":"62a48f659cd77522dc21c27f","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c29f","post_id":"62a48f659cd77522dc21c280","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c2a0","post_id":"62a48f659cd77522dc21c281","author_id":"1","sort_order":0},{"id":"62a48f669cd77522dc21c2a1","post_id":"62a48f659cd77522dc21c282","author_id":"1","sort_order":0}],"roles":[{"id":"62a48eba9cd77522dc21c089","name":"Administrator","description":"Administrators","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:46:50","updated_by":"1"},{"id":"62a48eba9cd77522dc21c08a","name":"Editor","description":"Editors","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:46:50","updated_by":"1"},{"id":"62a48eba9cd77522dc21c08b","name":"Author","description":"Authors","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:46:50","updated_by":"1"},{"id":"62a48eba9cd77522dc21c08c","name":"Contributor","description":"Contributors","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:46:50","updated_by":"1"},{"id":"62a48eba9cd77522dc21c08d","name":"Owner","description":"Blog Owner","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:46:50","updated_by":"1"},{"id":"62a48eba9cd77522dc21c08e","name":"Admin Integration","description":"External Apps","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:46:50","updated_by":"1"},{"id":"62a48eba9cd77522dc21c08f","name":"DB Backup Integration","description":"Internal DB Backup Client","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:46:50","updated_by":"1"},{"id":"62a48eba9cd77522dc21c090","name":"Scheduler Integration","description":"Internal Scheduler Client","created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:46:50","updated_by":"1"}],"roles_users":[{"id":"62a48eba9cd77522dc21c091","role_id":"62a48eba9cd77522dc21c08d","user_id":"1"}],"settings":[{"id":"62a48ebb9cd77522dc21c207","group":"core","key":"db_hash","value":"90691f48-39c3-4adb-a3af-c542473f4a08","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c208","group":"core","key":"routes_hash","value":"3d180d52c663d173a6be791ef411ed01","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c209","group":"core","key":"next_update_check","value":"1655038040","type":"number","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:47:15","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c20a","group":"core","key":"notifications","value":"[]","type":"array","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c20b","group":"core","key":"version_notifications","value":"[]","type":"array","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c20c","group":"core","key":"admin_session_secret","value":"d18f1ca0021f20696eab6c5cd4f172c548d233cf8196d31ebdc6a3924abe6da4","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c20d","group":"core","key":"theme_session_secret","value":"913f28f4911a4b8409b7c5dbf2fc6739c5238e9e64ef3dd42fa044b24a01cb1c","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c20e","group":"core","key":"ghost_public_key","value":"-----BEGIN RSA PUBLIC KEY-----\nMIGJAoGBAKO48nyBnRvj+NtWe12UXeNBvSNY+vbky2Z5Aefu8uriQC9XBzYdGfhgW/V+re+B\nd02tvs0fxpxR6o/JQJ577JI7YZNtwZJWjZ1RsAMzNohyEg3+vQE2VrBGTEoleziy+wsZd+lO\nttuDy3fQkEiz0KOQkRO5JLcSqdiZUFjuMoNDAgMBAAE=\n-----END RSA PUBLIC KEY-----\n","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c20f","group":"core","key":"ghost_private_key","value":"-----BEGIN RSA PRIVATE KEY-----\nMIICXgIBAAKBgQCjuPJ8gZ0b4/jbVntdlF3jQb0jWPr25MtmeQHn7vLq4kAvVwc2HRn4YFv1\nfq3vgXdNrb7NH8acUeqPyUCee+ySO2GTbcGSVo2dUbADMzaIchIN/r0BNlawRkxKJXs4svsL\nGXfpTrbbg8t30JBIs9CjkJETuSS3EqnYmVBY7jKDQwIDAQABAoGAa3qLfV7dU6TqBpuUaw9u\nPzU1xBGy1wfF22SO8sJzp+yVdD5uloCuPtaLJ/NcngFg35ayzhgRGyfPk0rr5960oxBt1d6x\npj7hwir04wg1awLkx1rREyUorA0cVfSZazrjah5M1ASqJqmFghAqkfEpJBLT2y2GcbQwH1GG\nC317BjkCQQDk4mplamMBsWq6CWbue41Ubdjbfvoy7njVUZq7mIqcldYjSTFgk6ev60R4wmTX\ncMUvcVfT6en7KbcVGgeqs/nfAkEAtx5OLVw7Kdnvq8ZBFFiFGHdGfDbz5MIWt0eg0uf4irVE\nqQZza+JiQoPG5QfvRm6nXnbvh6hNoerk7TWIK4FrHQJBAAvv6xCi/crmz+Qn/WBOvU479GVu\nN+pUGaU2flVuXTxRbDum45Zf3Q0Fvip2KQA7d21EAgqhVnys7kmBdAjpHg0CQQCiB0G7Z0G+\nbWVhw+Gv5AeYt2l53ZH/FzHMaKfIFpPYAD7JpLiafEzfeASUgWnaE20q6+hUS7qti8+WiOh9\nPl2NAkEAk/lGxlpXADs0jVKJvDB9Gj+0V1GN2RznNtQsUHF8M3sHPDR8wapP1aeGpq0Jme2B\nlGSUkHTYBVSqO6Spjsa/QQ==\n-----END RSA PRIVATE KEY-----\n","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c210","group":"core","key":"members_public_key","value":"-----BEGIN RSA PUBLIC KEY-----\nMIGJAoGBANXwRLRMprn6r1TZqvr4A+h7aun9tNzVNN/0NM0eM8AdVpfiJD60NQKtTF8mD1/N\ngV71aEZw0MqUWXugN/sCyDOQboy655lfu0z48oV910Hwtc2XzUfrKPTxqyjWNNpS+282qQii\nV09gZgcWzHNNUXh50/YzJvk8sam1/Qcl125VAgMBAAE=\n-----END RSA PUBLIC KEY-----\n","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c211","group":"core","key":"members_private_key","value":"-----BEGIN RSA PRIVATE KEY-----\nMIICXQIBAAKBgQDV8ES0TKa5+q9U2ar6+APoe2rp/bTc1TTf9DTNHjPAHVaX4iQ+tDUCrUxf\nJg9fzYFe9WhGcNDKlFl7oDf7AsgzkG6MuueZX7tM+PKFfddB8LXNl81H6yj08aso1jTaUvtv\nNqkIoldPYGYHFsxzTVF4edP2Myb5PLGptf0HJdduVQIDAQABAoGBAJucQQz3+Amsmp1YGfKk\nNYuDQbfjDwvVlLkVEtbjkfa6IEMnfP+S6kABN1y5/VLM0r30OJ2L74J6N0AhwLY2RtFNJCoM\nwmEwNC9iy17NeyqC13kONeLkka23YHnQhALpdjmUizhVvwwScQiUkR2OBTBtuJB1pQZb9Mn8\nvl4NT0NdAkEA/pVt5jXUdSa6mVahQK0MC/VV3MKp0qL5iNPNCvpYZiwU50aOdkFuGl/n6HgN\nXPgOlD3FJb35W4/4i4gZLy2qLwJBANcg9BPoHLq715N87Z3LR1IDE7AR8/MLvuE9C6Fk8n2h\nxNUifW6kzBGWS2cYmThChdK9+szA8zM45HByY/UkQrsCQQAJQce4Ojbad6kLUFIWtvQcLzSL\nDWz9Yr2uEv1+q7GxLWMpMbCWbjShsuEM2+ioe8CT9VcI00qQ4MBJ2o4H4CIzAj8daWP1VMaY\nwRW4FFxoNmKJ0+HdMJcpo3F1WeM9LY/5nSRL/2smtWExBltIvRQ1nOKu7UpctASL/Ds/JGSG\nH28CQQCeI0/hBiG3CuvkScRMperFy9HlpGoDZ14B9ejaYSdES3CCS3meOmpnaBzzbtFmNFjs\nLwrrx4qJY6bSrf5LWnun\n-----END RSA PRIVATE KEY-----\n","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c212","group":"core","key":"members_email_auth_secret","value":"b38e4c2c7c32769ff1cc9690f502bd09c297bb9e50df985420ce63ea6eb4ed832f644d25c23e3698a40d04ddfb413e335d949eccc5bb7174c19acf2f7d998619","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c215","group":"site","key":"title","value":"Jeroen Overschie","type":"string","flags":"PUBLIC","created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:37:26","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c216","group":"site","key":"description","value":"I write about Data Science, Software Engineering & Life ‚ú®","type":"string","flags":"PUBLIC","created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-12-22 11:50:15","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c217","group":"site","key":"logo","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c218","group":"site","key":"cover_image","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-28 13:46:24","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c219","group":"site","key":"icon","value":"__GHOST_URL__/content/images/2021/11/cartoon-head-jeroen-1.png","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-28 15:35:34","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c21a","group":"site","key":"accent_color","value":"#FF1A75","type":"string","flags":"PUBLIC","created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c21b","group":"site","key":"locale","value":"en","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c21c","group":"site","key":"timezone","value":"Europe/Amsterdam","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 13:38:15","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c21d","group":"site","key":"codeinjection_head","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c21e","group":"site","key":"codeinjection_foot","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c21f","group":"site","key":"facebook","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 13:38:15","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c220","group":"site","key":"twitter","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 13:38:15","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c221","group":"site","key":"navigation","value":"[{\"label\":\"Data Science\",\"url\":\"/tag/data-science/\"},{\"label\":\"Software Engineering\",\"url\":\"/tag/software-engineering/\"}]","type":"array","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-12-01 14:59:21","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c222","group":"site","key":"secondary_navigation","value":"[{\"label\":\"Data & privacy\",\"url\":\"/privacy/\"},{\"label\":\"Contact\",\"url\":\"/contact/\"}]","type":"array","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 12:04:27","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c223","group":"site","key":"meta_title","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c224","group":"site","key":"meta_description","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c225","group":"site","key":"og_image","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c226","group":"site","key":"og_title","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c227","group":"site","key":"og_description","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c228","group":"site","key":"twitter_image","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c229","group":"site","key":"twitter_title","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c22a","group":"site","key":"twitter_description","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c22b","group":"theme","key":"active_theme","value":"dunnkers-theme-edition","type":"string","flags":"RO","created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:50:14","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c22c","group":"private","key":"is_private","value":"false","type":"boolean","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c22d","group":"private","key":"password","value":"","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c22e","group":"private","key":"public_hash","value":"30a95d83845c7d4b9115d829afb88a","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c22f","group":"members","key":"default_content_visibility","value":"public","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c230","group":"members","key":"default_content_visibility_tiers","value":"[]","type":"array","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c231","group":"members","key":"members_signup_access","value":"none","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-28 13:47:24","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c232","group":"members","key":"members_support_address","value":"noreply","type":"string","flags":"PUBLIC,RO","created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c235","group":"members","key":"stripe_plans","value":"[]","type":"array","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c238","group":"members","key":"stripe_connect_livemode","value":null,"type":"boolean","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c239","group":"members","key":"stripe_connect_display_name","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c23b","group":"members","key":"members_monthly_price_id","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c23c","group":"members","key":"members_yearly_price_id","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c23d","group":"portal","key":"portal_name","value":"true","type":"boolean","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c23e","group":"portal","key":"portal_button","value":"false","type":"boolean","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 12:03:54","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c23f","group":"portal","key":"portal_plans","value":"[\"free\"]","type":"array","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c240","group":"portal","key":"portal_products","value":"[]","type":"array","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c241","group":"portal","key":"portal_button_style","value":"icon-and-text","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c242","group":"portal","key":"portal_button_icon","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c243","group":"portal","key":"portal_button_signup_text","value":"Subscribe","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c244","group":"email","key":"mailgun_domain","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c245","group":"email","key":"mailgun_api_key","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c246","group":"email","key":"mailgun_base_url","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c247","group":"email","key":"email_track_opens","value":"true","type":"boolean","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c249","group":"amp","key":"amp","value":"true","type":"boolean","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c24a","group":"amp","key":"amp_gtag_id","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c24b","group":"firstpromoter","key":"firstpromoter","value":"false","type":"boolean","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c24c","group":"firstpromoter","key":"firstpromoter_id","value":null,"type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c24d","group":"labs","key":"labs","value":"{}","type":"object","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c24e","group":"slack","key":"slack_url","value":"","type":"string","flags":null,"created_at":"2022-06-11 12:46:51","created_by":"1","updated_at":"2022-06-11 12:46:51","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c24f","group":"slack","key":"slack_username","value":"Ghost","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2022-01-06 13:37:30","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c250","group":"unsplash","key":"unsplash","value":"true","type":"boolean","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c251","group":"views","key":"shared_views","value":"[]","type":"array","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c252","group":"editor","key":"editor_default_email_recipients","value":"visibility","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"},{"id":"62a48ebb9cd77522dc21c253","group":"editor","key":"editor_default_email_recipients_filter","value":"all","type":"string","flags":null,"created_at":"2021-11-26 11:15:42","created_by":"1","updated_at":"2021-11-26 11:15:42","updated_by":"1"}],"tags":[{"id":"62a48eba9cd77522dc21c095","name":"News","slug":"news","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2022-06-11 12:46:50","created_by":"1","updated_at":"2022-06-11 12:46:50","updated_by":"1"},{"id":"62a48f659cd77522dc21c270","name":"Data Science","slug":"data-science","description":"All things Data Science. Machine Learning, Deep Learning and other cool stuff üôèüèª.","feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2021-11-29 19:30:44","created_by":"1","updated_at":"2021-12-01 14:55:16","updated_by":null},{"id":"62a48f659cd77522dc21c271","name":"Software Engineering","slug":"software-engineering","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2021-12-01 14:55:40","created_by":"1","updated_at":"2021-12-01 14:55:40","updated_by":null},{"id":"62a48f659cd77522dc21c272","name":"Internet of Things","slug":"internet-of-things","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2021-12-01 14:57:07","created_by":"1","updated_at":"2021-12-01 14:57:07","updated_by":null}],"posts_tags":[{"id":"62a48f659cd77522dc21c285","post_id":"62a48f659cd77522dc21c275","tag_id":"62a48f659cd77522dc21c272","sort_order":0},{"id":"62a48f659cd77522dc21c288","post_id":"62a48f659cd77522dc21c276","tag_id":"62a48f659cd77522dc21c271","sort_order":0},{"id":"62a48f659cd77522dc21c28c","post_id":"62a48f659cd77522dc21c278","tag_id":"62a48f659cd77522dc21c270","sort_order":0},{"id":"62a48f659cd77522dc21c28d","post_id":"62a48f659cd77522dc21c278","tag_id":"62a48f659cd77522dc21c271","sort_order":1},{"id":"62a48f669cd77522dc21c290","post_id":"62a48f659cd77522dc21c279","tag_id":"62a48f659cd77522dc21c270","sort_order":0},{"id":"62a48f669cd77522dc21c293","post_id":"62a48f659cd77522dc21c27a","tag_id":"62a48f659cd77522dc21c271","sort_order":0},{"id":"62a48f669cd77522dc21c295","post_id":"62a48f659cd77522dc21c27b","tag_id":"62a48f659cd77522dc21c270","sort_order":0},{"id":"62a48f669cd77522dc21c298","post_id":"62a48f659cd77522dc21c27c","tag_id":"62a48f659cd77522dc21c270","sort_order":0},{"id":"62a48f669cd77522dc21c29b","post_id":"62a48f659cd77522dc21c27d","tag_id":"62a48f659cd77522dc21c270","sort_order":0}],"products":[{"id":"62a48eba9cd77522dc21c092","name":"Free","slug":"free","active":1,"welcome_page_url":null,"visibility":"public","monthly_price_id":null,"yearly_price_id":null,"description":null,"type":"free","created_at":"2022-06-11 12:46:50","updated_at":"2022-06-11 12:46:50"},{"id":"62a48eba9cd77522dc21c093","name":"Jeroen Overschie","slug":"default-product","active":1,"welcome_page_url":null,"visibility":"public","monthly_price_id":null,"yearly_price_id":null,"description":null,"type":"paid","created_at":"2022-06-11 12:46:50","updated_at":"2022-06-11 12:47:41"}],"offers":[],"benefits":[],"products_benefits":[],"posts_products":[],"offer_redemptions":[],"stripe_products":[],"stripe_prices":[],"snippets":[],"custom_theme_settings":[{"id":"62a48ebb9cd77522dc21c258","theme":"casper","key":"title_font","type":"select","value":"Modern sans-serif"},{"id":"62a48ebb9cd77522dc21c259","theme":"casper","key":"body_font","type":"select","value":"Elegant serif"},{"id":"62a48ebb9cd77522dc21c25a","theme":"casper","key":"show_publication_cover","type":"boolean","value":"true"},{"id":"62a48ebb9cd77522dc21c25b","theme":"casper","key":"header_style","type":"select","value":"Center aligned"},{"id":"62a48ebb9cd77522dc21c25c","theme":"casper","key":"show_logo_in_navigation","type":"boolean","value":"false"},{"id":"62a48ebb9cd77522dc21c25d","theme":"casper","key":"feed_layout","type":"select","value":"Classic"},{"id":"62a48ebb9cd77522dc21c25e","theme":"casper","key":"color_scheme","type":"select","value":"Light"},{"id":"62a48ebb9cd77522dc21c25f","theme":"casper","key":"post_image_style","type":"select","value":"Wide"},{"id":"62a48ebb9cd77522dc21c260","theme":"casper","key":"email_signup_text","type":"text","value":"Sign up for more like this."},{"id":"62a48ebb9cd77522dc21c261","theme":"casper","key":"show_recent_posts_footer","type":"boolean","value":"true"},{"id":"62a48f869cd77522dc21c2a8","theme":"dunnkers-theme-edition","key":"title_font","type":"select","value":"Modern sans-serif"},{"id":"62a48f869cd77522dc21c2a9","theme":"dunnkers-theme-edition","key":"body_font","type":"select","value":"Modern sans-serif"},{"id":"62a48f869cd77522dc21c2aa","theme":"dunnkers-theme-edition","key":"email_signup_text","type":"text","value":null},{"id":"62a48f869cd77522dc21c2ab","theme":"dunnkers-theme-edition","key":"publication_cover_style","type":"select","value":"Fullscreen"},{"id":"62a48f869cd77522dc21c2ac","theme":"dunnkers-theme-edition","key":"show_featured_posts","type":"boolean","value":"true"},{"id":"62a48f869cd77522dc21c2ad","theme":"dunnkers-theme-edition","key":"featured_title","type":"text","value":"Featured articles"},{"id":"62a48f869cd77522dc21c2ae","theme":"dunnkers-theme-edition","key":"feed_title","type":"text","value":"Latest"},{"id":"62a48f869cd77522dc21c2af","theme":"dunnkers-theme-edition","key":"feed_layout","type":"select","value":"Expanded"},{"id":"62a48f869cd77522dc21c2b0","theme":"dunnkers-theme-edition","key":"show_share_links","type":"boolean","value":"true"},{"id":"62a48f869cd77522dc21c2b1","theme":"dunnkers-theme-edition","key":"show_author","type":"boolean","value":"true"},{"id":"62a48f869cd77522dc21c2b2","theme":"dunnkers-theme-edition","key":"show_related_posts","type":"boolean","value":"true"},{"id":"62a48f869cd77522dc21c2b3","theme":"dunnkers-theme-edition","key":"cover_icon_caption","type":"text","value":"Hi there üëãüèª."}]}}